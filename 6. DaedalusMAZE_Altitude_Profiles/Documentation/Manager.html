<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>AltitudeProfiles.Manager API documentation</title>
<meta name="description" content="This module includes functions which initiate the calculation of Altitude Profiles.
The function the user should call to initate a calculation is â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>AltitudeProfiles.Manager</code></h1>
</header>
<section id="section-intro">
<p>This module includes functions which initiate the calculation of Altitude Profiles.
The function the user should call to initate a calculation is called "StartCalculating(&hellip;)".
This function spawns one process for each source netcdf file. These processes save their results into temporary binary files.
After they all finish, "StartCalculating(&hellip;)" merges all results into a netcdf result-file.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module includes functions which initiate the calculation of Altitude Profiles.
The function the user should call to initate a calculation is called &#34;StartCalculating(...)&#34;. 
This function spawns one process for each source netcdf file. These processes save their results into temporary binary files.
After they all finish, &#34;StartCalculating(...)&#34; merges all results into a netcdf result-file.
&#34;&#34;&#34;

# local imports
import Data

# system imports
import netCDF4
from netCDF4 import Dataset 
import os
import datetime
import time
import glob
import shutil
import math
import numpy as np
import multiprocessing
import sys
from pathlib import Path
import random
from array import array

DEBUG_ENABLED = False # if true then the subprocesses print debug info in debug files. Useful because process cannot print on stdout

def CalcSurfaceAreaBetweenLatitudes( Lat1, Lat2 ):
    &#34;&#34;&#34;
    Calculates and returns the area on the surface of the Earth between Lat1 and Lat2.
    It assumes the Earth is a sphere with a radius of 6371km.
    
    Args:
        Lat1 (real): a latitude
        Lat2 (real): a latitude
        
    Returns:
        The area between the two latitudes on the Earth&#39;s surface
    &#34;&#34;&#34;
    result = math.sin(math.radians(Lat1)) - math.sin(math.radians(Lat2))
    result = 2 * math.pi * 6371 * result
    result = abs( result )
    return result
                                                     
                                                     

def StartCalculating( NetCDF_files_path, ResultFilename, TypeOfCalculation, TmpFilesPath, DeleteTmpFiles, Num_of_CalculationProcesses,   _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage):
    &#34;&#34;&#34;
    Initiate the calculation of Altitude Profiles. 
    The calculation is executed upon data from the TIEGCM model and the results are stored into a netcdf file.
    For each TIEGCM file one process is spawned, which saves its results into temporary binary files.
    After all processes finish, the temporary files are merged to create the results netcdf file.
    
    Args:
        NetCDF_files_path (string): the folder where TIEGCM model files are stored. 
        ResultFilename (string): the netcdf file where the calculation results will be stored
        TypeOfCalculation (string): the variable which will be used for the calculations. Possible values:  
            &#34;JH&#34; for Joule Heating (Ohmic)  
            &#34;JHminusWindHeat&#34; for Joule Heating minus Wind heating  
            &#34;PedCond&#34; for Pedersen Conductivity  
            &#34;HallCond&#34; for Pedersen Conductivity  
            &#34;EEX&#34; for Electric Field East in V/cm 
            &#34;EEY&#34; for Electric Field North in V/cm
            &#34;EEX_si&#34; for Electric Field East in V/m
            &#34;EEY_si&#34; for Electric Field North in V/m
            &#34;ConvHeat&#34; for Convection heating  
            &#34;WindHeat&#34; for Wind heating  
        TmpFilesPath (string): a folder where temporary files regarding the calculation will be stored.
        DeleteTmpFiles (boolean): whether the temporary files will be deleted after calculation finishes. 
        They can be ussed to continue a calculation after an intermediate halt. 
        Num_of_CalculationProcesses (int): how many processes will be spawned at the same time max, so that the calculation is parallel.
        There will be one process per sourcefile.
        _MLT_min: Magnetic Local Time range
        _MLT_max: Magnetic Local Time range
        _MLT_duration_of_a_bin: the size of each bin regarding Magnetic Local Time 
        _LAT_min: Latitude range
        _LAT_max: Latitude range
        _LAT_degrees_of_a_bin: how many degrees correspond to each bin 
        _ALT_min: Alttiude range
        _ALT_max: Alttiude range
        _ALT_distance_of_a_bin: kilometers of altitude assigned to each bin
        _num_of_KP_bins: how many Kp bins will be.  
                         One leads to range 0-9, two leads to ranges 0-3 and 3-9, three leads to ranges 0-2, 2-4, 4-9.
        _DistributionNumOfSlots: the resolution for calculating the Distribution of the values in the Bin.
        LatStep_for_WeightedAverage: Higher latitudes correspond to less surface area. 
            Thus, it is logical that values from different latitudes to have different impact on the calulation of average. 
            This value should match the grid size of the tiegcm source data.
            Possible values:  
            negative: normal average will be used for the calculations
            zero: default test values are used for latitudes 68.75, 71.25, 73.75, 76.25
            positive: the Bin is sliced by latitude of this magnitude and values falling in each slice have their own weight
    &#34;&#34;&#34;
    startSecs = time.time()
    print( &#34;START&#34;, datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;) )
    
    Data.setDataParams(_MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, TypeOfCalculation, _DistributionNumOfSlots)
    
    if not os.path.exists(TmpFilesPath):
        os.makedirs(TmpFilesPath)
    
    Allprocesses = list()
    AllCDFfiles = sorted( glob.glob( NetCDF_files_path, recursive=True ) )
    print( datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;) )
    print( &#34;I will calculate &#39;&#34; + TypeOfCalculation + &#34;&#39; on&#34;, len(AllCDFfiles), &#34;files in&#34;, NetCDF_files_path, &#34;\n&#34; )
    print( &#34;Results will be stored in &#39;&#34; + ResultFilename + &#34;&#39;\n&#34; )
    
    # del older partial txt files - there is one file for each bin containing all values in it
    if DeleteTmpFiles:
        try:
            shutil.rmtree( TmpFilesPath )
        except:
            pass
        
    num_of_processes = 0
    for CDF_file in AllCDFfiles:
        
        #print(&#34;-----------------------------------------------&#34;) # for debugging, so that prints errors on stdout
        #PROC_StatsCalculator(222, CDF_file, TypeOfCalculation, TmpFilesPath,    _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage)
        #print(&#34;-----------------------------------------------&#34;)
        
        num_of_processes += 1
        Data.Progress = int( 100 * num_of_processes/len(AllCDFfiles))
        
        # spawn new process
        print( &#34;Spawning process&#34;, num_of_processes, &#34;, reading&#34;,  CDF_file)    
        print( Data.ALT_min, Data.ALT_max, Data.ALT_distance_of_a_bin, Data.LAT_min, Data.LAT_max)
        print(Data.ALTsequence)
        P = multiprocessing.Process(target=PROC_StatsCalculator, args=(num_of_processes,CDF_file,TypeOfCalculation,TmpFilesPath,     _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage))
        Allprocesses.append(P)
        P.start()
        
        pause_spawning = True
        while pause_spawning:
            Num_of_alive_processes = 0        
            for P in Allprocesses:
                if P.is_alive():
                    Num_of_alive_processes += 1            
            if Num_of_alive_processes &gt;= Num_of_CalculationProcesses:
                pause_spawning = True
                time.sleep(12)
            else:
                pause_spawning = False
        
           
    # wait for all processes to terminate
    for T in Allprocesses: T.join()
        
    # every process creates a partial file, merge all of them into one
    print( &#34;Merging partial data files and calculating result values...&#34;,  datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;))
    ResultBins = Data.init_ResultDataStructure()
    NumOfBins = len(Data.KPsequence) * len(Data.ALTsequence) * len(Data.LATsequence) * len(Data.MLTsequence)
    CurrBinNum = 0
    
    for aKP in Data.KPsequence:
        for anALT in Data.ALTsequence:
            for aLat in Data.LATsequence:
                for aMLT in Data.MLTsequence:
                    CurrBinNum += 1
                    Data.Progress = int( 100 * CurrBinNum/NumOfBins )
                    AllBinValues = list()
                    for i in range(1,num_of_processes+1): # read all partial files for this bin 
                        partialDataFolder = TmpFilesPath+&#34;proc&#34;+ f&#34;{i:03}&#34; +&#34;/&#34;
                        if os.path.isdir(partialDataFolder)==False:
                            #print( &#34;There are no partial data files for process&#34;, i )
                            continue
                        partialTextFilename = partialDataFolder + str(aKP)+&#34;_&#34;+str(anALT)+&#34;_&#34;+str(aLat)+&#34;_&#34;+str(aMLT)+&#34;.txt&#34;
                        if os.path.exists(partialTextFilename) == False: # no hits for this bin from this process
                            #print(partialTextFilename, &#34;does not exist&#34;)
                            continue
                            
                        f = open(partialTextFilename, &#34;rb&#34;)
                        float_array = array(&#39;d&#39;)
                        float_array.frombytes(f.read())
                        AllBinValues += float_array.tolist()
                        f.close()
                        
                    print(&#34;BIN&#34;, &#34;Kp&#34;+str(aKP), &#34;Alt&#34;+str(anALT), &#34;Lat&#34;+str(aLat), &#34;MLT&#34;+str(aMLT), &#34;&#34;, len(AllBinValues), &#34;items&#34; )
                        
                    if len(AllBinValues) &gt; 0:
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Sum&#34;] = np.sum(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Len&#34;] = len(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile10&#34;] = np.percentile(AllBinValues, 10)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile25&#34;] = np.percentile(AllBinValues, 25)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile50&#34;] = np.percentile(AllBinValues, 50)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile75&#34;] = np.percentile(AllBinValues, 75)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile90&#34;] = np.percentile(AllBinValues, 90)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Variance&#34;] = np.var(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Minimum&#34;] = np.nanmin(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Maximum&#34;] = np.nanmax(AllBinValues)
                        
                        # calculate distribution
                        if Data.DistributionNumOfSlots &gt; 0:
                            histo_values, histo_ranges = np.histogram(AllBinValues, Data.DistributionNumOfSlots, (0, 0.0000001))
                            for i in range(0, Data.DistributionNumOfSlots):
                                ResultBins[aKP, anALT, aLat, aMLT, &#34;Distribution&#34;][i] = histo_values[i]
        
    if TypeOfCalculation == &#34;JH&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Joule Heating&#34;, &#34;W/m3&#34;)
    if TypeOfCalculation == &#34;JHminusWindHeat&#34; :
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Joule Heating minus Wind Heating&#34;, &#34;W/m3&#34;)
    elif TypeOfCalculation == &#34;PedCond&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Pedersen Conductivity&#34;, &#34;S/m&#34;)
    elif TypeOfCalculation == &#34;HallCond&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Hall Conductivity&#34;, &#34;S/m&#34;)    
    elif TypeOfCalculation==&#34;EEX_si&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field East&#34;, &#34;V/m&#34;)
    elif TypeOfCalculation==&#34;EEY_si&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field North&#34;, &#34;V/m&#34;)
    elif TypeOfCalculation==&#34;EEX&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field East&#34;, &#34;V/cm&#34;)
    elif TypeOfCalculation==&#34;EEY&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field North&#34;, &#34;V/cm&#34;)    
    elif TypeOfCalculation==&#34;ConvHeat&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Convection heating&#34;, &#34;W/m^3&#34;)
    elif TypeOfCalculation==&#34;WindHeat&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Wind heating&#34;, &#34;W/m^3&#34;)
    
    # delete temporary files, which contain all values for each bin
    if DeleteTmpFiles:
        try:
            shutil.rmtree( TmpFilesPath )
        except:
            pass
    
    # 
    finishSecs = time.time()
    print( &#34;FINISH&#34;,  datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), &#34; (&#34;, finishSecs-startSecs, &#34;sec )&#34;)


    
    

    
                  
                  
    

def PROC_StatsCalculator(ProcessNum, CDF_filename, TypeOfCalculation, TmpFilesPath,    _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage):
    &#34;&#34;&#34;
    Reads a NetCDF file and saves all the values of the variable in files.
    The variable is chosen by the &lt;TypeOfCalculation&gt; argument.
    The process saves several files in its own folder with name: TmpFilesPath+&#34;proc&#34;+&lt;ProcessNum&gt;+&#34;/&#34;
    The folder contains one binary file for each bin. The file contains all values of the variable which fall in the bin
    Args:
        ProcessNum: the unique index number of this process
        CDF_filename: the source file this process is going to read.
        TypeOfCalculation (string): the variable which will be used for the calculations. Possible values:  
            &#34;JH&#34; for Joule Heating (Ohmic)  
            &#34;JHminusWindHeat&#34; for Joule Heating minus Wind heating  
            &#34;PedCond&#34; for Pedersen Conductivity  
            &#34;HallCond&#34; for Pedersen Conductivity  
            &#34;EEX_si&#34; for Electric Field East in V/cm  
            &#34;EEY_si&#34; for Electric Field North in V/cm  
            &#34;EEX_si&#34; for Electric Field East in V/m  
            &#34;EEY_si&#34; for Electric Field North in V/m  
            &#34;ConvHeat&#34; for Convection heating  
            &#34;WindHeat&#34; for Wind heating  
        TmpFilesPath: the path where ths process is going to save its temporary files
    &#34;&#34;&#34;
    
    if DEBUG_ENABLED: debug_file = open( &#34;debug&#34;+str(ProcessNum)+&#34;.txt&#34;, &#34;w&#34; )
    if DEBUG_ENABLED: debug_file.write( &#34;START\n&#34; )
    
    # set again the data parameters, because the process has a different scope
    Data.setDataParams(_MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, TypeOfCalculation, _DistributionNumOfSlots)
    
    print( &#34;Process&#34;, ProcessNum, &#34;reading&#34;,  CDF_filename)    

    # check if the data of this process have already been calculated
    procfolder = TmpFilesPath+&#34;proc&#34;+ f&#34;{ProcessNum:03}&#34; +&#34;/&#34;
    if os.path.isdir(procfolder):
        print( &#34;Data for file&#34;, ProcessNum, &#34;already calculated.&#34;, &#34;Process&#34;, ProcessNum, &#34;finished.&#34; )
        return # &lt;&lt;&lt;&lt;
    else:
        if os.path.isdir(TmpFilesPath)==False: os.mkdir( TmpFilesPath )
        os.mkdir( procfolder )    
        
    # open netCDF file 
    ######## while( os.path.exists(&#34;ReadingFile.flag&#34;) ): # wait until no other process is reading from disk/NFS
    ########    time.sleep(random.randint(8,20))
    #Path(&#34;ReadingFile.flag&#34;).touch() # raise a flag that this process is now reading a file, so that other processes wait
    try:
        CDFroot = Dataset( CDF_filename, &#39;r&#39; )
    except:
        print ( &#34; !!!!!!!! WRONG FORMAT:&#34;, CDF_filename )
        #os.remove(&#34;ReadingFile.flag&#34;) # lower the reading-file flag
        return
        
    # read the data from the netCDF file
    #TIMEs  = CDFroot.variables[&#39;time&#39;][:] 
    if &#34;JH&#34; in TypeOfCalculation:        Ohmics = CDFroot.variables[&#39;Ohmic&#39;][:, :, :, :]  # m/s
    if &#34;PedCond&#34; in TypeOfCalculation:   PEDs   = CDFroot.variables[&#39;SIGMA_PED&#39;][:, :, :, :]
    if &#34;HallCond&#34; in TypeOfCalculation:  HALs   = CDFroot.variables[&#39;SIGMA_HAL&#39;][:, :, :, :]
    if &#34;EEX_si&#34; in TypeOfCalculation:    EEXs   = CDFroot.variables[&#39;EEX_si&#39;][:, :, :, :]
    if &#34;EEY_si&#34; in TypeOfCalculation:    EEYs   = CDFroot.variables[&#39;EEY_si&#39;][:, :, :, :]
    if TypeOfCalculation == &#34;EEX&#34;:       EEXs   = CDFroot.variables[&#39;EEX&#39;][:, :, :, :]
    if TypeOfCalculation == &#34;EEY&#34;:       EEYs   = CDFroot.variables[&#39;EEY&#39;][:, :, :, :]
    if &#34;ConvHeat&#34; in TypeOfCalculation:  ConvH  = CDFroot.variables[&#39;Convection_heating&#39;][:, :, :, :]
    if &#34;WindHeat&#34; in TypeOfCalculation:  WindH  = CDFroot.variables[&#39;Wind_heating&#39;][:, :, :, :]
    if &#34;JHminusWindHeat&#34; in TypeOfCalculation:  WindH  = CDFroot.variables[&#39;Wind_heating&#39;][:, :, :, :]        
        
    if &#34;JHnoWindsEISCAT&#34; in TypeOfCalculation: 
        UI = CDFroot.variables[&#39;UI_ExB&#39;][:, :, :, :]
        VI = CDFroot.variables[&#39;VI_ExB&#39;][:, :, :, :]
        WI = CDFroot.variables[&#39;WI_ExB&#39;][:, :, :, :]
        TIMEs = CDFroot.variables[&#39;time&#39;][:] 
        PEDs  = CDFroot.variables[&#39;SIGMA_PED&#39;][:, :, :, :]
        LONs  = CDFroot.variables[&#39;lon&#39;][:] 
        ZGs   = CDFroot.variables[&#39;ZG&#39;][:, :, :, :] / 100000 # Geometric height stored in cm, converted to km
    #
    LATs   = CDFroot.variables[&#39;lat&#39;][:] 
    #MLATs   = CDFroot.variables[&#39;mlat_qdf&#39;][:, :, :, :] 
    MLTs    = CDFroot.variables[&#39;mlt_qdf&#39;][:, :, :, :]         
    ALTs    = CDFroot.variables[&#39;ZGMID&#39;][:, :, :, :] / 100000 # Geometric height stored in cm, converted to km
    KPs     = CDFroot.variables[&#39;Kp&#39;][:]
    
    #try:
    #    os.remove(&#34;ReadingFile.flag&#34;) # lower the reading-file flag
    #except:
    #    pass
    
    hits = 0   # num of instances that fit in any of the defined bins

    ResultBins = Data.init_ResultDataStructure().copy()
    num_of_unbinned_items = 0
    step = 1
    for idx_time in range(0, len(ALTs), step):
        # $$$$$$$$ for each moment in time put the values in their bins and calculate the mean of each bin. 
        SingleMomentBins = Data.init_ResultDataStructure().copy()
        for idx_lev in range(0, len(ALTs[0]), step):
            for idx_lat in range(0, len(ALTs[0,0]), step):
                for idx_lon in range(0, len(ALTs[0,0,0]), step):
                    
                    curr_alt_km = ALTs[idx_time, idx_lev, idx_lat, idx_lon] 
                    
                    # ignore values for out-of-range positions 
                    if curr_alt_km&lt;Data.ALT_min or curr_alt_km&gt;Data.ALT_max:
                        continue
                        
                    curr_kp     = KPs[idx_time]
                    curr_mlt    = MLTs[idx_time, idx_lev, idx_lat, idx_lon]
                    curr_lat    = LATs[idx_lat]
                    
                    kp_to_fall,alt_to_fall,lat_to_fall,mlt_to_fall = Data.LocatePositionInBins(curr_kp,curr_alt_km,curr_lat,curr_mlt)
                    
                    if kp_to_fall is None or alt_to_fall is None or lat_to_fall is None or mlt_to_fall is None:
                        num_of_unbinned_items += 1
                        break # no other longitude can have a hit either
                    else:
                        if TypeOfCalculation==&#34;JHminusWindHeat&#34; or TypeOfCalculation==&#34;JHminusWindHeatEISCAT&#34;:
                            aValue = Ohmics[idx_time, idx_lev, idx_lat, idx_lon] - WindH[idx_time, idx_lev, idx_lat, idx_lon]
                            if aValue &gt; 100: continue # ignore faulty large values
                        elif TypeOfCalculation==&#34;JH&#34;:
                            aValue = Ohmics[idx_time, idx_lev, idx_lat, idx_lon]
                            if aValue &gt; 100: continue # ignore faulty large values
                        elif &#34;PedCond&#34; in TypeOfCalculation:
                            aValue = PEDs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;HallCond&#34; in TypeOfCalculation:
                            aValue = HALs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEX_si&#34; in TypeOfCalculation:
                            aValue = EEXs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEY_si&#34; in TypeOfCalculation:
                            aValue = EEYs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEX&#34; in TypeOfCalculation:
                            aValue = EEXs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEY&#34; in TypeOfCalculation:
                            aValue = EEYs[idx_time, idx_lev, idx_lat, idx_lon]    
                        elif &#34;ConvHeat&#34; in TypeOfCalculation:
                            aValue = ConvH[idx_time, idx_lev, idx_lat, idx_lon]
                            if aValue &gt; 100: continue # ignore faulty large values
                        elif &#34;WindHeat&#34; in TypeOfCalculation:
                            aValue = WindH[idx_time, idx_lev, idx_lat, idx_lon]
                        elif TypeOfCalculation==&#34;JHnoWindsEISCAT&#34;: 
                            I = list()
                            B = list()
                            time_p = datetime.datetime(2015, 3, 15, 0, 0, 0) + datetime.timedelta(minutes=TIMEs[idx_time])
                            lat_p = LATs[idx_lat]
                            lon_p = LONs[idx_lon]
                            alt_p = ZGs[idx_time, idx_lev, idx_lat, idx_lon]
                            pt = pyglow.Point(time_p, lat_p, lon_p, alt_p) # pyglow igrf
                            pt.run_igrf()
                            B.append( pt.Bx )  # Be, Tesla  (si)
                            B.append( pt.By )  # Bn, Tesla  (si)
                            B.append( pt.Bz )  # Bu, Tesla  (si)
                            I.append( UI[idx_time,idx_lev,idx_lat,idx_lon] )
                            I.append( VI[idx_time,idx_lev,idx_lat,idx_lon] )
                            I.append( WI[idx_time,idx_lev,idx_lat,idx_lon] )
                            E = -1 * np.cross(I, B)
                            aValue = PEDs[idx_time,idx_lev,idx_lat,idx_lon] * np.dot(E, E)
                        else:
                            print(&#34;ERROR: UNRECOGNISED TypeOfCalculation &#39;&#34; + TypeOfCalculation + &#34;&#39;&#34;)
                            CDFroot.close()
                            return
                        
                        # bin this value
                        SingleMomentBins[ kp_to_fall, alt_to_fall, lat_to_fall, mlt_to_fall, &#34;Vals&#34; ].append( aValue )
                        
                        # if weights are enabled then store the value&#39;s weight as well
                        if LatStep_for_WeightedAverage &gt;= 0:
                            weight = 1
                            if LatStep_for_WeightedAverage == 0:
                                if curr_lat == 68.75:
                                    weight = 0.0410
                                elif curr_lat == 71.25:
                                    weight = 0.381
                                elif curr_lat == 73.75:
                                    weight = 0.328
                                elif curr_lat == 76.25:
                                    weight = 0.249
                            else:
                                BinSurfaceArea = CalcSurfaceAreaBetweenLatitudes(lat_to_fall, lat_to_fall+Data.LAT_degrees_of_a_bin)
                                for i in range(math.floor(lat_to_fall), math.ceil(lat_to_fall+Data.LAT_degrees_of_a_bin)):
                                    if curr_lat&gt;i and curr_lat&lt;i+LatStep_for_WeightedAverage:
                                        RingArea = CalcSurfaceAreaBetweenLatitudes(i, i+LatStep_for_WeightedAverage )
                                        break
                                weight = RingArea / BinSurfaceArea 
                            #### warn
                            if DEBUG_ENABLED and weight==1: debug_file.write(&#34;Lat &#34; + str(curr_lat) + &#34; could not be assigned a weight\n&#34;)
                            #### bin the weight    
                            SingleMomentBins[ kp_to_fall, alt_to_fall, lat_to_fall, mlt_to_fall, &#34;Weights&#34; ].append( weight )
                            
                            if DEBUG_ENABLED: debug_file.write( str(weight) + &#34; &#34; +  str(aValue) + &#34;\n&#34; )
                        else:
                            SingleMomentBins[ kp_to_fall, alt_to_fall, lat_to_fall, mlt_to_fall, &#34;Weights&#34; ].append( 1 )
                        
                        # keep tracks of the number of the total binned values 
                        hits +=1
                        
        # $$$$$$$$ the averages of each time moment are stored in their bin. The percentiles will be calculated on them at the end 
        if LatStep_for_WeightedAverage &gt;= 0: # weighted average
            for aKP in Data.KPsequence:
                for anALT in Data.ALTsequence:
                    for aLat in Data.LATsequence:
                        for aMLT in Data.MLTsequence: 
                            L = len(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
                            if L &gt; 0:
                                S = 0
                                sum_of_weights = 0
                                BinVals    = SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;]
                                BinWeights = SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Weights&#34;]
                                for i in range(0, len(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])):
                                    S +=  BinWeights[i] * BinVals[i]
                                    sum_of_weights += BinWeights[i]
                                ResultBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;].append( S / sum_of_weights )
                                
        else: # normal average
            for aKP in Data.KPsequence:
                for anALT in Data.ALTsequence:
                    for aLat in Data.LATsequence:
                        for aMLT in Data.MLTsequence: 
                            L = len(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
                            if L &gt; 0:
                                S = sum(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
                                ResultBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;].append( S / L )

    # close cdf
    CDFroot.close()
    
    # ---- save values of each bin in a binary file
    for aKP in Data.KPsequence:
        for anALT in Data.ALTsequence:
            for aLat in Data.LATsequence:
                for aMLT in Data.MLTsequence:    
                    if len( ResultBins[ aKP, anALT, aLat, aMLT, &#34;Vals&#34; ] ) &gt; 0:
                        fname = str(aKP) + &#34;_&#34; + str(anALT) + &#34;_&#34; + str(aLat) + &#34;_&#34; + str(aMLT) + &#34;.txt&#34;
                        f = open( procfolder + fname, &#34;wb&#34; )
                        float_array = array(&#39;d&#39;, ResultBins[aKP, anALT, aLat, aMLT, &#34;Vals&#34;])
                        float_array.tofile(f)
                        f.close()

    # -------- print result
    &#39;&#39;&#39;
    msg = &#34;Process &#34; + str(ProcessNum) + &#34; &#34; + CDF_filename +  &#34; Hits=&#34; + str(hits)
    for aKP in Data.KPsequence:
        msg += &#34;\n&#34;
        for aMLT in Data.MLTsequence: 
            n = 0
            for aLat in Data.LATsequence:
                for anALT in Data.ALTsequence:
                    n += len(ResultBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
            msg += &#34;  &#34; + str(n)
    &#39;&#39;&#39;
    if DEBUG_ENABLED: debug_file.write( &#34;FINISH\n&#34; )
    if DEBUG_ENABLED: debug_file.close() 
    
    
    
    
    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="AltitudeProfiles.Manager.CalcSurfaceAreaBetweenLatitudes"><code class="name flex">
<span>def <span class="ident">CalcSurfaceAreaBetweenLatitudes</span></span>(<span>Lat1, Lat2)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates and returns the area on the surface of the Earth between Lat1 and Lat2.
It assumes the Earth is a sphere with a radius of 6371km.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Lat1</code></strong> :&ensp;<code>real</code></dt>
<dd>a latitude</dd>
<dt><strong><code>Lat2</code></strong> :&ensp;<code>real</code></dt>
<dd>a latitude</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The area between the two latitudes on the Earth's surface</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CalcSurfaceAreaBetweenLatitudes( Lat1, Lat2 ):
    &#34;&#34;&#34;
    Calculates and returns the area on the surface of the Earth between Lat1 and Lat2.
    It assumes the Earth is a sphere with a radius of 6371km.
    
    Args:
        Lat1 (real): a latitude
        Lat2 (real): a latitude
        
    Returns:
        The area between the two latitudes on the Earth&#39;s surface
    &#34;&#34;&#34;
    result = math.sin(math.radians(Lat1)) - math.sin(math.radians(Lat2))
    result = 2 * math.pi * 6371 * result
    result = abs( result )
    return result</code></pre>
</details>
</dd>
<dt id="AltitudeProfiles.Manager.PROC_StatsCalculator"><code class="name flex">
<span>def <span class="ident">PROC_StatsCalculator</span></span>(<span>ProcessNum, CDF_filename, TypeOfCalculation, TmpFilesPath, _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a NetCDF file and saves all the values of the variable in files.
The variable is chosen by the <TypeOfCalculation> argument.
The process saves several files in its own folder with name: TmpFilesPath+"proc"+<ProcessNum>+"/"
The folder contains one binary file for each bin. The file contains all values of the variable which fall in the bin</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ProcessNum</code></strong></dt>
<dd>the unique index number of this process</dd>
<dt><strong><code>CDF_filename</code></strong></dt>
<dd>the source file this process is going to read.</dd>
<dt><strong><code>TypeOfCalculation</code></strong> :&ensp;<code>string</code></dt>
<dd>the variable which will be used for the calculations. Possible values:<br>
"JH" for Joule Heating (Ohmic)<br>
"JHminusWindHeat" for Joule Heating minus Wind heating<br>
"PedCond" for Pedersen Conductivity<br>
"HallCond" for Pedersen Conductivity<br>
"EEX_si" for Electric Field East in V/cm<br>
"EEY_si" for Electric Field North in V/cm<br>
"EEX_si" for Electric Field East in V/m<br>
"EEY_si" for Electric Field North in V/m<br>
"ConvHeat" for Convection heating<br>
"WindHeat" for Wind heating
</dd>
<dt><strong><code>TmpFilesPath</code></strong></dt>
<dd>the path where ths process is going to save its temporary files</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def PROC_StatsCalculator(ProcessNum, CDF_filename, TypeOfCalculation, TmpFilesPath,    _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage):
    &#34;&#34;&#34;
    Reads a NetCDF file and saves all the values of the variable in files.
    The variable is chosen by the &lt;TypeOfCalculation&gt; argument.
    The process saves several files in its own folder with name: TmpFilesPath+&#34;proc&#34;+&lt;ProcessNum&gt;+&#34;/&#34;
    The folder contains one binary file for each bin. The file contains all values of the variable which fall in the bin
    Args:
        ProcessNum: the unique index number of this process
        CDF_filename: the source file this process is going to read.
        TypeOfCalculation (string): the variable which will be used for the calculations. Possible values:  
            &#34;JH&#34; for Joule Heating (Ohmic)  
            &#34;JHminusWindHeat&#34; for Joule Heating minus Wind heating  
            &#34;PedCond&#34; for Pedersen Conductivity  
            &#34;HallCond&#34; for Pedersen Conductivity  
            &#34;EEX_si&#34; for Electric Field East in V/cm  
            &#34;EEY_si&#34; for Electric Field North in V/cm  
            &#34;EEX_si&#34; for Electric Field East in V/m  
            &#34;EEY_si&#34; for Electric Field North in V/m  
            &#34;ConvHeat&#34; for Convection heating  
            &#34;WindHeat&#34; for Wind heating  
        TmpFilesPath: the path where ths process is going to save its temporary files
    &#34;&#34;&#34;
    
    if DEBUG_ENABLED: debug_file = open( &#34;debug&#34;+str(ProcessNum)+&#34;.txt&#34;, &#34;w&#34; )
    if DEBUG_ENABLED: debug_file.write( &#34;START\n&#34; )
    
    # set again the data parameters, because the process has a different scope
    Data.setDataParams(_MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, TypeOfCalculation, _DistributionNumOfSlots)
    
    print( &#34;Process&#34;, ProcessNum, &#34;reading&#34;,  CDF_filename)    

    # check if the data of this process have already been calculated
    procfolder = TmpFilesPath+&#34;proc&#34;+ f&#34;{ProcessNum:03}&#34; +&#34;/&#34;
    if os.path.isdir(procfolder):
        print( &#34;Data for file&#34;, ProcessNum, &#34;already calculated.&#34;, &#34;Process&#34;, ProcessNum, &#34;finished.&#34; )
        return # &lt;&lt;&lt;&lt;
    else:
        if os.path.isdir(TmpFilesPath)==False: os.mkdir( TmpFilesPath )
        os.mkdir( procfolder )    
        
    # open netCDF file 
    ######## while( os.path.exists(&#34;ReadingFile.flag&#34;) ): # wait until no other process is reading from disk/NFS
    ########    time.sleep(random.randint(8,20))
    #Path(&#34;ReadingFile.flag&#34;).touch() # raise a flag that this process is now reading a file, so that other processes wait
    try:
        CDFroot = Dataset( CDF_filename, &#39;r&#39; )
    except:
        print ( &#34; !!!!!!!! WRONG FORMAT:&#34;, CDF_filename )
        #os.remove(&#34;ReadingFile.flag&#34;) # lower the reading-file flag
        return
        
    # read the data from the netCDF file
    #TIMEs  = CDFroot.variables[&#39;time&#39;][:] 
    if &#34;JH&#34; in TypeOfCalculation:        Ohmics = CDFroot.variables[&#39;Ohmic&#39;][:, :, :, :]  # m/s
    if &#34;PedCond&#34; in TypeOfCalculation:   PEDs   = CDFroot.variables[&#39;SIGMA_PED&#39;][:, :, :, :]
    if &#34;HallCond&#34; in TypeOfCalculation:  HALs   = CDFroot.variables[&#39;SIGMA_HAL&#39;][:, :, :, :]
    if &#34;EEX_si&#34; in TypeOfCalculation:    EEXs   = CDFroot.variables[&#39;EEX_si&#39;][:, :, :, :]
    if &#34;EEY_si&#34; in TypeOfCalculation:    EEYs   = CDFroot.variables[&#39;EEY_si&#39;][:, :, :, :]
    if TypeOfCalculation == &#34;EEX&#34;:       EEXs   = CDFroot.variables[&#39;EEX&#39;][:, :, :, :]
    if TypeOfCalculation == &#34;EEY&#34;:       EEYs   = CDFroot.variables[&#39;EEY&#39;][:, :, :, :]
    if &#34;ConvHeat&#34; in TypeOfCalculation:  ConvH  = CDFroot.variables[&#39;Convection_heating&#39;][:, :, :, :]
    if &#34;WindHeat&#34; in TypeOfCalculation:  WindH  = CDFroot.variables[&#39;Wind_heating&#39;][:, :, :, :]
    if &#34;JHminusWindHeat&#34; in TypeOfCalculation:  WindH  = CDFroot.variables[&#39;Wind_heating&#39;][:, :, :, :]        
        
    if &#34;JHnoWindsEISCAT&#34; in TypeOfCalculation: 
        UI = CDFroot.variables[&#39;UI_ExB&#39;][:, :, :, :]
        VI = CDFroot.variables[&#39;VI_ExB&#39;][:, :, :, :]
        WI = CDFroot.variables[&#39;WI_ExB&#39;][:, :, :, :]
        TIMEs = CDFroot.variables[&#39;time&#39;][:] 
        PEDs  = CDFroot.variables[&#39;SIGMA_PED&#39;][:, :, :, :]
        LONs  = CDFroot.variables[&#39;lon&#39;][:] 
        ZGs   = CDFroot.variables[&#39;ZG&#39;][:, :, :, :] / 100000 # Geometric height stored in cm, converted to km
    #
    LATs   = CDFroot.variables[&#39;lat&#39;][:] 
    #MLATs   = CDFroot.variables[&#39;mlat_qdf&#39;][:, :, :, :] 
    MLTs    = CDFroot.variables[&#39;mlt_qdf&#39;][:, :, :, :]         
    ALTs    = CDFroot.variables[&#39;ZGMID&#39;][:, :, :, :] / 100000 # Geometric height stored in cm, converted to km
    KPs     = CDFroot.variables[&#39;Kp&#39;][:]
    
    #try:
    #    os.remove(&#34;ReadingFile.flag&#34;) # lower the reading-file flag
    #except:
    #    pass
    
    hits = 0   # num of instances that fit in any of the defined bins

    ResultBins = Data.init_ResultDataStructure().copy()
    num_of_unbinned_items = 0
    step = 1
    for idx_time in range(0, len(ALTs), step):
        # $$$$$$$$ for each moment in time put the values in their bins and calculate the mean of each bin. 
        SingleMomentBins = Data.init_ResultDataStructure().copy()
        for idx_lev in range(0, len(ALTs[0]), step):
            for idx_lat in range(0, len(ALTs[0,0]), step):
                for idx_lon in range(0, len(ALTs[0,0,0]), step):
                    
                    curr_alt_km = ALTs[idx_time, idx_lev, idx_lat, idx_lon] 
                    
                    # ignore values for out-of-range positions 
                    if curr_alt_km&lt;Data.ALT_min or curr_alt_km&gt;Data.ALT_max:
                        continue
                        
                    curr_kp     = KPs[idx_time]
                    curr_mlt    = MLTs[idx_time, idx_lev, idx_lat, idx_lon]
                    curr_lat    = LATs[idx_lat]
                    
                    kp_to_fall,alt_to_fall,lat_to_fall,mlt_to_fall = Data.LocatePositionInBins(curr_kp,curr_alt_km,curr_lat,curr_mlt)
                    
                    if kp_to_fall is None or alt_to_fall is None or lat_to_fall is None or mlt_to_fall is None:
                        num_of_unbinned_items += 1
                        break # no other longitude can have a hit either
                    else:
                        if TypeOfCalculation==&#34;JHminusWindHeat&#34; or TypeOfCalculation==&#34;JHminusWindHeatEISCAT&#34;:
                            aValue = Ohmics[idx_time, idx_lev, idx_lat, idx_lon] - WindH[idx_time, idx_lev, idx_lat, idx_lon]
                            if aValue &gt; 100: continue # ignore faulty large values
                        elif TypeOfCalculation==&#34;JH&#34;:
                            aValue = Ohmics[idx_time, idx_lev, idx_lat, idx_lon]
                            if aValue &gt; 100: continue # ignore faulty large values
                        elif &#34;PedCond&#34; in TypeOfCalculation:
                            aValue = PEDs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;HallCond&#34; in TypeOfCalculation:
                            aValue = HALs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEX_si&#34; in TypeOfCalculation:
                            aValue = EEXs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEY_si&#34; in TypeOfCalculation:
                            aValue = EEYs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEX&#34; in TypeOfCalculation:
                            aValue = EEXs[idx_time, idx_lev, idx_lat, idx_lon]
                        elif &#34;EEY&#34; in TypeOfCalculation:
                            aValue = EEYs[idx_time, idx_lev, idx_lat, idx_lon]    
                        elif &#34;ConvHeat&#34; in TypeOfCalculation:
                            aValue = ConvH[idx_time, idx_lev, idx_lat, idx_lon]
                            if aValue &gt; 100: continue # ignore faulty large values
                        elif &#34;WindHeat&#34; in TypeOfCalculation:
                            aValue = WindH[idx_time, idx_lev, idx_lat, idx_lon]
                        elif TypeOfCalculation==&#34;JHnoWindsEISCAT&#34;: 
                            I = list()
                            B = list()
                            time_p = datetime.datetime(2015, 3, 15, 0, 0, 0) + datetime.timedelta(minutes=TIMEs[idx_time])
                            lat_p = LATs[idx_lat]
                            lon_p = LONs[idx_lon]
                            alt_p = ZGs[idx_time, idx_lev, idx_lat, idx_lon]
                            pt = pyglow.Point(time_p, lat_p, lon_p, alt_p) # pyglow igrf
                            pt.run_igrf()
                            B.append( pt.Bx )  # Be, Tesla  (si)
                            B.append( pt.By )  # Bn, Tesla  (si)
                            B.append( pt.Bz )  # Bu, Tesla  (si)
                            I.append( UI[idx_time,idx_lev,idx_lat,idx_lon] )
                            I.append( VI[idx_time,idx_lev,idx_lat,idx_lon] )
                            I.append( WI[idx_time,idx_lev,idx_lat,idx_lon] )
                            E = -1 * np.cross(I, B)
                            aValue = PEDs[idx_time,idx_lev,idx_lat,idx_lon] * np.dot(E, E)
                        else:
                            print(&#34;ERROR: UNRECOGNISED TypeOfCalculation &#39;&#34; + TypeOfCalculation + &#34;&#39;&#34;)
                            CDFroot.close()
                            return
                        
                        # bin this value
                        SingleMomentBins[ kp_to_fall, alt_to_fall, lat_to_fall, mlt_to_fall, &#34;Vals&#34; ].append( aValue )
                        
                        # if weights are enabled then store the value&#39;s weight as well
                        if LatStep_for_WeightedAverage &gt;= 0:
                            weight = 1
                            if LatStep_for_WeightedAverage == 0:
                                if curr_lat == 68.75:
                                    weight = 0.0410
                                elif curr_lat == 71.25:
                                    weight = 0.381
                                elif curr_lat == 73.75:
                                    weight = 0.328
                                elif curr_lat == 76.25:
                                    weight = 0.249
                            else:
                                BinSurfaceArea = CalcSurfaceAreaBetweenLatitudes(lat_to_fall, lat_to_fall+Data.LAT_degrees_of_a_bin)
                                for i in range(math.floor(lat_to_fall), math.ceil(lat_to_fall+Data.LAT_degrees_of_a_bin)):
                                    if curr_lat&gt;i and curr_lat&lt;i+LatStep_for_WeightedAverage:
                                        RingArea = CalcSurfaceAreaBetweenLatitudes(i, i+LatStep_for_WeightedAverage )
                                        break
                                weight = RingArea / BinSurfaceArea 
                            #### warn
                            if DEBUG_ENABLED and weight==1: debug_file.write(&#34;Lat &#34; + str(curr_lat) + &#34; could not be assigned a weight\n&#34;)
                            #### bin the weight    
                            SingleMomentBins[ kp_to_fall, alt_to_fall, lat_to_fall, mlt_to_fall, &#34;Weights&#34; ].append( weight )
                            
                            if DEBUG_ENABLED: debug_file.write( str(weight) + &#34; &#34; +  str(aValue) + &#34;\n&#34; )
                        else:
                            SingleMomentBins[ kp_to_fall, alt_to_fall, lat_to_fall, mlt_to_fall, &#34;Weights&#34; ].append( 1 )
                        
                        # keep tracks of the number of the total binned values 
                        hits +=1
                        
        # $$$$$$$$ the averages of each time moment are stored in their bin. The percentiles will be calculated on them at the end 
        if LatStep_for_WeightedAverage &gt;= 0: # weighted average
            for aKP in Data.KPsequence:
                for anALT in Data.ALTsequence:
                    for aLat in Data.LATsequence:
                        for aMLT in Data.MLTsequence: 
                            L = len(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
                            if L &gt; 0:
                                S = 0
                                sum_of_weights = 0
                                BinVals    = SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;]
                                BinWeights = SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Weights&#34;]
                                for i in range(0, len(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])):
                                    S +=  BinWeights[i] * BinVals[i]
                                    sum_of_weights += BinWeights[i]
                                ResultBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;].append( S / sum_of_weights )
                                
        else: # normal average
            for aKP in Data.KPsequence:
                for anALT in Data.ALTsequence:
                    for aLat in Data.LATsequence:
                        for aMLT in Data.MLTsequence: 
                            L = len(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
                            if L &gt; 0:
                                S = sum(SingleMomentBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
                                ResultBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;].append( S / L )

    # close cdf
    CDFroot.close()
    
    # ---- save values of each bin in a binary file
    for aKP in Data.KPsequence:
        for anALT in Data.ALTsequence:
            for aLat in Data.LATsequence:
                for aMLT in Data.MLTsequence:    
                    if len( ResultBins[ aKP, anALT, aLat, aMLT, &#34;Vals&#34; ] ) &gt; 0:
                        fname = str(aKP) + &#34;_&#34; + str(anALT) + &#34;_&#34; + str(aLat) + &#34;_&#34; + str(aMLT) + &#34;.txt&#34;
                        f = open( procfolder + fname, &#34;wb&#34; )
                        float_array = array(&#39;d&#39;, ResultBins[aKP, anALT, aLat, aMLT, &#34;Vals&#34;])
                        float_array.tofile(f)
                        f.close()

    # -------- print result
    &#39;&#39;&#39;
    msg = &#34;Process &#34; + str(ProcessNum) + &#34; &#34; + CDF_filename +  &#34; Hits=&#34; + str(hits)
    for aKP in Data.KPsequence:
        msg += &#34;\n&#34;
        for aMLT in Data.MLTsequence: 
            n = 0
            for aLat in Data.LATsequence:
                for anALT in Data.ALTsequence:
                    n += len(ResultBins[aKP,anALT,aLat,aMLT,&#34;Vals&#34;])
            msg += &#34;  &#34; + str(n)
    &#39;&#39;&#39;
    if DEBUG_ENABLED: debug_file.write( &#34;FINISH\n&#34; )
    if DEBUG_ENABLED: debug_file.close() </code></pre>
</details>
</dd>
<dt id="AltitudeProfiles.Manager.StartCalculating"><code class="name flex">
<span>def <span class="ident">StartCalculating</span></span>(<span>NetCDF_files_path, ResultFilename, TypeOfCalculation, TmpFilesPath, DeleteTmpFiles, Num_of_CalculationProcesses, _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage)</span>
</code></dt>
<dd>
<div class="desc"><p>Initiate the calculation of Altitude Profiles.
The calculation is executed upon data from the TIEGCM model and the results are stored into a netcdf file.
For each TIEGCM file one process is spawned, which saves its results into temporary binary files.
After all processes finish, the temporary files are merged to create the results netcdf file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>NetCDF_files_path</code></strong> :&ensp;<code>string</code></dt>
<dd>the folder where TIEGCM model files are stored. </dd>
<dt><strong><code>ResultFilename</code></strong> :&ensp;<code>string</code></dt>
<dd>the netcdf file where the calculation results will be stored</dd>
<dt><strong><code>TypeOfCalculation</code></strong> :&ensp;<code>string</code></dt>
<dd>the variable which will be used for the calculations. Possible values:<br>
"JH" for Joule Heating (Ohmic)<br>
"JHminusWindHeat" for Joule Heating minus Wind heating<br>
"PedCond" for Pedersen Conductivity<br>
"HallCond" for Pedersen Conductivity<br>
"EEX" for Electric Field East in V/cm
"EEY" for Electric Field North in V/cm
"EEX_si" for Electric Field East in V/m
"EEY_si" for Electric Field North in V/m
"ConvHeat" for Convection heating<br>
"WindHeat" for Wind heating
</dd>
<dt><strong><code>TmpFilesPath</code></strong> :&ensp;<code>string</code></dt>
<dd>a folder where temporary files regarding the calculation will be stored.</dd>
<dt><strong><code>DeleteTmpFiles</code></strong> :&ensp;<code>boolean</code></dt>
<dd>whether the temporary files will be deleted after calculation finishes. </dd>
<dt>They can be ussed to continue a calculation after an intermediate halt.</dt>
<dt><strong><code>Num_of_CalculationProcesses</code></strong> :&ensp;<code>int</code></dt>
<dd>how many processes will be spawned at the same time max, so that the calculation is parallel.</dd>
<dt>There will be one process per sourcefile.</dt>
<dt><strong><code>_MLT_min</code></strong></dt>
<dd>Magnetic Local Time range</dd>
<dt><strong><code>_MLT_max</code></strong></dt>
<dd>Magnetic Local Time range</dd>
<dt><strong><code>_MLT_duration_of_a_bin</code></strong></dt>
<dd>the size of each bin regarding Magnetic Local Time </dd>
<dt><strong><code>_LAT_min</code></strong></dt>
<dd>Latitude range</dd>
<dt><strong><code>_LAT_max</code></strong></dt>
<dd>Latitude range</dd>
<dt><strong><code>_LAT_degrees_of_a_bin</code></strong></dt>
<dd>how many degrees correspond to each bin </dd>
<dt><strong><code>_ALT_min</code></strong></dt>
<dd>Alttiude range</dd>
<dt><strong><code>_ALT_max</code></strong></dt>
<dd>Alttiude range</dd>
<dt><strong><code>_ALT_distance_of_a_bin</code></strong></dt>
<dd>kilometers of altitude assigned to each bin</dd>
<dt><strong><code>_num_of_KP_bins</code></strong></dt>
<dd>how many Kp bins will be.<br>
One leads to range 0-9, two leads to ranges 0-3 and 3-9, three leads to ranges 0-2, 2-4, 4-9.</dd>
<dt><strong><code>_DistributionNumOfSlots</code></strong></dt>
<dd>the resolution for calculating the Distribution of the values in the Bin.</dd>
<dt><strong><code>LatStep_for_WeightedAverage</code></strong></dt>
<dd>Higher latitudes correspond to less surface area.
Thus, it is logical that values from different latitudes to have different impact on the calulation of average.
This value should match the grid size of the tiegcm source data.
Possible values:<br>
negative: normal average will be used for the calculations
zero: default test values are used for latitudes 68.75, 71.25, 73.75, 76.25
positive: the Bin is sliced by latitude of this magnitude and values falling in each slice have their own weight</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def StartCalculating( NetCDF_files_path, ResultFilename, TypeOfCalculation, TmpFilesPath, DeleteTmpFiles, Num_of_CalculationProcesses,   _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage):
    &#34;&#34;&#34;
    Initiate the calculation of Altitude Profiles. 
    The calculation is executed upon data from the TIEGCM model and the results are stored into a netcdf file.
    For each TIEGCM file one process is spawned, which saves its results into temporary binary files.
    After all processes finish, the temporary files are merged to create the results netcdf file.
    
    Args:
        NetCDF_files_path (string): the folder where TIEGCM model files are stored. 
        ResultFilename (string): the netcdf file where the calculation results will be stored
        TypeOfCalculation (string): the variable which will be used for the calculations. Possible values:  
            &#34;JH&#34; for Joule Heating (Ohmic)  
            &#34;JHminusWindHeat&#34; for Joule Heating minus Wind heating  
            &#34;PedCond&#34; for Pedersen Conductivity  
            &#34;HallCond&#34; for Pedersen Conductivity  
            &#34;EEX&#34; for Electric Field East in V/cm 
            &#34;EEY&#34; for Electric Field North in V/cm
            &#34;EEX_si&#34; for Electric Field East in V/m
            &#34;EEY_si&#34; for Electric Field North in V/m
            &#34;ConvHeat&#34; for Convection heating  
            &#34;WindHeat&#34; for Wind heating  
        TmpFilesPath (string): a folder where temporary files regarding the calculation will be stored.
        DeleteTmpFiles (boolean): whether the temporary files will be deleted after calculation finishes. 
        They can be ussed to continue a calculation after an intermediate halt. 
        Num_of_CalculationProcesses (int): how many processes will be spawned at the same time max, so that the calculation is parallel.
        There will be one process per sourcefile.
        _MLT_min: Magnetic Local Time range
        _MLT_max: Magnetic Local Time range
        _MLT_duration_of_a_bin: the size of each bin regarding Magnetic Local Time 
        _LAT_min: Latitude range
        _LAT_max: Latitude range
        _LAT_degrees_of_a_bin: how many degrees correspond to each bin 
        _ALT_min: Alttiude range
        _ALT_max: Alttiude range
        _ALT_distance_of_a_bin: kilometers of altitude assigned to each bin
        _num_of_KP_bins: how many Kp bins will be.  
                         One leads to range 0-9, two leads to ranges 0-3 and 3-9, three leads to ranges 0-2, 2-4, 4-9.
        _DistributionNumOfSlots: the resolution for calculating the Distribution of the values in the Bin.
        LatStep_for_WeightedAverage: Higher latitudes correspond to less surface area. 
            Thus, it is logical that values from different latitudes to have different impact on the calulation of average. 
            This value should match the grid size of the tiegcm source data.
            Possible values:  
            negative: normal average will be used for the calculations
            zero: default test values are used for latitudes 68.75, 71.25, 73.75, 76.25
            positive: the Bin is sliced by latitude of this magnitude and values falling in each slice have their own weight
    &#34;&#34;&#34;
    startSecs = time.time()
    print( &#34;START&#34;, datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;) )
    
    Data.setDataParams(_MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, TypeOfCalculation, _DistributionNumOfSlots)
    
    if not os.path.exists(TmpFilesPath):
        os.makedirs(TmpFilesPath)
    
    Allprocesses = list()
    AllCDFfiles = sorted( glob.glob( NetCDF_files_path, recursive=True ) )
    print( datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;) )
    print( &#34;I will calculate &#39;&#34; + TypeOfCalculation + &#34;&#39; on&#34;, len(AllCDFfiles), &#34;files in&#34;, NetCDF_files_path, &#34;\n&#34; )
    print( &#34;Results will be stored in &#39;&#34; + ResultFilename + &#34;&#39;\n&#34; )
    
    # del older partial txt files - there is one file for each bin containing all values in it
    if DeleteTmpFiles:
        try:
            shutil.rmtree( TmpFilesPath )
        except:
            pass
        
    num_of_processes = 0
    for CDF_file in AllCDFfiles:
        
        #print(&#34;-----------------------------------------------&#34;) # for debugging, so that prints errors on stdout
        #PROC_StatsCalculator(222, CDF_file, TypeOfCalculation, TmpFilesPath,    _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage)
        #print(&#34;-----------------------------------------------&#34;)
        
        num_of_processes += 1
        Data.Progress = int( 100 * num_of_processes/len(AllCDFfiles))
        
        # spawn new process
        print( &#34;Spawning process&#34;, num_of_processes, &#34;, reading&#34;,  CDF_file)    
        print( Data.ALT_min, Data.ALT_max, Data.ALT_distance_of_a_bin, Data.LAT_min, Data.LAT_max)
        print(Data.ALTsequence)
        P = multiprocessing.Process(target=PROC_StatsCalculator, args=(num_of_processes,CDF_file,TypeOfCalculation,TmpFilesPath,     _MLT_min, _MLT_max, _MLT_duration_of_a_bin, _LAT_min, _LAT_max, _LAT_degrees_of_a_bin, _ALT_min, _ALT_max, _ALT_distance_of_a_bin, _num_of_KP_bins, _DistributionNumOfSlots, LatStep_for_WeightedAverage))
        Allprocesses.append(P)
        P.start()
        
        pause_spawning = True
        while pause_spawning:
            Num_of_alive_processes = 0        
            for P in Allprocesses:
                if P.is_alive():
                    Num_of_alive_processes += 1            
            if Num_of_alive_processes &gt;= Num_of_CalculationProcesses:
                pause_spawning = True
                time.sleep(12)
            else:
                pause_spawning = False
        
           
    # wait for all processes to terminate
    for T in Allprocesses: T.join()
        
    # every process creates a partial file, merge all of them into one
    print( &#34;Merging partial data files and calculating result values...&#34;,  datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;))
    ResultBins = Data.init_ResultDataStructure()
    NumOfBins = len(Data.KPsequence) * len(Data.ALTsequence) * len(Data.LATsequence) * len(Data.MLTsequence)
    CurrBinNum = 0
    
    for aKP in Data.KPsequence:
        for anALT in Data.ALTsequence:
            for aLat in Data.LATsequence:
                for aMLT in Data.MLTsequence:
                    CurrBinNum += 1
                    Data.Progress = int( 100 * CurrBinNum/NumOfBins )
                    AllBinValues = list()
                    for i in range(1,num_of_processes+1): # read all partial files for this bin 
                        partialDataFolder = TmpFilesPath+&#34;proc&#34;+ f&#34;{i:03}&#34; +&#34;/&#34;
                        if os.path.isdir(partialDataFolder)==False:
                            #print( &#34;There are no partial data files for process&#34;, i )
                            continue
                        partialTextFilename = partialDataFolder + str(aKP)+&#34;_&#34;+str(anALT)+&#34;_&#34;+str(aLat)+&#34;_&#34;+str(aMLT)+&#34;.txt&#34;
                        if os.path.exists(partialTextFilename) == False: # no hits for this bin from this process
                            #print(partialTextFilename, &#34;does not exist&#34;)
                            continue
                            
                        f = open(partialTextFilename, &#34;rb&#34;)
                        float_array = array(&#39;d&#39;)
                        float_array.frombytes(f.read())
                        AllBinValues += float_array.tolist()
                        f.close()
                        
                    print(&#34;BIN&#34;, &#34;Kp&#34;+str(aKP), &#34;Alt&#34;+str(anALT), &#34;Lat&#34;+str(aLat), &#34;MLT&#34;+str(aMLT), &#34;&#34;, len(AllBinValues), &#34;items&#34; )
                        
                    if len(AllBinValues) &gt; 0:
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Sum&#34;] = np.sum(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Len&#34;] = len(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile10&#34;] = np.percentile(AllBinValues, 10)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile25&#34;] = np.percentile(AllBinValues, 25)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile50&#34;] = np.percentile(AllBinValues, 50)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile75&#34;] = np.percentile(AllBinValues, 75)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Percentile90&#34;] = np.percentile(AllBinValues, 90)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Variance&#34;] = np.var(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Minimum&#34;] = np.nanmin(AllBinValues)
                        ResultBins[aKP, anALT, aLat, aMLT, &#34;Maximum&#34;] = np.nanmax(AllBinValues)
                        
                        # calculate distribution
                        if Data.DistributionNumOfSlots &gt; 0:
                            histo_values, histo_ranges = np.histogram(AllBinValues, Data.DistributionNumOfSlots, (0, 0.0000001))
                            for i in range(0, Data.DistributionNumOfSlots):
                                ResultBins[aKP, anALT, aLat, aMLT, &#34;Distribution&#34;][i] = histo_values[i]
        
    if TypeOfCalculation == &#34;JH&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Joule Heating&#34;, &#34;W/m3&#34;)
    if TypeOfCalculation == &#34;JHminusWindHeat&#34; :
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Joule Heating minus Wind Heating&#34;, &#34;W/m3&#34;)
    elif TypeOfCalculation == &#34;PedCond&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Pedersen Conductivity&#34;, &#34;S/m&#34;)
    elif TypeOfCalculation == &#34;HallCond&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Hall Conductivity&#34;, &#34;S/m&#34;)    
    elif TypeOfCalculation==&#34;EEX_si&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field East&#34;, &#34;V/m&#34;)
    elif TypeOfCalculation==&#34;EEY_si&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field North&#34;, &#34;V/m&#34;)
    elif TypeOfCalculation==&#34;EEX&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field East&#34;, &#34;V/cm&#34;)
    elif TypeOfCalculation==&#34;EEY&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Electric Field North&#34;, &#34;V/cm&#34;)    
    elif TypeOfCalculation==&#34;ConvHeat&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Convection heating&#34;, &#34;W/m^3&#34;)
    elif TypeOfCalculation==&#34;WindHeat&#34;:
        Data.WriteResultsToCDF(ResultBins, ResultFilename, &#34;Wind heating&#34;, &#34;W/m^3&#34;)
    
    # delete temporary files, which contain all values for each bin
    if DeleteTmpFiles:
        try:
            shutil.rmtree( TmpFilesPath )
        except:
            pass
    
    # 
    finishSecs = time.time()
    print( &#34;FINISH&#34;,  datetime.datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), &#34; (&#34;, finishSecs-startSecs, &#34;sec )&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="AltitudeProfiles" href="index.html">AltitudeProfiles</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="AltitudeProfiles.Manager.CalcSurfaceAreaBetweenLatitudes" href="#AltitudeProfiles.Manager.CalcSurfaceAreaBetweenLatitudes">CalcSurfaceAreaBetweenLatitudes</a></code></li>
<li><code><a title="AltitudeProfiles.Manager.PROC_StatsCalculator" href="#AltitudeProfiles.Manager.PROC_StatsCalculator">PROC_StatsCalculator</a></code></li>
<li><code><a title="AltitudeProfiles.Manager.StartCalculating" href="#AltitudeProfiles.Manager.StartCalculating">StartCalculating</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>