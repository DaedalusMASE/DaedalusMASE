<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>DaedalusMASE_Global_Statistics.data API documentation</title>
<meta name="description" content="This module contains all data structures, tools for saving and loading data from NetCDF files amd function which calculate statistics.
The main data â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>DaedalusMASE_Global_Statistics.data</code></h1>
</header>
<section id="section-intro">
<p>This module contains all data structures, tools for saving and loading data from NetCDF files amd function which calculate statistics.
The main data container is called Bin. A Bin is defined by ranges of Magnetic Latitude, Magnetic Local Time, Altitude and Kp-index.
There are several predefined Bins, but they can be deleted and new ones added.
The first letters of the Bin's ID is consiered the region name, which is a central notion for grouping the data and ploting them.
During calculations values of many variables are read from the TIEGCM or/and ORBIT NeyCDF files and are stored into the corresponding Bins along with their positions. These data can then be stored to a NetCDF result-file and are used to produce various plots.
The variables which are expected to be at the source and are stored to the result files are:<br>
|Variable description
|Unit
|Name in NetCDF files | Comment
|<br>
| ------------------------------ | --------------- | ------------------- | ------------ |<br>
|UTC timestamp
|seconds
|time
|
|<br>
|Altitude
|cm
|ZGMID
|
|<br>
|Latitude
|degrees
|lat
|
|<br>
|Magnetic Latitude
|degrees
|mlat_qdf
|
|<br>
|Magnetic Local Time
|hours
|mlt_qdf
|
|<br>
|Kp index
|0-9
|Kp
|
|<br>
|midpoint levels
|-
|lev
|
|<br>
|Ohmic (Joule) Heating
|W/m3
|Ohmic
|can be plotted|
<br>
|Convection Heating
|W/m3
|Convection_heating
|can be plotted|
<br>
|Wind Heating
|W/m3
|Wind_heating
|can be plotted|
<br>
|Electric field strength East
|V/m
|EEX
|can be plotted| <br>
|Electric field strength North
|V/m
|EEY
|can be plotted|<br>
|Total Density
|g/cm3
|DEN
|can be plotted|<br>
|Pedersen Conductivity
|S/m
|SIGMA_PED
|can be plotted| <br>
|Hall Conductivity
|S/m
|SIGMA_HAL
|can be plotted|<br>
Because many large files may contain the source data, folders are used to keep each file category:<br>
ORBITdata: all netcdf files containing the data along the orbit of a satellite<br>
RESULTS: netcdf files which this software creates as results and can be loaded in order to produce plots<br>
TIEGCMdata/*/: all netcdf files containing the data from the TIEGCM model. There must be one subfolder for each year.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module contains all data structures, tools for saving and loading data from NetCDF files amd function which calculate statistics.
The main data container is called Bin. A Bin is defined by ranges of Magnetic Latitude, Magnetic Local Time, Altitude and Kp-index.
There are several predefined Bins, but they can be deleted and new ones added. 
The first letters of the Bin&#39;s ID is consiered the region name, which is a central notion for grouping the data and ploting them.
During calculations values of many variables are read from the TIEGCM or/and ORBIT NeyCDF files and are stored into the corresponding Bins along with their positions. These data can then be stored to a NetCDF result-file and are used to produce various plots. 
The variables which are expected to be at the source and are stored to the result files are:  
    |Variable description            |Unit             |Name in NetCDF files | Comment      |  
    | ------------------------------ | --------------- | ------------------- | ------------ |  
    |UTC timestamp                   |seconds          |time                 |              |  
    |Altitude                        |cm               |ZGMID                |              |  
    |Latitude                        |degrees          |lat                  |              |  
    |Magnetic Latitude               |degrees          |mlat_qdf             |              |  
    |Magnetic Local Time             |hours            |mlt_qdf              |              |  
    |Kp index                        |0-9              |Kp                   |              |  
    |midpoint levels                 |-                |lev                  |              |  
    |Ohmic (Joule) Heating           |W/m3             |Ohmic                |can be plotted|    
    |Convection Heating              |W/m3             |Convection_heating   |can be plotted|    
    |Wind Heating                    |W/m3             |Wind_heating         |can be plotted|    
    |Electric field strength East    |V/m              |EEX                  |can be plotted|   
    |Electric field strength North   |V/m              |EEY                  |can be plotted|  
    |Total Density                   |g/cm3            |DEN                  |can be plotted|  
    |Pedersen Conductivity           |S/m              |SIGMA_PED            |can be plotted|   
    |Hall Conductivity               |S/m              |SIGMA_HAL            |can be plotted|  
Because many large files may contain the source data, folders are used to keep each file category:  
    ORBITdata: all netcdf files containing the data along the orbit of a satellite  
    RESULTS: netcdf files which this software creates as results and can be loaded in order to produce plots  
    TIEGCMdata/*/: all netcdf files containing the data from the TIEGCM model. There must be one subfolder for each year.  
&#34;&#34;&#34;

from datetime import datetime
import netCDF4
from netCDF4 import Dataset 
from os import path
import numpy as np 

import time
import numpy as np 
import threading
import glob
import copy
import calendar

from utils import *

# Properties of the current calculation
CALCULATIONS_Title = &#34;&#34;
CALCULATIONS_Description =&#34;&#34;
CALCULATIONS_RegionName = &#34;&#34;
CALCULATIONS_OrbitFilesPath = &#34;&#34;
CALCULATIONS_ResultsFilename = &#34;&#34;
CALCULATIONS_TIEGCMfolder = &#34;&#34;
CALCULATIONS_ExecutionDuration = 0

# The following lists store data about each hit
all_JH_values       = list()
all_MagLat_values   = list()
all_MLT_values      = list()
all_Altitude_values = list()
all_Lat_values      = list()
all_Kp_values       = list() 
all_Time_values     = list()
all_HittedBin_IDs   = list()
all_EEX_values      = list()
all_EEY_values      = list()
all_Pedersen_values = list()
all_Density_values  = list()
all_Lev_values      = list()
all_Hall_values     = list()
all_ConvectionHeating_values = list()
all_WindHeating_values = list()


def doit():
    global all_JH_values
    all_JH_values.append(4.44);
    all_JH_values.clear()
    all_JH_values.append(4.44);

# Define a class which can describe a bin
class Bin:
    ID             = &#34;&#34;
    Description    = &#34;&#34;
    MLT_min        = 0 # Magnetic Local Time (hour &amp; min of the 24-hour day) (string)
    MLT_max        = 0 # Magnetic Local Time (hour &amp; min of the 24-hour day) (string)
    MagLat_min     = 0 # Magnetic Latitude (degrees)
    MagLat_max     = 0 # Magnetic Latitude (degrees)
    Altitude_min   = 0 # Satellite&#39;s Altitude measured from Earth&#39;s surface (km)
    Altitude_max   = 0 # Satellite&#39;s Altitude measured from Earth&#39;s surface (km)
    Kp_min         = 0 #
    Kp_max         = 0 #
    Lat_min        = 0
    Lat_max        = 0
    NumOfBins      = 0 # How many parts will the Altitude range be splitted in
    CumulativeTime = 0 # (sec)
    DesirableCumulativeTime = 0 # (sec)
    JH_min      = 99999 # the minimum JH value inside the bin
    JH_max      = 0     # the maximum JH value inside the bin
    JH_mean     = 0     # the mean JH value inside the bin
    JH_median   = 0     # the median JH value inside the bin (=50th percentile)
    JH_variance = 0     # the variance of JH value inside the bin (variance = (1/(N-1)) * Sum{1-&gt;N}(X-MeanVariance)^2  )
    JH_medianVariance = 0
    JH_medianAbsDev = 0
    # Data:
    JH_values         = list() # here will be stored all Joule Heating values in order to calculate the variance at the end
    JH_distribution   = list() # the item 0 holds the number of points which have 0&lt;JH&lt;JH_max/100 etc
    MagLat_values     = list() #  these values correspond to the JH_values
    MLT_values        = list() #  these values correspond to the JH_values
    Altitude_values   = list() #  these values correspond to the JH_values
    Kp_values         = list() #  these values correspond to the JH_values
    Time_values       = list() #  these values correspond to the JH_values
    EEX_values        = list()
    EEY_values        = list()
    Pedersen_values   = list()
    Density_values    = list()
    Lev_values        = list()
    Hall_values       = list()
    ConvectionHeating_values = list()
    WindHeating_values = list()
    
    def __init__(self, ID, Description, MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Lat_min, Lat_max, Kp_min, Kp_max, DesirableCumulativeTime):
        self.ID             = ID
        self.Description    = Description
        self.MLT_min        = MLT_min 
        self.MLT_max        = MLT_max
        self.MagLat_min     = MagLat_min
        self.MagLat_max     = MagLat_max
        self.Altitude_min   = Altitude_min
        self.Altitude_max   = Altitude_max
        self.Lat_min        = Lat_min
        self.Lat_max        = Lat_max                
        self.Kp_min         = Kp_min
        self.Kp_max         = Kp_max
        self.DesirableCumulativeTime = DesirableCumulativeTime
        self.JH_values       = list()
        self.JH_distribution = [0] * 100
        self.MagLat_values   = list()
        self.MLT_values      = list()
        self.Altitude_values = list()
        self.Lat_values       = list()
        self.Kp_values       = list()
        self.Time_values     = list()
        self.EEX_values        = list()
        self.EEY_values        = list()
        self.Pedersen_values   = list()
        self.Density_values    = list()
        self.Lev_values        = list()
        self.Hall_values       = list()
        self.ConvectionHeating_values = list()
        self.WindHeating_values = list()

    def reset(self):
        self.JH_min      = 99999
        self.JH_mean     = 0
        self.JH_median   = 0
        self.JH_variance = 0
        self.JH_medianVariance = 0
        self.JH_medianAbsDev = 0
        self.JH_values.clear()
        self.MagLat_values.clear()
        self.MLT_values.clear()
        self.Altitude_values.clear()
        self.Lat_values.clear()
        self.Kp_values.clear()
        self.Time_values.clear()
        self.EEX_values.clear()
        self.EEY_values.clear()
        self.Pedersen_values.clear()
        self.Density_values.clear()
        self.Lev_values.clear()
        self.Hall_values.clear()        
        self.ConvectionHeating_values.clear()
        self.WindHeating_values.clear()
        
    def getInfo(self):
        s  = self.ID.ljust(8, &#39; &#39;) + &#34;: &#34;
        s += &#34;{:02.0f}&#34;.format(self.MLT_min)      + &#34;&lt;MLT&lt;=&#34;    + &#34;{:02.0f}&#34;.format(self.MLT_max)      + &#34; &#34;
        s += &#34;{:03.0f}&#34;.format(self.MagLat_min)   + &#34;&lt;MagLat&lt;=&#34; + &#34;{:03.0f}&#34;.format(self.MagLat_max)   + &#34; &#34;
        s += &#34;{:03.0f}&#34;.format(self.Altitude_min) + &#34;&lt;Alt&lt;=&#34;    + &#34;{:03.0f}&#34;.format(self.Altitude_max) + &#34; &#34;
        s += str(self.Kp_min)             + &#34;&lt;Kp&lt;=&#34;     + str(self.Kp_max)       + &#34; &#34;
        if self.JH_min == 99999:
            s += &#34; JHmin=&#34; + &#34;         &#34;
        else:
            s += &#34; JHmin=&#34; + &#34;{:.3e}&#34;.format(self.JH_min) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_min) )
        s += &#34; JHmean=&#34; + &#34;{:.3e}&#34;.format(self.JH_mean) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_mean) )
        s += &#34; JHvariance=&#34; + &#34;{:.3e}&#34;.format(self.JH_variance) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_variance) )
        ##
        str_JH = &#34;&#34;
        for i in range(0, len(self.JH_values) ):            
            str_JH += str( self.JH_values[i] )
            if i &lt; len(self.JH_values)-1: str_JH += &#39;,&#39;
        s += &#34; JH_values=&#34; + str_JH # &#39;&#39;.join(str(e) for e in self.JH_values)
        ##
        return s
    
    def printMe(self):
        print( self.getInfo()[:220] )


Bins = list() # this list holds the definitions of all bins
#                ID        Description                          MLT      MagLat    Altitude                Lat      Kp       DesiredTime(sec)
Bins.append( Bin(&#34;AEM_00&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   100, 105,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_01&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   105, 110,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_02&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   110, 115,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_03&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   115, 120,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_04&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   120, 125,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_05&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   125, 130,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_06&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   130, 135,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_07&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   135, 140,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_08&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   140, 145,               -90,90,  0, 3,   50*60 ) )    
Bins.append( Bin(&#34;AEM_09&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   145, 150,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_10&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   150, 155,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_11&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   155, 160,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEM_20&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   100, 105,               -90,90,  3, 9,   30*60 ) )
Bins.append( Bin(&#34;AEM_21&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   105, 110,               -90,90,  3, 9,   30*60 ) )
Bins.append( Bin(&#34;AEM_22&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   110, 115,               -90,90,  3, 9,   30*60 ) )
Bins.append( Bin(&#34;AEM_23&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   115, 120,               -90,90,  3, 9,   30*60 ) )
Bins.append( Bin(&#34;AEM_24&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   120, 125,               -90,90,  3, 9,   30*60 ) )
Bins.append( Bin(&#34;AEM_25&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   125, 130,               -90,90,  3, 9,   30*60 ) )    
Bins.append( Bin(&#34;AEM_26&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   130, 135,               -90,90,  3, 9,   30*60 ) )    
Bins.append( Bin(&#34;AEM_27&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   135, 140,               -90,90,  3, 9,   20*60 ) )
Bins.append( Bin(&#34;AEM_28&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   140, 145,               -90,90,  3, 9,   20*60 ) )
Bins.append( Bin(&#34;AEM_29&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   145, 150,               -90,90,  3, 9,   20*60 ) )
Bins.append( Bin(&#34;AEM_30&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   150, 155,               -90,90,  3, 9,   20*60 ) )
Bins.append( Bin(&#34;AEM_31&#34;, &#34;Auroral E region, midnight sector&#34;, 21, 3,   60, 75,   155, 160,               -90,90,  3, 9,   20*60 ) )

Bins.append( Bin(&#34;AAA_L1&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   100, 105,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L2&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   105, 110,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L3&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   110, 115,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L4&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   115, 120,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L5&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   120, 125,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L6&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   125, 130,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L7&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   130, 135,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L8&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   135, 140,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_L9&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   140, 145,               -90,90,  0, 3,   50*60 ) )    

Bins.append( Bin(&#34;AAA_La&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   145, 150,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_Lb&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   150, 155,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_Lc&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   155, 160,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AAA_M1&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   100, 105,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M2&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   105, 110,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M3&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   110, 115,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M4&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   115, 120,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M5&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   120, 125,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M6&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   125, 130,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M7&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   130, 135,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M8&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   135, 140,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_M9&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   140, 145,               -90,90,  3, 9,   50*60 ) )    
Bins.append( Bin(&#34;AAA_Ma&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   145, 150,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_Mb&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   150, 155,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AAA_Mc&#34;, &#34;Auroral E region, midnight sector&#34;, 12, 12,   50, 90,   155, 160,               -90,90,  3, 9,   50*60 ) )    
    
Bins.append( Bin(&#34;AFM_L1&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   150, 185,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L2&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   185, 220,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L3&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   220, 255,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L4&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   255, 290,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L5&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   290, 325,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L6&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   325, 360,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L7&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   360, 395,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L8&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   395, 430,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L9&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   430, 465,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_L10&#34;,&#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   465, 500,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;AFM_M1&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   150.0, 237.5,           -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;AFM_M2&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   237.5, 325.0,           -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;AFM_M3&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   325.0, 412.5,           -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;AFM_M4&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   412.5, 500.0,           -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;AFM_H1&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   150, 265,               -90,90,  4, 9,   20*60 ) )
Bins.append( Bin(&#34;AFM_H2&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   265, 380,               -90,90,  4, 9,   20*60 ) )
Bins.append( Bin(&#34;AFM_H3&#34;, &#34;Auroral F region, midnight sector&#34;, 21, 3,   60, 75,   380, 500,               -90,90,  4, 9,   20*60 ) )
    
Bins.append( Bin(&#34;AEE_00&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   100, 105,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_01&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   105, 110,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_02&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   110, 115,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_03&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   115, 120,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_04&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   120, 125,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_05&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   125, 130,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_06&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   130, 135,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_07&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   135, 140,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_08&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   140, 145,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_09&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   145, 150,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_10&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   150, 155,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_11&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   155, 160,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AEE_20&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   100, 105,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_21&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   105, 110,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_22&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   110, 115,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_23&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   115, 120,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_24&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   120, 125,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_25&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   125, 130,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_26&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   130, 135,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_27&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   135, 140,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_28&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   140, 145,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_29&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   145, 150,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_30&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   150, 155,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AEE_31&#34;, &#34;Auroral E region, evening sector&#34;,  15, 21,  60, 75,   155, 160,               -90,90,  3, 9,   50*60 ) )

Bins.append( Bin(&#34;AED_00&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   100, 105,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_01&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   105, 110,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_02&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   110, 115,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_03&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   115, 120,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_04&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   120, 125,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_05&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   125, 130,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_06&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   130, 135,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_07&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   135, 140,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_08&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   140, 145,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_09&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   145, 150,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_10&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   150, 155,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_11&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   155, 160,               -90,90,  0, 3,   50*60 ) )
Bins.append( Bin(&#34;AED_20&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   100, 105,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_21&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   105, 110,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_22&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   110, 115,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_23&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   115, 120,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_24&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   120, 125,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_25&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   125, 130,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_26&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   130, 135,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_27&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   135, 140,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_28&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   140, 145,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_29&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   145, 150,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_30&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   150, 155,               -90,90,  3, 9,   50*60 ) )
Bins.append( Bin(&#34;AED_31&#34;, &#34;Auroral E region, dawn sector&#34;,   3,  9,  60, 75,   155, 160,               -90,90,  3, 9,   50*60 ) )
    
Bins.append( Bin(&#34;EEJ_A1&#34;, &#34;Equatorial E-region&#34;,             10, 13,  -7,  7,   115,   127,                -90,90,  0, 9,   10*60 ) )
Bins.append( Bin(&#34;EEJ_A2&#34;, &#34;Equatorial E-region&#34;,             10, 13,  -7,  7,   127,   139,                -90,90,  0, 9,   10*60 ) )
Bins.append( Bin(&#34;EEJ_A3&#34;, &#34;Equatorial E-region&#34;,             10, 13,  -7,  7,   139,   150,                -90,90,  0, 9,   10*60 ) )

Bins.append( Bin(&#34;EPB_A1&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   150, 185,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A2&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   185, 220,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A3&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   220, 255,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A4&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   255, 290,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A5&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   290, 325,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A6&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   325, 360,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A7&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   360, 395,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A8&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   395, 430,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A9&#34;, &#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   430, 465,                  -90,90,  0, 9,   150*60 ) )
Bins.append( Bin(&#34;EPB_A10&#34;,&#34;Equatorial Plasma Bubbles&#34;,       18,  4, -30, 30,   465, 500,                  -90,90,  0, 9,   150*60 ) )

Bins.append( Bin(&#34;SQ_A1&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   150, 185,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A2&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   185, 220,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A3&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   220, 255,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A4&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   255, 290,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A5&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   290, 325,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A6&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   325, 360,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A7&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   360, 395,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A8&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   395, 430,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A9&#34;,  &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   430, 465,                  -90,90,  0, 3,   150*60 ) )
Bins.append( Bin(&#34;SQ_A10&#34;, &#34;Sq &amp; midlat F region currents&#34;,    6, 19, -60, 60,   465, 500,                  -90,90,  0, 3,   150*60 ) )
    
Bins.append( Bin(&#34;CF_L1&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   140, 185,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_L2&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   185, 230,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_L3&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   230, 275,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_L4&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   275, 320,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_L5&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   320, 365,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_L6&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   365, 410,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_L7&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   410, 455,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_L8&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   455, 500,                -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;CF_M1&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   140, 230,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;CF_M2&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   230, 320,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;CF_M3&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   320, 410,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;CF_M4&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   410, 500,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;CF_H1&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   140, 260,               -90,90,  4, 9,   20*60 ) )
Bins.append( Bin(&#34;CF_H2&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   260, 380,               -90,90,  4, 9,   20*60 ) )
Bins.append( Bin(&#34;CF_H3&#34;, &#34;Dayside Cusp F-region&#34;,            10, 14,   70,  80,   380, 500,               -90,90,  4, 9,   20*60 ) )
    
Bins.append( Bin(&#34;PCF_L1&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   140, 185,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_L2&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   185, 230,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_L3&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   230, 275,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_L4&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   275, 320,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_L5&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   320, 365,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_L6&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   365, 410,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_L7&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   410, 455,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_L8&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   455, 500,               -90,90,  0, 2,   50*60 ) )
Bins.append( Bin(&#34;PCF_M1&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   140, 230,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;PCF_M2&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   230, 320,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;PCF_M3&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   320, 410,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;PCF_M4&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   410, 500,               -90,90,  2, 4,   30*60 ) )
Bins.append( Bin(&#34;PCF_H1&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   140, 260,               -90,90,  4, 9,   20*60 ) )
Bins.append( Bin(&#34;PCF_H2&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   260, 380,               -90,90,  4, 9,   20*60 ) )
Bins.append( Bin(&#34;PCF_H3&#34;, &#34;Polar cap F-region&#34;,              14, 10,   70,  90,   380, 500,               -90,90,  4, 9,   20*60 ) )
    
Bins.append( Bin(&#34;TRO_01&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   80,  85,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_02&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   85,  90,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_03&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   90,  95,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_04&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   95, 100,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_05&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  100, 105,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_06&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  105, 110,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_07&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  110, 115,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_08&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  115, 120,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_09&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  120, 125,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_10&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  125, 130,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_11&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  130, 135,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_12&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  135, 140,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_13&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  140, 145,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_14&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  145, 150,                 60,90,  0, 2,   20*60 ) )
Bins.append( Bin(&#34;TRO_15&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   80,  87,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_16&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   87,  94,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_17&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   94, 101,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_18&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  101, 108,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_19&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  108, 115,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_20&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  115, 122,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_21&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  122, 129,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_22&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  129, 136,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_23&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  136, 143,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_24&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,  143, 150,                 60,90,  2, 4,   20*60 ) )
Bins.append( Bin(&#34;TRO_25&#34;, &#34;EISCAT Tromso radar scan region&#34;,  0, 24,  -90,  90,   80, 150,                 60,90,  4, 9,   20*60 ) )
    
#Bins.append( Bin(&#34;TST_00&#34;, &#34;Test region&#34;,                      0, 24,  -90,  90,   80, 150,                 60,90,  0, 9,   20*60 ) )
    

    
    
def ClearBins():
    &#34;&#34;&#34;
        Removes all Bins.
    &#34;&#34;&#34;
    Bins.clear()     

def CreateNewBin( ID, Description, MagneticLocalTime_from, MagneticLocalTime_to, MagneticLatitude_from, MagneticLatitude_to, Altitude_from, Altitude_to, Kp_from, Kp_to, DesirableTime ):
    &#34;&#34;&#34;
        Defines a new Bin according to the specified ranges.
        All satellite positions which fall in these ranges will be assigned to this Bin. 
        The plots will be created according to all the defined Bins.
        The library initializes certain predefined Bins. Call ClearBins() in order to remove them.
        Args:
            ID (string): a code name for this Bin. It will be displayed on the plots.
            Description (string): a description for this Bin. It will be displayed on the plots.
            MagneticLocalTime_from: range for Magnetic-Local-Time of the Bin.
            MagneticLocalTime_to: range for Magnetic-Local-Time of the Bin.
            MagneticLatitude_from: range for Magnetic-Latitude of the Bin.
            MagneticLatitude_to: range for Magnetic-Latitude of the Bin.
            Altitude_from: range for Altitude of the Bin.
            Altitude_to: range for Altitude of the Bin.
            Kp_from: range for Kp-index of the Bin.
            Kp_to: range for Kp-index of the Bin.
            DesirableTime: (seconds) The minimun time for the satellite to stay inside the Bin in order to accomplish its mission.
    &#34;&#34;&#34;
    Bins.append( Bin(ID, Description, MagneticLocalTime_from, MagneticLocalTime_to, MagneticLatitude_from, MagneticLatitude_to, Altitude_from, Altitude_to, Kp_from, Kp_to, DesirableTime) )
    
    
    
    
def getBinDescription( str ):
    &#34;&#34;&#34;
    Tries to identify the bin according to the given argument and returns its description. If it fails it returns the argument.
    examples: &#34;PCF_H2&#34;-&gt;&#34;Polar cap F-region&#34;   &#34;PCF&#34;-&gt;&#34;Polar cap F-region&#34;
    &#34;&#34;&#34;
    result = &#34;&#34;
    for B in Bins:
        if B.ID == str: result = B.Description
    if len(result)==0:
        for B in Bins:
            if B.ID.startswith( str ): result = B.Description
    if len(result)==0: result = str
    #
    return result

def is_MLT_inside_range( MLT, MLT_min, MLT_max ):
    &#34;&#34;&#34;
        Checks if certain Magnetic-Local-Time lies in a certain range. It can handle ranges like 22-2
        Returns:
            true if MLT falls inside [MLT_min, MLT_max]
    &#34;&#34;&#34;
    if MLT_min &lt; MLT_max: # example: from 13 to 18 hour
        return (MLT &gt; MLT_min  and  MLT &lt;= MLT_max)
    elif MLT_min == MLT_max: # example: from 12 until 12 the other day
        return True
    else: # example: from 22 to 3 hour
        return (MLT &gt; MLT_min  or   MLT &lt;= MLT_max)

    
    
def GetMatchedBin( MLT, MagLat, Altitude, Kp, Latitude ):
    &#34;&#34;&#34;
        Finds and returns the Bin object which matches the position of the satellite described by the arguments.
        
        Args:
                MLT: the Magnetic Local Time
                MagLat: The Magnetic Latitude
                Altitude: The Altitude
                Kp: the Kp-index
                Latitude: the Latitude
        Returns:
                Bin: the Bin in which the position represented by the arguments is matched.
    &#34;&#34;&#34;    
    MatchedBin = None
    for B in Bins:
        if Latitude &gt;= B.Lat_min  and  Latitude &lt;= B.Lat_max:
            if is_MLT_inside_range(MLT, B.MLT_min, B.MLT_max):
                if MagLat   &gt; B.MagLat_min    and  MagLat   &lt;= B.MagLat_max:
                    if Altitude &gt; B.Altitude_min  and  Altitude &lt;= B.Altitude_max:
                        Kp_min_to_check = B.Kp_min
                        if Kp_min_to_check == 0: Kp_min_to_check = -1
                        if Kp       &gt; Kp_min_to_check and  Kp       &lt;= B.Kp_max:
                            MatchedBin = B
                            break
    return MatchedBin



def getBinByItsProperties( MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Kp_min, Kp_max ):
    &#34;&#34;&#34;
        Returns: the bin object which has been defined by the same ranges as the arguments
    &#34;&#34;&#34;
    CorrectBin = None
    for B in Bins:
        if             MLT_min      == B.MLT_min       and  MLT_max      == B.MLT_max:
            if         MagLat_min   == B.MagLat_min    and  MagLat_max   == B.MagLat_max:
                if     Altitude_min == B.Altitude_min  and  Altitude_max == B.Altitude_max:
                    if Kp_min       == B.Kp_min        and  Kp_max       == B.Kp_max:
                        CorrectBin = B
                        break
    return CorrectBin

def getBinByItsID( aBinID ):
    &#34;&#34;&#34;
        ReturnsL the Bin object wich has the same ID as the argument
    &#34;&#34;&#34;
    CorrectBin = None
    for B in Bins:
        if  B.ID == aBinID:
            CorrectBin = B
            break
    return CorrectBin




def CreateResults_CDF( ResultsFilename,  CALCULATIONS_Title=&#34;&#34;, CALCULATIONS_Description=&#34;&#34;, CALCULATIONS_RegionName=&#34;&#34;, CALCULATIONS_OrbitFilesPath=&#34;&#34;, CALCULATIONS_TIEGCMfolder=&#34;&#34;):
    &#34;&#34;&#34;
        Creates a results NetCDF file and its structure. The file will contain no date.
        The optional parameters are extra information to be added to the result-file.
        Args: 
            ResultsFilename: the full or relative path and filename to be created.
    &#34;&#34;&#34;
    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values, all_Kp_values, all_Time_values, all_EEX_values, all_EEY_values, all_Pedersen_values, all_Density_values, all_Lev_values, all_Hall_values
    # save general info
    resultsCDF = Dataset( ResultsFilename, &#39;w&#39; )
    resultsCDF.Content         = &#34;JOULE HEATING per BIN RESULTS. This file contains information about the bins in which the thermosphere is divided according to Magnetic Latitude, Magnetic Local Time, Altitude and Kp-index. We say there is a hit inside a bin when a satellite position or TIEGCM-grid position lies inside the above boundaries. The file contains data for each hit inside a bin. That is the position&#39;s MagLat, MLT, Alt, Kp and Joule-Heating value&#34;
    resultsCDF.DateOfCreation  = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
    resultsCDF.DateOfUpdate    = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
    resultsCDF.Title           = CALCULATIONS_Title
    resultsCDF.Region          = CALCULATIONS_RegionName
    resultsCDF.OrbitFile       = CALCULATIONS_OrbitFilesPath
    resultsCDF.Description     = CALCULATIONS_Description
    resultsCDF.DataPath        = CALCULATIONS_TIEGCMfolder
    resultsCDF.LastExecDurationSec = 0
    resultsCDF.Progress        = &#34;&#34;
    # save data for each bin spearately 
    resultsCDF.createDimension( &#34;SingleSpaceFooDimension&#34;, 1 )
    resultsCDF.createDimension(&#39;char8&#39;, 8)
    for B in Bins:
        # save general info about the bin
        VAR_BinInfo = resultsCDF.createVariable( B.ID, &#34;S1&#34;, (&#34;SingleSpaceFooDimension&#34;,) )
        VAR_BinInfo.long_name    = &#34;Information about the bin &#34; + B.ID + &#34; (&#34; + B.Description + &#34;)&#34;
        VAR_BinInfo.MagLat_min   = &#34;{:02.0f}&#34;.format(B.MagLat_min)
        VAR_BinInfo.MagLat_max   = &#34;{:02.0f}&#34;.format(B.MagLat_max)
        VAR_BinInfo.MLT_min      = &#34;{:02.0f}&#34;.format(B.MLT_min)
        VAR_BinInfo.MLT_max      = &#34;{:02.0f}&#34;.format(B.MLT_max)
        VAR_BinInfo.Altitude_min = &#34;{:02.0f}&#34;.format(B.Altitude_min)
        VAR_BinInfo.Altitude_max = &#34;{:02.0f}&#34;.format(B.Altitude_max)
        VAR_BinInfo.Lat_min       = &#34;{:02.0f}&#34;.format(B.Lat_min)
        VAR_BinInfo.Lat_max       = &#34;{:02.0f}&#34;.format(B.Lat_max)
        VAR_BinInfo.Kp_min       = &#34;{:02.0f}&#34;.format(B.Kp_min)
        VAR_BinInfo.Kp_max       = &#34;{:02.0f}&#34;.format(B.Kp_max)
        VAR_BinInfo.JH_mean      = &#34;{:.3e}&#34;.format(B.JH_mean)
        VAR_BinInfo.JH_variance  = &#34;{:.3e}&#34;.format(B.JH_variance)
        VAR_BinInfo.DesirableCumulativeTime = str(B.DesirableCumulativeTime) + &#34;sec&#34;
        if B.JH_min == 99999: 
            VAR_BinInfo.JH_min = &#34;&#34;
        else:
            VAR_BinInfo.JH_min = &#34;{:.3e}&#34;.format(B.JH_min)
        # create structure for each bin
        resultsCDF.createDimension( B.ID+&#34;_time_dim&#34;, None )
        VAR_BinTimeValues             = resultsCDF.createVariable( B.ID+&#34;_TimeValues&#34;, &#34;f4&#34;, (B.ID+&#34;_time_dim&#34;,) )
        VAR_BinTimeValues.description = &#34;UTC timestamp&#34;
        VAR_BinTimeValues.units       = &#34;seconds&#34;
        resultsCDF.createDimension( B.ID+&#34;_jh_dim&#34;, None )
        VAR_BinJHvalues = resultsCDF.createVariable( B.ID+&#34;_JHValues&#34;, &#34;f4&#34;, (B.ID+&#34;_jh_dim&#34;,) )
        VAR_BinJHvalues.description = &#34;Ohmic&#34;
        VAR_BinJHvalues.units       = &#34;W/m3&#34;
        resultsCDF.createDimension( B.ID+&#34;_maglat_dim&#34;, None )
        VAR_BinMagLatValues = resultsCDF.createVariable( B.ID+&#34;_MagLatValues&#34;, &#34;f4&#34;, (B.ID+&#34;_maglat_dim&#34;,) )
        VAR_BinMagLatValues.description = &#34;Magnetic Latitude&#34;
        VAR_BinMagLatValues.units       = &#34;degrees&#34;
        resultsCDF.createDimension( B.ID+&#34;_mlt_dim&#34;, None )
        VAR_BinMLTValues = resultsCDF.createVariable( B.ID+&#34;_MLTValues&#34;, &#34;f4&#34;, (B.ID+&#34;_mlt_dim&#34;,) )
        VAR_BinMLTValues.description = &#34;Magnetic Local Time&#34;
        VAR_BinMLTValues.units       = &#34;hours&#34;
        resultsCDF.createDimension( B.ID+&#34;_alt_dim&#34;, None )
        VAR_BinAltitudeValues = resultsCDF.createVariable( B.ID+&#34;_AltitudeValues&#34;, &#34;f4&#34;, (B.ID+&#34;_alt_dim&#34;,) )
        VAR_BinAltitudeValues.description = &#34;Altitude from the surface of the Earth&#34;
        VAR_BinAltitudeValues.units       = &#34;km&#34;
        resultsCDF.createDimension( B.ID+&#34;_lat_dim&#34;, None )
        VAR_BinLatValues = resultsCDF.createVariable( B.ID+&#34;_LatValues&#34;, &#34;f4&#34;, (B.ID+&#34;_lat_dim&#34;,) )
        VAR_BinLatValues.description = &#34;Latitude&#34;
        VAR_BinLatValues.units       = &#34;degrees&#34;
        resultsCDF.createDimension( B.ID+&#34;_kp_dim&#34;, None )
        VAR_BinKpValues = resultsCDF.createVariable( B.ID+&#34;_KpValues&#34;, &#34;f4&#34;, (B.ID+&#34;_kp_dim&#34;,) )
        VAR_BinKpValues.description = &#34;Kp index of Sun activity&#34;
        VAR_BinKpValues.units       = &#34;-&#34;
        resultsCDF.createDimension( B.ID+&#34;_eex_dim&#34;, None )
        VAR_BinEEXValues = resultsCDF.createVariable( B.ID+&#34;_EEXValues&#34;, &#34;f4&#34;, (B.ID+&#34;_eex_dim&#34;,) )
        VAR_BinEEXValues.description = &#34;Electric field strength East. (SI)&#34;
        VAR_BinEEXValues.units       = &#34;V/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_eey_dim&#34;, None )
        VAR_BinEEYValues = resultsCDF.createVariable( B.ID+&#34;_EEYValues&#34;, &#34;f4&#34;, (B.ID+&#34;_eey_dim&#34;,) )
        VAR_BinEEYValues.description = &#34;Electric field strength North. (SI)&#34;
        VAR_BinEEYValues.units       = &#34;V/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_ped_dim&#34;, None )
        VAR_BinPedersenValues = resultsCDF.createVariable( B.ID+&#34;_PedersenValues&#34;, &#34;f4&#34;, (B.ID+&#34;_ped_dim&#34;,) )
        VAR_BinPedersenValues.description = &#34;SIGMA_PED&#34;
        VAR_BinPedersenValues.units       = &#34;S/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_den_dim&#34;, None )
        VAR_BinDensityValues = resultsCDF.createVariable( B.ID+&#34;_DensityValues&#34;, &#34;f4&#34;, (B.ID+&#34;_den_dim&#34;,) )
        VAR_BinDensityValues.description = &#34;Total Density&#34;
        VAR_BinDensityValues.units       = &#34;g/cm3&#34;
        resultsCDF.createDimension( B.ID+&#34;_lev_dim&#34;, None )
        VAR_BinLevValues = resultsCDF.createVariable( B.ID+&#34;_LevValues&#34;, &#34;f4&#34;, (B.ID+&#34;_lev_dim&#34;,) )
        VAR_BinLevValues.description = &#34;midpoint levels&#34;
        VAR_BinLevValues.units       = &#34;&#34;
        resultsCDF.createDimension( B.ID+&#34;_hal_dim&#34;, None )
        VAR_BinHallValues = resultsCDF.createVariable( B.ID+&#34;_HallValues&#34;, &#34;f4&#34;, (B.ID+&#34;_hal_dim&#34;,) )
        VAR_BinHallValues.description = &#34;SIGMA_HAL&#34;
        VAR_BinHallValues.units       = &#34;S/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_convh_dim&#34;, None )
        VAR_BinConvhValues = resultsCDF.createVariable( B.ID+&#34;_ConvectionHeatingValues&#34;, &#34;f4&#34;, (B.ID+&#34;_convh_dim&#34;,) )
        VAR_BinConvhValues.description = &#34;Convection Heating&#34;
        VAR_BinConvhValues.units       = &#34;W/m3&#34;
        resultsCDF.createDimension( B.ID+&#34;_windh_dim&#34;, None )
        VAR_BinWindhValues = resultsCDF.createVariable( B.ID+&#34;_WindHeatingValues&#34;, &#34;f4&#34;, (B.ID+&#34;_windh_dim&#34;,) )
        VAR_BinWindhValues.description = &#34;Wind Correction&#34;
        VAR_BinWindhValues.units       = &#34;W/m3&#34;
    ## save data for all hits
    resultsCDF.createDimension( &#34;time_dim&#34;, None )
    VAR_TimeValues         = resultsCDF.createVariable(&#34;allTimeValues&#34;, &#34;f4&#34;, (&#34;time_dim&#34;,) )
    VAR_TimeValues.description = &#34;UTC timestamp&#34;
    VAR_TimeValues.units       = &#34;seconds&#34;
    resultsCDF.createDimension( &#34;jh_dim&#34;, None )
    VAR_JHvalues = resultsCDF.createVariable(&#34;allJHValues&#34;, &#34;f4&#34;, (&#34;jh_dim&#34;,) )
    VAR_JHvalues.description = &#34;Ohmic&#34;
    VAR_JHvalues.units       = &#34;W/m3&#34;
    resultsCDF.createDimension( &#34;maglat_dim&#34;, None )
    VAR_MagLatValues = resultsCDF.createVariable(&#34;allMagLatValues&#34;, &#34;f4&#34;, (&#34;maglat_dim&#34;,) )
    VAR_MagLatValues.description = &#34;Magnetic Latitude&#34;
    VAR_MagLatValues.units       = &#34;degrees&#34;
    resultsCDF.createDimension( &#34;mlt_dim&#34;, None )
    VAR_MLTValues = resultsCDF.createVariable(&#34;allMLTValues&#34;, &#34;f4&#34;, (&#34;mlt_dim&#34;,) )
    VAR_MLTValues.description = &#34;Magnetic Local Time&#34;
    VAR_MLTValues.units       = &#34;hours&#34;
    resultsCDF.createDimension( &#34;alt_dim&#34;, None )
    VAR_AltitudeValues = resultsCDF.createVariable(&#34;allAltitudeValues&#34;, &#34;f4&#34;, (&#34;alt_dim&#34;,) )
    VAR_AltitudeValues.description = &#34;Altitude from the surface of the Earth&#34;
    VAR_AltitudeValues.units       = &#34;km&#34;
    resultsCDF.createDimension( &#34;lat_dim&#34;, None )
    VAR_LatValues = resultsCDF.createVariable(&#34;allLatValues&#34;, &#34;f4&#34;, (&#34;lat_dim&#34;,) )
    VAR_LatValues.description = &#34;Latitude&#34;
    VAR_LatValues.units       = &#34;degrees&#34;
    resultsCDF.createDimension( &#34;kp_dim&#34;, None )
    VAR_KpValues = resultsCDF.createVariable(&#34;allKpValues&#34;, &#34;f4&#34;, (&#34;kp_dim&#34;,) )
    VAR_KpValues.description = &#34;Kp index of Sun activity&#34;
    VAR_KpValues.units       = &#34;-&#34;
    resultsCDF.createDimension( &#34;bins_dim&#34;, None )
    VAR_HittedBinIDs = resultsCDF.createVariable(&#34;allHittedBinIDs&#34;, &#34;S1&#34;, (&#34;bins_dim&#34;,&#34;char8&#34;,) )
    VAR_HittedBinIDs.description = &#34;The ID of the bin, where the hit occured&#34;
    resultsCDF.createDimension( &#34;eex_dim&#34;, None )
    VAR_EEXvalues = resultsCDF.createVariable(&#34;allEEXValues&#34;, &#34;f4&#34;, (&#34;eex_dim&#34;,) )
    VAR_EEXvalues.description = &#34;Electric field strength East. (SI)&#34;
    VAR_EEXvalues.units       = &#34;V/m&#34;
    resultsCDF.createDimension( &#34;eey_dim&#34;, None )
    VAR_EEYvalues = resultsCDF.createVariable(&#34;allEEYValues&#34;, &#34;f4&#34;, (&#34;eey_dim&#34;,) )
    VAR_EEYvalues.description = &#34;Electric field strength North. (SI)&#34;
    VAR_EEYvalues.units       = &#34;V/m&#34;
    resultsCDF.createDimension( &#34;ped_dim&#34;, None )
    VAR_Pedersenvalues = resultsCDF.createVariable(&#34;allPedersenValues&#34;, &#34;f4&#34;, (&#34;ped_dim&#34;,) )
    VAR_Pedersenvalues.description = &#34;Pedersen Conductivity&#34;
    VAR_Pedersenvalues.units       = &#34;S/m&#34;
    resultsCDF.createDimension( &#34;den_dim&#34;, None )
    VAR_Densityvalues = resultsCDF.createVariable(&#34;allDensityValues&#34;, &#34;f4&#34;, (&#34;den_dim&#34;,) )
    VAR_Densityvalues.description = &#34;Total Density&#34;
    VAR_Densityvalues.units       = &#34;g/cm3&#34;
    resultsCDF.createDimension( &#34;lev_dim&#34;, None )
    VAR_LevValues = resultsCDF.createVariable(&#34;allLevValues&#34;, &#34;f4&#34;, (&#34;lev_dim&#34;,) )
    VAR_LevValues.description = &#34;midpoint levels&#34;
    VAR_LevValues.units       = &#34;&#34;
    resultsCDF.createDimension( &#34;hal_dim&#34;, None )
    VAR_Hallvalues = resultsCDF.createVariable(&#34;allHallValues&#34;, &#34;f4&#34;, (&#34;hal_dim&#34;,) )
    VAR_Hallvalues.description = &#34;Hall Conductivity&#34;
    VAR_Hallvalues.units       = &#34;S/m&#34;
    resultsCDF.createDimension( &#34;convh_dim&#34;, None )
    VAR_ConvhValues = resultsCDF.createVariable(&#34;allConvectionHeatingValues&#34;, &#34;f4&#34;, (&#34;convh_dim&#34;,) )
    VAR_ConvhValues.description = &#34;Convection Heating&#34;
    VAR_ConvhValues.units       = &#34;W/m3&#34;
    resultsCDF.createDimension( &#34;windh_dim&#34;, None )
    VAR_WindhValues = resultsCDF.createVariable(&#34;allWindHeatingValues&#34;, &#34;f4&#34;, (&#34;windh_dim&#34;,) )
    VAR_WindhValues.description = &#34;Wind Correction&#34;
    VAR_WindhValues.units       = &#34;W/m3&#34;
    resultsCDF.close()
    
    
def SaveResults_CDF( ResultsFilename, DataFilename ):
    &#34;&#34;&#34;
    Append the results in a NetCDF file which can contain results of several calculations.
    The data will be saved in ResultsFilename and they come from calculations on the netcdf DataFilename.
    DataFilename is needed to check if the file contains already the results of calculations on that file.
    
        Args: 
            ResultsFilename: the netcdf file where the results will be stored.
            DataFilename: the netcdf file (with orbit or tiegcm data ) on which the calculation have taken place. 
    &#34;&#34;&#34;
    if path.exists( ResultsFilename ) == False:
        CreateResults_CDF( ResultsFilename )
    # save general info
    ErrorMsg = &#34;&#34;
    resultsCDF = Dataset( ResultsFilename, &#39;a&#39; )
    resultsCDF.DateOfUpdate = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
    if resultsCDF.Region    != CALCULATIONS_RegionName: ErrorMsg = &#34;Save aborted: NetCDF file has already data about region &#34; + resultsCDF.Region + &#34; and you tried to save data about region &#34; + CALCULATIONS_RegionName        
    if resultsCDF.OrbitFile != CALCULATIONS_OrbitFilesPath: ErrorMsg = &#34;Save aborted: NetCDF file has already data about orbit &#34; + resultsCDF.OrbitFile + &#34; and you tried to save data about orbit &#34; + DataFilename
    if resultsCDF.DataPath  != CALCULATIONS_TIEGCMfolder: ErrorMsg = &#34;Save aborted: NetCDF file has already data about TIEGCM file &#34; + resultsCDF.DataPath  + &#34;and you tried to save data about TIEGCM file &#34; + CALCULATIONS_TIEGCMfolder        
    if len(DataFilename)&gt;0 and resultsCDF.Progress &gt; DataFilename: ErrorMsg = &#34;Save aborted: NetCDF file contains data about file: &#34; + resultsCDF.Progress + &#34; which is later than &#34; + DataFilename
    if len(ErrorMsg) &gt; 0:
        print( ErrorMsg )
        resultsCDF.close()
        return
    resultsCDF.LastExecDurationSec = ConvertLeadingZerosToSpaces(&#34;{0:.0f}&#34;.format(CALCULATIONS_ExecutionDuration)).strip()
    # save data for each bin spearately 
    for B in Bins:
        # save data about the hits inside the bin
        if len(B.Time_values) &gt; 0:
            resultsCDF.variables[B.ID+&#34;_TimeValues&#34;][:]      = resultsCDF.variables[B.ID+&#34;_TimeValues&#34;][:].tolist() + B.Time_values
            resultsCDF.variables[B.ID+&#34;_JHValues&#34;][:]        = resultsCDF.variables[B.ID+&#34;_JHValues&#34;][:].tolist() + B.JH_values        
            resultsCDF.variables[B.ID+&#34;_MagLatValues&#34;][:]    = resultsCDF.variables[B.ID+&#34;_MagLatValues&#34;][:].tolist() + B.MagLat_values
            resultsCDF.variables[B.ID+&#34;_MLTValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_MLTValues&#34;][:].tolist() + B.MLT_values
            resultsCDF.variables[B.ID+&#34;_AltitudeValues&#34;][:]  = resultsCDF.variables[B.ID+&#34;_AltitudeValues&#34;][:].tolist() + B.Altitude_values
            resultsCDF.variables[B.ID+&#34;_LatValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_LatValues&#34;][:].tolist() + B.Lat_values
            resultsCDF.variables[B.ID+&#34;_KpValues&#34;][:]        = resultsCDF.variables[B.ID+&#34;_KpValues&#34;][:].tolist() + B.Kp_values
            resultsCDF.variables[B.ID+&#34;_EEXValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_EEXValues&#34;][:].tolist() + B.EEX_values        
            resultsCDF.variables[B.ID+&#34;_EEYValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_EEYValues&#34;][:].tolist() + B.EEY_values
            resultsCDF.variables[B.ID+&#34;_PedersenValues&#34;][:]  = resultsCDF.variables[B.ID+&#34;_PedersenValues&#34;][:].tolist() + B.Pedersen_values
            resultsCDF.variables[B.ID+&#34;_DensityValues&#34;][:]   = resultsCDF.variables[B.ID+&#34;_DensityValues&#34;][:].tolist() + B.Density_values
            resultsCDF.variables[B.ID+&#34;_LevValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_LevValues&#34;][:].tolist() + B.Lev_values
            resultsCDF.variables[B.ID+&#34;_HallValues&#34;][:]      = resultsCDF.variables[B.ID+&#34;_HallValues&#34;][:].tolist() + B.Hall_values
            resultsCDF.variables[B.ID+&#34;_ConvectionHeatingValues&#34;][:] = resultsCDF.variables[B.ID+&#34;_ConvectionHeatingValues&#34;][:].tolist() + B.ConvectionHeating_values
            resultsCDF.variables[B.ID+&#34;_WindHeatingValues&#34;][:] = resultsCDF.variables[B.ID+&#34;_WindHeatingValues&#34;][:].tolist() + B.WindHeating_values
    ## save data for all hits
    if len(all_Time_values) &gt; 0:
        resultsCDF.variables[&#34;allTimeValues&#34;][:]     = resultsCDF.variables[&#34;allTimeValues&#34;][:].tolist() + all_Time_values
        resultsCDF.variables[&#34;allJHValues&#34;][:]       = resultsCDF.variables[&#34;allJHValues&#34;][:].tolist() + all_JH_values    
        resultsCDF.variables[&#34;allMagLatValues&#34;][:]   = resultsCDF.variables[&#34;allMagLatValues&#34;][:].tolist() + all_MagLat_values
        resultsCDF.variables[&#34;allMLTValues&#34;][:]      = resultsCDF.variables[&#34;allMLTValues&#34;][:].tolist() + all_MLT_values
        resultsCDF.variables[&#34;allAltitudeValues&#34;][:] = resultsCDF.variables[&#34;allAltitudeValues&#34;][:].tolist() + all_Altitude_values
        resultsCDF.variables[&#34;allLatValues&#34;][:]      = resultsCDF.variables[&#34;allLatValues&#34;][:].tolist() + all_Lat_values
        resultsCDF.variables[&#34;allKpValues&#34;][:]       = resultsCDF.variables[&#34;allKpValues&#34;][:].tolist() + all_Kp_values
        #resultsCDF.variables[&#34;allHittedBinIDs&#34;][:]   = resultsCDF.variables[&#34;allHittedBinIDs&#34;][:].tolist() + netCDF4.stringtochar(np.array(all_HittedBin_IDs[:], &#39;S8&#39;))
        resultsCDF.variables[&#34;allEEXValues&#34;][:]      = resultsCDF.variables[&#34;allEEXValues&#34;][:].tolist() + all_EEX_values
        resultsCDF.variables[&#34;allEEYValues&#34;][:]      = resultsCDF.variables[&#34;allEEYValues&#34;][:].tolist() + all_EEY_values
        resultsCDF.variables[&#34;allPedersenValues&#34;][:] = resultsCDF.variables[&#34;allPedersenValues&#34;][:].tolist() + all_Pedersen_values
        resultsCDF.variables[&#34;allDensityValues&#34;][:]  = resultsCDF.variables[&#34;allDensityValues&#34;][:].tolist() + all_Density_values
        resultsCDF.variables[&#34;allLevValues&#34;][:]      = resultsCDF.variables[&#34;allLevValues&#34;][:].tolist() + all_Lev_values
        resultsCDF.variables[&#34;allHallValues&#34;][:]     = resultsCDF.variables[&#34;allHallValues&#34;][:].tolist() + all_Hall_values
        resultsCDF.variables[&#34;allConvectionHeatingValues&#34;][:] = resultsCDF.variables[&#34;allConvectionHeatingValues&#34;][:].tolist() + all_ConvectionHeating_values
        resultsCDF.variables[&#34;allWindHeatingValues&#34;][:] = resultsCDF.variables[&#34;allWindHeatingValues&#34;][:].tolist() + all_WindHeating_values
    #
    resultsCDF.close()    
    



    


def LoadResults_CDF( filepath, VariableToLoad, loadBinValues=True, loadGlobalValues=True, loadTimeValues=True, loadMagLatValues=True, loadMLTvalues=True, loadAltValues=True, loadLatValues=True, loadKpValues=True ):
    &#34;&#34;&#34;
    Reads the calculation results from a netcdf result-file and fills with data the corresponding Bins.
    User must choose a Variable to work with (see start of this module for available variables).
    User can choose which other parallel data to load in order to produce the plots he is interested in, in order to speed up loading
        
        Args: 
             filepath: the netcdf result-file to be loaded
             VariableToLoad: the variable which the user is interested in. Only data about this variable will be loaded
    &#34;&#34;&#34;
    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration
    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values, all_Kp_values, all_Time_values, all_EEX_values, all_EEY_values, all_Pedersen_values, all_Density_values, all_Lev_values, all_Hall_values

    # reset values
    for B in Bins:
        B.reset()
    all_JH_values.clear()
    all_MagLat_values.clear()
    all_MLT_values.clear()
    all_Altitude_values.clear()
    all_Lat_values.clear()
    all_Kp_values.clear() 
    all_Time_values.clear()
    all_HittedBin_IDs.clear()
    all_EEX_values.clear()
    all_EEY_values.clear()
    all_Pedersen_values.clear()
    all_Density_values.clear()
    all_Lev_values.clear()
    all_Hall_values.clear()
    all_ConvectionHeating_values.clear()
    all_WindHeating_values.clear()
    
    print( &#34;Started Loading&#34;, filepath, datetime.now() )

    # make a list of all the files we are going to load
    All_ResultFilenames = list()
    if filepath[-1] == &#39;/&#39;:
        All_ResultFilenames = sorted( glob.glob(filepath+&#34;*.nc&#34;) )
    else:
        All_ResultFilenames.append( filepath )
    
    # load each file into memory
    for file_idx in range(0, len(All_ResultFilenames)):
        if file_idx % 10 == 0: print( &#34;Now Loading&#34;, All_ResultFilenames[file_idx] )
        #if file_idx == 30: break
        resultsCDF = Dataset( All_ResultFilenames[file_idx], &#39;r&#39; )
        #### load general information
        if file_idx == 0:
            try:
                print( &#34;DateOfCreation:&#34;, resultsCDF.DateOfCreation, &#34; LastExecDurationSec :&#34;, resultsCDF.LastExecDurationSec , &#34;sec&#34; )
                #print( &#34;Title:&#34;, resultsCDF.Title, &#34; Description:&#34;, resultsCDF.Description )
                print( &#34;Region:&#34;, resultsCDF.Region )
                print( &#34;OrbitFile:&#34;, resultsCDF.OrbitFile )
                print( &#34;TIEGCM data path:&#34;, resultsCDF.DataPath, &#34;\n&#34; )
                #print( &#34;Progress:&#34;, resultsCDF.Progress, &#34;\n&#34; )
            except:
                pass
            CALCULATIONS_Title = resultsCDF.Title
            CALCULATIONS_Description = resultsCDF.Description
            #CALCULATIONS_ExecutionDuration = resultsCDF.LastExecDurationSec
            CALCULATIONS_RegionName = resultsCDF.Region
            CALCULATIONS_OrbitFilesPath = resultsCDF.OrbitFile.split()
            CALCULATIONS_TIEGCMfolder = resultsCDF.DataPath
        #### load data for each bin
        if loadBinValues:
            for B in Bins:
                try:
                    if loadTimeValues and len(CALCULATIONS_OrbitFilesPath) &gt; 0: concatLists( B.Time_values, list(resultsCDF.variables[ B.ID+&#34;_TimeValues&#34; ][:]) )
                    if loadMagLatValues: concatLists( B.MagLat_values, list(resultsCDF.variables[ B.ID+&#34;_MagLatValues&#34; ][:]) )
                    if loadMLTvalues: concatLists( B.MLT_values, list(resultsCDF.variables[ B.ID+&#34;_MLTValues&#34; ][:]) )
                    if loadAltValues: concatLists( B.Altitude_values, list(resultsCDF.variables[ B.ID+&#34;_AltitudeValues&#34; ][:]) )
                    try:
                        if loadLatValues: concatLists(B.Lat_values, list(resultsCDF.variables[ B.ID+&#34;_LatValues&#34; ][:]) )
                    except:
                        pass
                    if loadKpValues: concatLists(B.Kp_values, list(resultsCDF.variables[ B.ID+&#34;_KpValues&#34; ][:]) )
                    if VariableToLoad == &#34;Ohmic&#34;:    
                        Ohmics = resultsCDF.variables[ B.ID+&#34;_ConvectionHeatingValues&#34; ][:] + resultsCDF.variables[ B.ID+&#34;_WindHeatingValues&#34; ][:]
                        concatLists( B.JH_values, list(Ohmics) ) #    if VariableToLoad == &#34;Ohmic&#34;:     concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_ConvenctionHeatingValues&#34; ][:]+resultsCDF.variables[ B.ID+&#34;_WindHeatingValues&#34; ][:]) )
                    if VariableToLoad == &#34;EEX&#34;:    concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_EEXValues&#34; ][:])*1000 ) #if VariableToLoad == &#34;EEX_si&#34;:    B.EEX_values = list(resultsCDF.variables[ B.ID+&#34;_EEXValues&#34; ][:])
                    if VariableToLoad == &#34;EEY&#34;:    concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_EEYValues&#34; ][:])*1000 ) #if VariableToLoad == &#34;EEY_si&#34;:    B.EEY_values = list(resultsCDF.variables[ B.ID+&#34;_EEYValues&#34; ][:])
                    if VariableToLoad == &#34;SIGMA_PED&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_PedersenValues&#34; ][:]) ) #if VariableToLoad == &#34;SIGMA_PED&#34;: B.Pedersen_values = list(resultsCDF.variables[ B.ID+&#34;_PedersenValues&#34; ][:])
                    if VariableToLoad == &#34;SIGMA_HAL&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_HallValues&#34; ][:]) ) #if VariableToLoad == &#34;SIGMA_HAL&#34;: B.Hall_values = list(resultsCDF.variables[ B.ID+&#34;_HallValues&#34; ][:])
                    try:
                        if VariableToLoad == &#34;Convection_heating&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_ConvectionHeatingValues&#34; ][:]) )
                    except:
                        if VariableToLoad == &#34;Convection_heating&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_ConvenctionHeatingValues&#34; ][:]) )
                    if VariableToLoad == &#34;Wind_heating&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_WindHeatingValues&#34; ][:]) )
                except: # data about this region do not exist inside this netcdf file
                    continue
        #### load collective data about all bins
        if loadGlobalValues:
            if loadTimeValues and len(CALCULATIONS_OrbitFilesPath) &gt; 0: concatLists( all_Time_values, list(resultsCDF.variables[ &#34;allTimeValues&#34; ][:]) )
            if loadMagLatValues:  concatLists( all_MagLat_values, list(resultsCDF.variables[ &#34;allMagLatValues&#34; ][:]) )
            if loadMLTvalues: concatLists( all_MLT_values, list(resultsCDF.variables[ &#34;allMLTValues&#34; ][:]) )
            if loadAltValues: concatLists( all_Altitude_values, list(resultsCDF.variables[ &#34;allAltitudeValues&#34; ][:]) )
            try:
                if loadLatValues: concatLists( all_Lat_values, list(resultsCDF.variables[ &#34;allLatValues&#34; ][:]) )
            except:
                pass
            if loadKpValues: concatLists( all_Kp_values, list(resultsCDF.variables[ &#34;allKpValues&#34; ][:]) )
            if VariableToLoad == &#34;Ohmic&#34;: 
                Ohmics = resultsCDF.variables[ &#34;allConvectionHeatingValues&#34; ][:] + resultsCDF.variables[ &#34;allWindHeatingValues&#34; ][:]
                concatLists( all_JH_values, list(Ohmics) ) #if VariableToLoad == &#34;Ohmic&#34;:     concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allConvenctionHeatingValues&#34; ][:] + resultsCDF.variables[ &#34;allWindHeatingValues&#34; ][:]) )
            if VariableToLoad == &#34;EEX&#34;:    concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allEEXValues&#34; ][:]*1000) )#if VariableToLoad == &#34;EEX_si&#34;:    all_EEX_values = list(resultsCDF.variables[ &#34;allEEXValues&#34; ][:])
            if VariableToLoad == &#34;EEY&#34;:    concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allEEYValues&#34; ][:]*1000) )#if VariableToLoad == &#34;EEY_si&#34;:    all_EEY_values = list(resultsCDF.variables[ &#34;allEEYValues&#34; ][:])
            if VariableToLoad == &#34;SIGMA_PED&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allPedersenValues&#34; ][:]) )#if VariableToLoad == &#34;SIGMA_PED&#34;: all_Pedersen_values = list(resultsCDF.variables[ &#34;allPedersenValues&#34; ][:])
            if VariableToLoad == &#34;SIGMA_HAL&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allHallValues&#34; ][:]) )#if VariableToLoad == &#34;SIGMA_HAL&#34;: all_Hall_values = list(resultsCDF.variables[ &#34;allHallValues&#34; ][:])
            if VariableToLoad == &#34;JH/mass&#34;:   concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allJHValues&#34; ][:]/(1000*resultsCDF.variables[ &#34;allDensityValues&#34; ][:]) ) )
            if VariableToLoad == &#34;JH/pressure&#34;: 
                #newVals = np.zeros( len(resultsCDF.variables[ &#34;allJHValues&#34; ]) )
                #for i in range( 0, len(resultsCDF.variables[ &#34;allJHValues&#34; ]) ):
                #    newVals[i] = resultsCDF.variables[ &#34;allJHValues&#34; ][i]/(0.00005*math.exp(-resultsCDF.variables[ &#34;allLevValues&#34; ][i]) )  
                #concatLists( all_JH_values, list(newVals) )
                #print( &#34;QQQQ &#34;, resultsCDF.variables[ &#34;allJHValues&#34; ][1], resultsCDF.variables[ &#34;allJHValues&#34; ][1000] )
                #print( &#34;QQQQ &#34;, resultsCDF.variables[ &#34;allAltitudeValues&#34; ][1],  resultsCDF.variables[ &#34;allAltitudeValues&#34; ][1000] )
                concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allJHValues&#34; ][:]/(0.00005*np.exp(-resultsCDF.variables[ &#34;allLevValues&#34; ][:]) ) ) )
            try:
                if VariableToLoad == &#34;Convection_heating&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allConvectionHeatingValues&#34; ][:]) )
            except:
                if VariableToLoad == &#34;Convection_heating&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allConvenctionHeatingValues&#34; ][:]) )
            if VariableToLoad == &#34;Wind_heating&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allWindHeatingValues&#34; ][:]) )
        #### close and go on
        resultsCDF.close()
    ########
    
    # !!!! remove incorrect huge or negative Ohmic values
    if (VariableToLoad == &#34;Ohmic&#34;)  and  (&#34;Hz&#34; in filepath or &#34;Tri&#34; in filepath):
        # for each bin
        for B in Bins:
            if len(B.JH_values): print(B.ID, &#34;LENGTH BEFORE:&#34;, len(B.JH_values))
            huge_values = 0
            negative_values = 0
            nan_values = 0
            found_at_current_round = True
            while found_at_current_round:
                found_at_current_round = False
                for t in range(0, len(B.JH_values)):
                    if B.JH_values[t] &gt; 100 or B.JH_values[t] == float(&#34;inf&#34;):  huge_values += 1
                    if B.JH_values[t] &lt; 0   or B.JH_values[t] == float(&#34;-inf&#34;): negative_values += 1
                    if np.isnan(B.JH_values[t]): nan_values += 1
                    if B.JH_values[t]&gt;100 or B.JH_values[t]&lt;0 or np.isnan(B.JH_values[t]) or B.JH_values[t]==float(&#34;inf&#34;) or B.JH_values[t]==float(&#34;-inf&#34;):
                        found_at_current_round = True
                        del B.JH_values[t]
                        if len(B.Time_values) &gt; 0: del B.Time_values[t]
                        if len(B.MagLat_values) &gt; 0: del B.MagLat_values[t]
                        if len(B.MLT_values) &gt; 0: del B.MLT_values[t]
                        if len(B.Altitude_values) &gt; 0: del B.Altitude_values[t]
                        if len(B.Lat_values) &gt; 0: del B.Lat_values[t]
                        if len(B.Kp_values) &gt; 0: del B.Kp_values[t]
                        break
            if len(B.JH_values): print( B.ID, &#34;:&#34;,  &#34;huge values =&#34;, huge_values, &#34;negative values =&#34;, negative_values, &#34;nan values =&#34;, nan_values )
            if len(B.JH_values): print(B.ID, &#34;LENGTH AFTER:&#34;, len(B.JH_values))
        # for arrays with all the data
        print(&#34;ALL&#34;, &#34;LENGTH BEFORE:&#34;, len(all_JH_values))
        huge_values = 0
        negative_values = 0
        nan_values = 0
        found_at_current_round = True
        while found_at_current_round:
            found_at_current_round = False
            for t in range(0, len(all_JH_values)):
                if all_JH_values[t] &gt; 100 or all_JH_values[t] == float(&#34;inf&#34;):  huge_values += 1
                if all_JH_values[t] &lt; 0   or all_JH_values[t] == float(&#34;-inf&#34;): negative_values += 1
                if np.isnan(all_JH_values[t]): nan_values += 1
                if all_JH_values[t]&gt;100 or all_JH_values[t]&lt;0 or np.isnan(all_JH_values[t]) or all_JH_values[t]==float(&#34;inf&#34;) or all_JH_values[t]==float(&#34;-inf&#34;):
                    found_at_current_round = True
                    del all_JH_values[t]
                    if len(all_Time_values) &gt; 0: del all_Time_values[t]
                    if len(all_MagLat_values) &gt; 0: del all_MagLat_values[t]
                    if len(all_MLT_values) &gt; 0: del all_MLT_values[t]
                    if len(all_Altitude_values) &gt; 0: del all_Altitude_values[t]
                    if len(all_Lat_values) &gt; 0: del all_Lat_values[t]
                    if len(all_Kp_values) &gt; 0: del all_Kp_values[t]
                    break
        #print( &#34;Globaly&#34;, &#34;:&#34;,  &#34;huge values =&#34;, huge_values, &#34;negative values =&#34;, negative_values, &#34;nan values =&#34;, nan_values )
        #print(&#34;ALL&#34;, &#34;LENGTH AFTER:&#34;, len(all_JH_values))
    else:
        pass
        #print( &#34;NO correct value check:&#34;, VariableToLoad , filepath )
    ########
    CalculateStatsOnData()
    print( &#34;Results loaded for&#34;, VariableToLoad, &#34;    &#34;, datetime.now(), &#34;\n&#34; )

    
    
    
    

    
    
    
    
    
    
###########################################################################################################################
############################# CALCULATIONS ################################################################################
###########################################################################################################################
















def AssignJouleHeatingValuesToBins_AlongOrbit( TIEGCM_filesPath, Orbit_filesPath, ResultsFilename ): 
    &#34;&#34;&#34;
        Reads the orbit positions and fills the correct Bin with values for each position.
        
        Args:
            TIEGCM_filesPath: the folder which has all TIEGCM netcdf files. Needed to read the Kp index for each satellite position.
            Orbit_filesPath: the folder which has the netCDF files which contain all the positions of the satellite.
            ResultsFilename: the netcdf file where the results of this calculation will be stored.
    &#34;&#34;&#34;    
    
    if path.exists( ResultsFilename ): 
        print(&#34;Skipping because exists:&#34;, ResultsFilename)
        return
    
    # initialize
    MagLat_min =  1000
    MagLat_max = -1000
    MLT_min    =  1000
    MLT_max    = -1000
    Altitude_min    =  1000
    Altitude_max    = -1000
    Lat_min     =  1000
    Lat_max     = -1000
    Kp_min     =  1000
    Kp_max     = -1000
    for B in Bins:
        B.reset()
        if B.MagLat_min &lt; MagLat_min: MagLat_min = B.MagLat_min 
        if B.MagLat_max &gt; MagLat_max: MagLat_max = B.MagLat_max
        if B.MLT_min &lt; MLT_min: MLT_min = B.MLT_min 
        if B.MLT_max &gt; MLT_max: MLT_max = B.MLT_max
        if B.Altitude_min &lt; Altitude_min: Altitude_min = B.Altitude_min 
        if B.Altitude_max &gt; Altitude_max: Altitude_max = B.Altitude_max
        if B.Lat_min &lt; Lat_min: Lat_min = B.Lat_min 
        if B.Lat_max &gt; Lat_max: Lat_max = B.Lat_max                                
        if B.Kp_min &lt; Kp_min: Kp_min = B.Kp_min 
        if B.Kp_max &gt; Kp_max: Kp_max = B.Kp_max                    
            
    # miscellaneous
    currentfilenumber = -1        
    Matches = 0
    Errors  = 0
    # information about the TIEGCM files
    TIEGCMfilenamePrefix  = &#34;tiegcm&#34; 
    TIEGCMfilenamePostfix = &#34;&#34;

    # read orbit file
    current_timestamp_offset = 0 # increases after each satellite position is parsed
    AllOrbitFiles = sorted( glob.glob( Orbit_filesPath + &#34;*.nc&#34; ) )
    for currentOrbitFile in AllOrbitFiles:
        current_timestamp_offset = 0 # reseted ONLY when the orbits of 2 satellites are inside the folder (one file each)
        print( &#34;\nReading Orbit file:&#34;, currentOrbitFile )
        try:
            Orbit_CDF = Dataset( currentOrbitFile, &#39;r&#39; )
        except:
            print ( &#34;WRONG FORMAT:&#34;, currentDataFile )
            continue
        # Load data from the netCDF file
        ORBIT_Times      = Orbit_CDF.variables[&#39;time&#39;][:]
        ORBIT_MagLats    = Orbit_CDF.variables[&#39;DaedalusMagneticLatitude&#39;][:]
        ORBIT_MLTs       = Orbit_CDF.variables[&#39;DaedalusMLT&#39;][:]
        ORBIT_Altitudes  = Orbit_CDF.variables[&#39;ZGMID&#39;][:] / 100000
        ORBIT_Lats       = Orbit_CDF.variables[&#39;lat&#39;][:]
        ORBIT_Ohmic      = Orbit_CDF.variables[&#39;Ohmic&#39;][:]
        ORBIT_Density    = Orbit_CDF.variables[&#39;DEN&#39;][:]
        try:
            ORBIT_Lev    = Orbit_CDF.variables[&#39;lev&#39;][:]
        except:
            ORBIT_Lev    = list()
        try:
            ORBIT_ConvH  = Orbit_CDF.variables[&#39;Convection_heating&#39;][:]
        except:
            ORBIT_ConvH  = Orbit_CDF.variables[&#39;Convenction_heating&#39;][:]
        ORBIT_WindH  = Orbit_CDF.variables[&#39;Wind_heating&#39;][:]
        try: 
            ORBIT_EEX    = Orbit_CDF.variables[&#39;EEX&#39;][:] 
        except: 
            try:
                ORBIT_EEX    = Orbit_CDF.variables[&#39;EEX_si&#39;][:] 
            except:
                ORBIT_EEX    = list()
        try: 
            ORBIT_EEY    = Orbit_CDF.variables[&#39;EEY&#39;][:] 
        except: 
            try:
                ORBIT_EEY    = Orbit_CDF.variables[&#39;EEY_si&#39;][:] 
            except:
                ORBIT_EEY    = list()  
        try: 
            ORBIT_Pedersen = Orbit_CDF.variables[&#39;SIGMA_PED&#39;][:] 
        except: 
            ORBIT_Pedersen = list()            
        try: 
            ORBIT_Hall    = Orbit_CDF.variables[&#39;SIGMA_HAL&#39;][:] 
        except: 
            ORBIT_Hall    = list()
            
        try:
            orbit_start_datetime = datetime.strptime(Orbit_CDF.variables[&#39;time&#39;].UNITS[14:], &#39;%d %b %Y %H:%M:%S.%f&#39;)
        except:
            orbit_start_datetime = datetime.strptime(&#34;Seconds Since 1 Jan 2015 00:00:00.000&#34;[14:], &#39;%d %b %Y %H:%M:%S.%f&#39;)
            print(&#34;!!! ERROR while reading units of time inside NetCDF file. Assumed default value: &#39;Seconds Since 1 Jan 2015 00:00:00.000&#39;&#34;)
        orbit_start_timestamp = calendar.timegm(orbit_start_datetime.utctimetuple())
        orbit_timestamp_step = ORBIT_Times[1] - ORBIT_Times[0]
        print( &#34;orbit_timestamp_step =&#34;, orbit_timestamp_step )
        num_of_positions =  len(ORBIT_Times)
        # read the satellite positions and try to fill the bins
        for idx in range(0, num_of_positions): # for each satellite position
            if idx % 200000 == 0: print (&#34;Checking sat position No&#34;, idx, &#34;of&#34;, num_of_positions)
            in_Altitude_range = in_MagLat_range = in_MLT_range = in_Lat_range = in_Kp_range = False
                      
            # check if this position lies inside some bin
            current_Altitude = ORBIT_Altitudes[ idx ]
            if current_Altitude &gt;= Altitude_min and current_Altitude &lt;= Altitude_max: in_Altitude_range = True
            #
            if in_Altitude_range:
                current_MagLat = ORBIT_MagLats[ idx ]
                if current_MagLat &gt;= MagLat_min and current_MagLat &lt;= MagLat_max: in_MagLat_range = True
            #
            if in_MagLat_range:
                current_MLT = ORBIT_MLTs[ idx ]
                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )
                
            # 
            if in_MLT_range: 
                current_Lat = ORBIT_Lats[ idx ]
                if current_Lat &gt;= Lat_min and current_Lat &lt;= Lat_max: in_Lat_range = True
                    
            if in_Lat_range==False:
                current_MagLat = ORBIT_MagLats[ idx ]
                current_MLT = ORBIT_MLTs[ idx ]
                current_Lat = ORBIT_Lats[ idx ]
                #if idx % 200000 == 0: print( &#34;ALT:&#34;,current_Altitude, &#34;MAGLAT:&#34;, current_MagLat, &#34;MLT:&#34;, current_MLT, &#34;LAT:&#34;,current_Lat )

            # The position is probably inside a bin (only kp remains to be checked). 
            # Open the corresponding TIEGCM file to read the kp and if position is in bin then calculate JH
            if in_Lat_range:
                current_timestamp = orbit_start_timestamp + current_timestamp_offset
                current_datetime  = datetime.utcfromtimestamp( current_timestamp )
                
                # Locate the corresponding TIEGCM file and timestep inside the file
                # one TIEGCM file contains 60 timesteps, 1 per 120min. The file&#39;s duration is 5 days. Each year consists of 74 files (the last file is smaller)
                start_of_current_year_datetime  = datetime.strptime(&#34;01 Jan &#34; + str(current_datetime.year) + &#34; 00:00:00&#34;, &#39;%d %b %Y %H:%M:%S&#39;)
                start_of_current_year_timestamp = calendar.timegm(start_of_current_year_datetime.utctimetuple())
                newfilenumber = int(  ( (current_timestamp - start_of_current_year_timestamp)/(60*120) ) / 60  ) 
                tmp = (current_timestamp - start_of_current_year_timestamp)/(60*120) - newfilenumber*60 
                timestep_number = int( tmp )
                if tmp - float(timestep_number) &gt; 0.5: timestep_number += 1 # select the nearest neighbor
                if  ( current_timestamp==start_of_current_year_timestamp  or  (current_timestamp - start_of_current_year_timestamp)/(60*120) ) % 60  !=  0: newfilenumber += 1 # file numbers start from 1
                if current_datetime.year == 2016: newfilenumber += 74
                if current_datetime.year == 2017: newfilenumber += 148
                
                # open the TIEGCM file if necessary
                if currentfilenumber &lt; 0   or   currentfilenumber != newfilenumber:
                    if currentfilenumber &gt;= 0: 
                        try:
                            tiegcm_CDF.close()
                        except:
                            print(&#34;Error closing tiegcm file no&#34;, currentfilenumber )
                    TIEGCMfilename = TIEGCM_filesPath + str(current_datetime.year) + &#34;/&#34; + TIEGCMfilenamePrefix + &#34;{:03.0f}&#34;.format(newfilenumber) + TIEGCMfilenamePostfix + &#34;.nc&#34;
                    currentfilenumber = newfilenumber
                    print(  &#34;Opening TIEGCMfile:&#34;, TIEGCMfilename)
                    try:
                        tiegcm_CDF = Dataset( TIEGCMfilename, &#39;r&#39; )
                    except Exception as ex:
                        print ( &#34;FILE NOT FOUND OR WRONG FORMAT:&#34;, TIEGCMfilename )
                        continue
                        
                # read Kp from the tiegcm file
                try:
                    current_Kp = tiegcm_CDF.variables[&#39;Kp&#39;][timestep_number]
                except:
                    #print(&#34;%%%%%%%%%%%%%%%%%%%%%&#34;)
                    #print(len(tiegcm_CDF.variables[&#39;Kp&#39;]), timestep_number)
                    #print( current_datetime, current_timestamp, start_of_current_year_timestamp )
                    #print(TIEGCMfilename)
                    #print(&#34;%%%%%%%%%%%%%%%%%%%%%&#34;)
                    try:
                        current_Kp = tiegcm_CDF.variables[&#39;Kp&#39;][timestep_number-1]
                    except:
                        #print( &#34;!! Timestep Error&#34;,  timestep_number) # &#34;of&#34;, len(tiegcm_CDF.variables[&#39;Kp&#39;]) )
                        continue
                    
                if current_Kp &gt;= Kp_min and current_Kp &lt;= Kp_max:
                    in_Kp_range = True 
                # if the satellite position matches a bin then mark it as a hit and remember the JH values 
                if in_MagLat_range and in_MLT_range and in_Altitude_range and in_Kp_range:
                    matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )
                    if matchedBin is not None:
                        # for this position locate the neighbor latitudes at the TIEGCM file. 
                        #lat1_idx, lat2_idx, lat1_val, lat2_val = findNeighborValues( TIEGCM_Lats, current_GeogLat )
                        # for this position locate the neighbor longitudes at the TIEGCM file.
                        #lon1_idx, lon2_idx, lon1_val, lon2_val = findNeighborValues( TIEGCM_Lons, current_Lon )
                        # for this position locate the neighbor Altitudes at the TIEGCM file. 
                        #lev1_idx, lev2_idx, lev1_val, lev2_val = findNeighborValues( CDFroot.variables[&#39;ZGMID&#39;][time_idx, :, lat_idx, lon_idx], current_Altitude )
                        current_JH = ORBIT_Ohmic[ idx ]
                        # save 
                        matchedBin.JH_values.append( current_JH )
                        matchedBin.MagLat_values.append( current_MagLat )
                        matchedBin.MLT_values.append( current_MLT )
                        matchedBin.Altitude_values.append( current_Altitude )
                        matchedBin.Lat_values.append( current_Lat )
                        matchedBin.Kp_values.append( current_Kp )
                        matchedBin.Time_values.append( current_timestamp )
                        matchedBin.EEX_values.append( ORBIT_EEX[ idx ] ) 
                        matchedBin.EEY_values.append( ORBIT_EEY[ idx ] ) 
                        matchedBin.Pedersen_values.append( ORBIT_Pedersen[ idx ] ) 
                        matchedBin.Density_values.append( ORBIT_Density[ idx ] ) 
                        if len(ORBIT_Lev) &gt; 0: matchedBin.Lev_values.append( ORBIT_Lev[ idx ] )
                        matchedBin.ConvectionHeating_values.append( ORBIT_ConvH[ idx ] )
                        matchedBin.WindHeating_values.append( ORBIT_WindH[ idx ] )
                        if len(ORBIT_Hall) &gt; 0: 
                            matchedBin.Hall_values.append( ORBIT_Hall[ idx ] ) 
                        all_JH_values.append( current_JH )
                        all_MagLat_values.append( current_MagLat )
                        all_MLT_values.append( current_MLT )
                        all_Altitude_values.append( current_Altitude )
                        all_Lat_values.append( current_Lat )
                        all_Kp_values.append( current_Kp )
                        all_Time_values.append( current_timestamp )
                        all_HittedBin_IDs.append( matchedBin.ID )
                        all_EEX_values.append( ORBIT_EEX[ idx ] )
                        all_EEY_values.append( ORBIT_EEY[ idx ] )
                        all_Pedersen_values.append( ORBIT_Pedersen[ idx ] )
                        all_Density_values.append( ORBIT_Density[ idx ] )
                        if len(ORBIT_Lev) &gt; 0: all_Lev_values.append( ORBIT_Lev[ idx ] )
                        all_ConvectionHeating_values.append( ORBIT_ConvH[ idx ] )
                        all_WindHeating_values.append( ORBIT_WindH[ idx ] )
                        if len(ORBIT_Hall) &gt; 0: all_Hall_values.append( ORBIT_Hall[ idx ] )
                        Matches += 1
                    else:
                        pass
                        #print( &#34;PARADOX at:&#34;, current_MLT, current_MagLat, current_Altitude, current_Kp, &#34; :: &#34;, time_idx, lev_idx, lat_idx, lon_idx )
            current_timestamp_offset += orbit_timestamp_step
    # save and clean up
    CalculateStatsOnData()
    SaveResults_CDF( ResultsFilename, &#34;&#34; ) 
    print( Matches, &#34;satellite positions where matched inside bins.&#34; )
    try:
        CDFroot.close()
    except:
        print (&#34;.&#34;)

        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
DiskAccessLock = threading.Lock()   
class Thread_ValueAssigner (threading.Thread):
    &#34;&#34;&#34;
    The thread executes the actual calculation using a single source file (DataFilename) and producing one result file (ResultsFilename):  
        - reads the netcdf orbit or tiegcm file  
        - checks every space-time position  
        - assign the position&#39;s data to the corresponding Bin   
        - saves the above data into a netcdf results-file  
    Threads are employed in order to speed up the calculation when there are many source files. 
    There will be one thread for each source file
    &#34;&#34;&#34;
    def __init__(self, DataFilename, ResultsFilename):
        threading.Thread.__init__(self)
        self.DataFilename = DataFilename
        self.ResultsFilename = ResultsFilename
    def run(self):
        global Bins
        global all_JH_values
        DataFilename = self.DataFilename
        ResultsFilename = self.ResultsFilename
        print( &#34;Thread start&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename, &#34;\n&#34; )
        MagLat_min =  1000
        MagLat_max = -1000
        MLT_min    =  1000
        MLT_max    = -1000
        Altitude_min    =  1000
        Altitude_max    = -1000
        Lat_min     =  1000
        Lat_max     = -1000    
        Kp_min     =  1000
        Kp_max     = -1000
        localBins = copy.deepcopy(Bins)
        for B in localBins:
            B.reset()
            if B.MagLat_min &lt; MagLat_min: MagLat_min = B.MagLat_min 
            if B.MagLat_max &gt; MagLat_max: MagLat_max = B.MagLat_max
            if B.MLT_min &lt; MLT_min: MLT_min = B.MLT_min 
            if B.MLT_max &gt; MLT_max: MLT_max = B.MLT_max
            if B.Altitude_min &lt; Altitude_min: Altitude_min = B.Altitude_min 
            if B.Altitude_max &gt; Altitude_max: Altitude_max = B.Altitude_max
            if B.Lat_min &lt; Lat_min: Lat_min = B.Lat_min 
            if B.Lat_max &gt; Lat_max: Lat_max = B.Lat_max                        
            if B.Kp_min &lt; Kp_min: Kp_min = B.Kp_min 
            if B.Kp_max &gt; Kp_max: Kp_max = B.Kp_max            
        all_JH_values.clear()
        all_MagLat_values.clear()
        all_MLT_values.clear()
        all_Altitude_values.clear()
        all_Lat_values.clear()
        all_Kp_values.clear()
        all_Time_values.clear()
        all_HittedBin_IDs.clear()
        all_EEX_values.clear()
        all_EEY_values.clear()
        all_Pedersen_values.clear()
        all_Density_values.clear()
        all_Lev_values.clear()
        all_Hall_values.clear()
        all_ConvectionHeating_values.clear()
        all_WindHeating_values.clear()
        Matches = 0
        
        # parse TIEGCM file
        try:
            CDFroot = Dataset( DataFilename, &#39;r&#39; )
            print( &#34;Reading&#34;, DataFilename )
        except:
            print ( &#34;WRONG FORMAT:&#34;, DataFilename )
            return
        try:
            FileStartTimeStamp = calendar.timegm( datetime.strptime( CDFroot.variables[&#39;time&#39;].units[14:],  &#34;%Y-%m-%d %H:%M:%S&#34; ).utctimetuple() ) # ex: &#34;minutes since 2015-1-1 0:0:0&#34;
        except:
            print ( &#34;WRONG CONTENTS:&#34;, DataFilename )
            return
        length_time = CDFroot.variables[&#39;Ohmic&#39;].shape[0]
        length_lev  = CDFroot.variables[&#39;Ohmic&#39;].shape[1]
        length_lat  = CDFroot.variables[&#39;Ohmic&#39;].shape[2]
        length_lon  = CDFroot.variables[&#39;Ohmic&#39;].shape[3]
        # wait until disk is released
        DiskAccessLock.acquire()
        # Load or calculate all basic values from the netcdf file
        try:
            TIMEs   = CDFroot.variables[&#39;time&#39;][:] # minutes since the start time
            LATs    = CDFroot.variables[&#39;lat&#39;][:] 
            ALTs    = CDFroot.variables[&#39;ZGMID&#39;][:, :, :, :] / 100000 # it is stored in cm inside the file
            JHs     = CDFroot.variables[&#39;Ohmic&#39;][:, :, :, :]
            KPs     = CDFroot.variables[&#39;Kp&#39;][:]
            MAGLATs = CDFroot.variables[&#39;mlat_qdf&#39;][:, :, :, :] 
            MLTs    = CDFroot.variables[&#39;mlt_qdf&#39;][:, :, :, :] 
            EEXs    = CDFroot.variables[&#39;EEX&#39;][:, :, :, :] 
            EEYs    = CDFroot.variables[&#39;EEY&#39;][:, :, :, :] 
            PEDs    = CDFroot.variables[&#39;SIGMA_PED&#39;][:, :, :, :] 
            HALs    = CDFroot.variables[&#39;SIGMA_HAL&#39;][:, :, :, :]
            DENs    = CDFroot.variables[&#39;DEN&#39;][:, :, :, :] 
            LEVs    = CDFroot.variables[&#39;lev&#39;][:] 
            try:
                CONV_H  = CDFroot.variables[&#39;Convection_heating&#39;][:, :, :, :]
            except:
                CONV_H  = CDFroot.variables[&#39;Convenction_heating&#39;][:, :, :, :]
            WIND_H  = CDFroot.variables[&#39;Wind_heating&#39;][:, :, :, :]
        except Exception as e:
            print( &#34;Thread aborted while reading&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;:&#34;, e, repr(e), &#34;\n&#34; )
            DiskAccessLock.release()
            return 
        DiskAccessLock.release()
        print( &#34;Thread file read done&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34; )
    
        step = 1
        for idx_lat in range(0, length_lat, step):
            if idx_lat%2==0: print(&#34;Thread Calculating Lat&#34;,  idx_lat, ResultsFilename[-26:])
            current_Lat = LATs[idx_lat] 
            if current_Lat &lt; Lat_min  or  current_Lat &gt; Lat_max: continue
            for idx_lon in range(0, length_lon, step):
                for idx_lev in range(0, length_lev, step):
                    for idx_time in range(0, length_time, step):                    
                        in_Altitude_range = in_MagLat_range = in_MLT_range = in_Kp_range = False
                            
                        current_Altitude = ALTs[idx_time, idx_lev, idx_lat, idx_lon]
                        if current_Altitude &gt;= Altitude_min and current_Altitude &lt;= Altitude_max:
                            in_Altitude_range = True
                        
                        if in_Altitude_range:
                            current_MagLat = MAGLATs[ idx_time, idx_lev, idx_lat, idx_lon ]
                            if current_MagLat &gt;= MagLat_min and current_MagLat &lt;= MagLat_max:
                                in_MagLat_range = True
                                
                        if in_MagLat_range:
                            current_MLT = MLTs[ idx_time, idx_lev, idx_lat, idx_lon ]
                            if in_MagLat_range:
                                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )
                        
                        if in_MLT_range:
                            current_Kp = KPs[idx_time]
                            if current_Kp &gt;= Kp_min and current_Kp &lt;= Kp_max:
                                in_Kp_range = True   
                                
                        if in_Kp_range:                    
                            matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )
                            if matchedBin is not None:
                                for B in localBins:
                                    if B.ID == matchedBin.ID:
                                        matchedBin = B
                                current_time = int( FileStartTimeStamp + TIMEs[idx_time]*120*60 )
                                current_JH = JHs[idx_time, idx_lev, idx_lat ,idx_lon] #CDFroot.variables[&#39;Joule Heating&#39;][idx_time, idx_lev, idx_lat, idx_lon]
                                matchedBin.JH_values.append( current_JH )
                                matchedBin.MagLat_values.append( current_MagLat )
                                matchedBin.MLT_values.append( current_MLT )
                                matchedBin.Altitude_values.append( current_Altitude )
                                matchedBin.Kp_values.append( current_Kp )
                                matchedBin.Time_values.append( current_time )
                                matchedBin.EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Lev_values.append( LEVs[ idx_lev ] ) 
                                matchedBin.ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                all_JH_values.append( current_JH )
                                all_MagLat_values.append( current_MagLat )
                                all_MLT_values.append( current_MLT )
                                all_Altitude_values.append( current_Altitude )
                                all_Kp_values.append( current_Kp )
                                all_Time_values.append( current_time )
                                all_HittedBin_IDs.append( matchedBin.ID )
                                all_EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Lev_values.append( LEVs[ idx_lev ] )
                                all_ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                all_WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                Matches += 1
                    #break
                #break
        CDFroot.close()
        # wait until disk is released
        #DiskAccessLock.acquire()
        #### SAVE Results ####
        try:
            # save general info
            resultsCDF = Dataset( ResultsFilename, &#39;a&#39; )
            resultsCDF.DateOfUpdate = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
            resultsCDF.Region = CALCULATIONS_RegionName
            resultsCDF.DataPath = CALCULATIONS_TIEGCMfolder
            # save data for each bin seperately 
            for B in localBins:
                # save data about the hits inside the bin
                if len(B.Time_values) &gt; 0:
                    resultsCDF.variables[B.ID+&#34;_TimeValues&#34;][:]      = B.Time_values
                    resultsCDF.variables[B.ID+&#34;_JHValues&#34;][:]        = B.JH_values        
                    resultsCDF.variables[B.ID+&#34;_MagLatValues&#34;][:]    = B.MagLat_values
                    resultsCDF.variables[B.ID+&#34;_MLTValues&#34;][:]       = B.MLT_values
                    resultsCDF.variables[B.ID+&#34;_AltitudeValues&#34;][:]  = B.Altitude_values
                    resultsCDF.variables[B.ID+&#34;_LatValues&#34;][:]       = B.Lat_values
                    resultsCDF.variables[B.ID+&#34;_KpValues&#34;][:]        = B.Kp_values
                    resultsCDF.variables[B.ID+&#34;_EEXValues&#34;][:]       = B.EEX_values        
                    resultsCDF.variables[B.ID+&#34;_EEYValues&#34;][:]       = B.EEY_values
                    resultsCDF.variables[B.ID+&#34;_PedersenValues&#34;][:]  = B.Pedersen_values
                    resultsCDF.variables[B.ID+&#34;_HallValues&#34;][:]      = B.Hall_values
                    resultsCDF.variables[B.ID+&#34;_DensityValues&#34;][:]   = B.Density_values
                    resultsCDF.variables[B.ID+&#34;_LevValues&#34;][:]       = B.Lev_values
                    resultsCDF.variables[B.ID+&#34;_ConvectionHeatingValues&#34;][:] = B.ConvectionHeating_values
                    resultsCDF.variables[B.ID+&#34;_WindHeatingValues&#34;][:] = B.WindHeating_values
            ## save data for all hits
            resultsCDF.variables[&#34;allTimeValues&#34;][:]     = all_Time_values
            resultsCDF.variables[&#34;allJHValues&#34;][:]       = all_JH_values    
            resultsCDF.variables[&#34;allMagLatValues&#34;][:]   = all_MagLat_values
            resultsCDF.variables[&#34;allMLTValues&#34;][:]      = all_MLT_values
            resultsCDF.variables[&#34;allAltitudeValues&#34;][:] = all_Altitude_values
            resultsCDF.variables[&#34;allLatValues&#34;][:]      = all_Lat_values
            resultsCDF.variables[&#34;allKpValues&#34;][:]       = all_Kp_values
            #resultsCDF.variables[&#34;allHittedBinIDs&#34;][:]   = netCDF4.stringtochar(np.array(all_HittedBin_IDs[:], &#39;S8&#39;))
            resultsCDF.variables[&#34;allEEXValues&#34;][:]      = all_EEX_values
            resultsCDF.variables[&#34;allEEYValues&#34;][:]      = all_EEY_values
            resultsCDF.variables[&#34;allPedersenValues&#34;][:] = all_Pedersen_values
            resultsCDF.variables[&#34;allHallValues&#34;][:]     = all_Hall_values
            resultsCDF.variables[&#34;allDensityValues&#34;][:]  = all_Density_values
            resultsCDF.variables[&#34;allLevValues&#34;][:]      = all_Lev_values
            resultsCDF.variables[&#34;allConvectionHeatingValues&#34;][:] = all_ConvectionHeating_values
            resultsCDF.variables[&#34;allWindHeatingValues&#34;][:] = all_WindHeating_values
            #
            resultsCDF.close()    
        except Exception as e:
            print( &#34;!!!! Thread error while writing&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34; )
            print( e )
            #DiskAccessLock.release()
        #DiskAccessLock.release()
    
        print( &#34;Thread finish&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34;, Matches, &#34;matches&#34;, len(localBins[0].JH_values), len(Bins[0].JH_values) )
        print( &#34;&#34; )

        
        

        
        
def CalculateStatsOnData():
    &#34;&#34;&#34;
    This function uses the values assigned into the Bins to calculate mean, variance, deviation and stores them into the Bin class.
    &#34;&#34;&#34;
    global Bins
    for B in Bins:
        if len(B.JH_values) &gt; 0:
            # calculate the mean value
            for aJHvalue in B.JH_values:
                if B.JH_min &gt; aJHvalue: B.JH_min = aJHvalue
                if B.JH_max &lt; aJHvalue: B.JH_max = aJHvalue
                B.JH_mean += aJHvalue
            B.JH_mean = B.JH_mean / len(B.JH_values)
            
            # calculate the median value
            B.JH_median = np.percentile(B.JH_values, 50)
            
            # for Variance (around mean):
            for aJHvalue in B.JH_values:
                B.JH_variance += abs(aJHvalue - B.JH_mean)**2
            B.JH_variance = B.JH_variance / len(B.JH_values)
            
            # for Median Variance (around median):
            for aJHvalue in B.JH_values:
                B.JH_medianVariance += abs(aJHvalue - B.JH_median)**2
            B.JH_medianVariance = B.JH_medianVariance / len(B.JH_values)
            
            # for Median absolute deviation
            AbsoluteDeviations = B.JH_values.copy()
            for i in range(0, len(AbsoluteDeviations)):
                AbsoluteDeviations[i] = abs(B.JH_median - AbsoluteDeviations[i])
            B.JH_medianAbsDev = np.percentile(AbsoluteDeviations, 50)
        
        
        
        
def AssignValuesPerBin_MultipleResultFiles( TIEGCMfilesPath, ResultFilesPath ):
    &#34;&#34;&#34;
    This function initiates the calculation. 
    It creates a Thread_ValueAssigner for each source file which resides in TIEGCMfilesPath
    It also tells the thread to store the result file into ResultFilesPath
    &#34;&#34;&#34;
    startSecs = time.time()

    if path.exists( ResultFilesPath ) == False:
        os.mkdir( ResultFilesPath )
    
    AllThreads = list()
    AllDataFiles = sorted( glob.glob( TIEGCMfilesPath + &#34;/*/*.nc&#34;, recursive=True ) )
    for currentDataFile in AllDataFiles:
        if &#39;\\&#39; in currentDataFile: #windows
            prefix = currentDataFile[ currentDataFile.rfind(&#39;\\&#39;)+1 : -3 ]
        else: # linux
            prefix = currentDataFile[ currentDataFile.rfind(&#39;/&#39;)+1 : -3 ]
        ResultsFilename = ResultFilesPath + currentDataFile[ currentDataFile.rfind(&#39;\\&#39;)+1 : -3 ] + &#34;.stats.nc&#34;
        if path.exists( ResultsFilename ): 
            print(&#34;Skipping because exists:&#34;, ResultsFilename)
            continue
        else:
            # wait if there are plenty alive threads
            alive_counter = 0
            for aThread in AllThreads:
                if aThread.is_alive():
                    alive_counter += 1
            while alive_counter &gt;= 5:
                time.sleep(random.randint(10, 15))
                alive_counter = 0
                for aThread in AllThreads:
                    if aThread.is_alive():
                        alive_counter += 1
            # spawn new thread
            CreateResults_CDF( ResultsFilename )
            T = Thread_ValueAssigner(currentDataFile, ResultsFilename)
            AllThreads.append(T)
            T.start()
            time.sleep(2)

    # wait for all threads to terminate
    for T in AllThreads: T.join()
    # finish it
    finishSecs = time.time()
    print( finishSecs-startSecs, &#34; sec&#34;)    
    
    





    
    
    
    
    
    
    
    
    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="DaedalusMASE_Global_Statistics.data.AssignJouleHeatingValuesToBins_AlongOrbit"><code class="name flex">
<span>def <span class="ident">AssignJouleHeatingValuesToBins_AlongOrbit</span></span>(<span>TIEGCM_filesPath, Orbit_filesPath, ResultsFilename)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads the orbit positions and fills the correct Bin with values for each position.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>TIEGCM_filesPath</code></strong></dt>
<dd>the folder which has all TIEGCM netcdf files. Needed to read the Kp index for each satellite position.</dd>
<dt><strong><code>Orbit_filesPath</code></strong></dt>
<dd>the folder which has the netCDF files which contain all the positions of the satellite.</dd>
<dt><strong><code>ResultsFilename</code></strong></dt>
<dd>the netcdf file where the results of this calculation will be stored.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AssignJouleHeatingValuesToBins_AlongOrbit( TIEGCM_filesPath, Orbit_filesPath, ResultsFilename ): 
    &#34;&#34;&#34;
        Reads the orbit positions and fills the correct Bin with values for each position.
        
        Args:
            TIEGCM_filesPath: the folder which has all TIEGCM netcdf files. Needed to read the Kp index for each satellite position.
            Orbit_filesPath: the folder which has the netCDF files which contain all the positions of the satellite.
            ResultsFilename: the netcdf file where the results of this calculation will be stored.
    &#34;&#34;&#34;    
    
    if path.exists( ResultsFilename ): 
        print(&#34;Skipping because exists:&#34;, ResultsFilename)
        return
    
    # initialize
    MagLat_min =  1000
    MagLat_max = -1000
    MLT_min    =  1000
    MLT_max    = -1000
    Altitude_min    =  1000
    Altitude_max    = -1000
    Lat_min     =  1000
    Lat_max     = -1000
    Kp_min     =  1000
    Kp_max     = -1000
    for B in Bins:
        B.reset()
        if B.MagLat_min &lt; MagLat_min: MagLat_min = B.MagLat_min 
        if B.MagLat_max &gt; MagLat_max: MagLat_max = B.MagLat_max
        if B.MLT_min &lt; MLT_min: MLT_min = B.MLT_min 
        if B.MLT_max &gt; MLT_max: MLT_max = B.MLT_max
        if B.Altitude_min &lt; Altitude_min: Altitude_min = B.Altitude_min 
        if B.Altitude_max &gt; Altitude_max: Altitude_max = B.Altitude_max
        if B.Lat_min &lt; Lat_min: Lat_min = B.Lat_min 
        if B.Lat_max &gt; Lat_max: Lat_max = B.Lat_max                                
        if B.Kp_min &lt; Kp_min: Kp_min = B.Kp_min 
        if B.Kp_max &gt; Kp_max: Kp_max = B.Kp_max                    
            
    # miscellaneous
    currentfilenumber = -1        
    Matches = 0
    Errors  = 0
    # information about the TIEGCM files
    TIEGCMfilenamePrefix  = &#34;tiegcm&#34; 
    TIEGCMfilenamePostfix = &#34;&#34;

    # read orbit file
    current_timestamp_offset = 0 # increases after each satellite position is parsed
    AllOrbitFiles = sorted( glob.glob( Orbit_filesPath + &#34;*.nc&#34; ) )
    for currentOrbitFile in AllOrbitFiles:
        current_timestamp_offset = 0 # reseted ONLY when the orbits of 2 satellites are inside the folder (one file each)
        print( &#34;\nReading Orbit file:&#34;, currentOrbitFile )
        try:
            Orbit_CDF = Dataset( currentOrbitFile, &#39;r&#39; )
        except:
            print ( &#34;WRONG FORMAT:&#34;, currentDataFile )
            continue
        # Load data from the netCDF file
        ORBIT_Times      = Orbit_CDF.variables[&#39;time&#39;][:]
        ORBIT_MagLats    = Orbit_CDF.variables[&#39;DaedalusMagneticLatitude&#39;][:]
        ORBIT_MLTs       = Orbit_CDF.variables[&#39;DaedalusMLT&#39;][:]
        ORBIT_Altitudes  = Orbit_CDF.variables[&#39;ZGMID&#39;][:] / 100000
        ORBIT_Lats       = Orbit_CDF.variables[&#39;lat&#39;][:]
        ORBIT_Ohmic      = Orbit_CDF.variables[&#39;Ohmic&#39;][:]
        ORBIT_Density    = Orbit_CDF.variables[&#39;DEN&#39;][:]
        try:
            ORBIT_Lev    = Orbit_CDF.variables[&#39;lev&#39;][:]
        except:
            ORBIT_Lev    = list()
        try:
            ORBIT_ConvH  = Orbit_CDF.variables[&#39;Convection_heating&#39;][:]
        except:
            ORBIT_ConvH  = Orbit_CDF.variables[&#39;Convenction_heating&#39;][:]
        ORBIT_WindH  = Orbit_CDF.variables[&#39;Wind_heating&#39;][:]
        try: 
            ORBIT_EEX    = Orbit_CDF.variables[&#39;EEX&#39;][:] 
        except: 
            try:
                ORBIT_EEX    = Orbit_CDF.variables[&#39;EEX_si&#39;][:] 
            except:
                ORBIT_EEX    = list()
        try: 
            ORBIT_EEY    = Orbit_CDF.variables[&#39;EEY&#39;][:] 
        except: 
            try:
                ORBIT_EEY    = Orbit_CDF.variables[&#39;EEY_si&#39;][:] 
            except:
                ORBIT_EEY    = list()  
        try: 
            ORBIT_Pedersen = Orbit_CDF.variables[&#39;SIGMA_PED&#39;][:] 
        except: 
            ORBIT_Pedersen = list()            
        try: 
            ORBIT_Hall    = Orbit_CDF.variables[&#39;SIGMA_HAL&#39;][:] 
        except: 
            ORBIT_Hall    = list()
            
        try:
            orbit_start_datetime = datetime.strptime(Orbit_CDF.variables[&#39;time&#39;].UNITS[14:], &#39;%d %b %Y %H:%M:%S.%f&#39;)
        except:
            orbit_start_datetime = datetime.strptime(&#34;Seconds Since 1 Jan 2015 00:00:00.000&#34;[14:], &#39;%d %b %Y %H:%M:%S.%f&#39;)
            print(&#34;!!! ERROR while reading units of time inside NetCDF file. Assumed default value: &#39;Seconds Since 1 Jan 2015 00:00:00.000&#39;&#34;)
        orbit_start_timestamp = calendar.timegm(orbit_start_datetime.utctimetuple())
        orbit_timestamp_step = ORBIT_Times[1] - ORBIT_Times[0]
        print( &#34;orbit_timestamp_step =&#34;, orbit_timestamp_step )
        num_of_positions =  len(ORBIT_Times)
        # read the satellite positions and try to fill the bins
        for idx in range(0, num_of_positions): # for each satellite position
            if idx % 200000 == 0: print (&#34;Checking sat position No&#34;, idx, &#34;of&#34;, num_of_positions)
            in_Altitude_range = in_MagLat_range = in_MLT_range = in_Lat_range = in_Kp_range = False
                      
            # check if this position lies inside some bin
            current_Altitude = ORBIT_Altitudes[ idx ]
            if current_Altitude &gt;= Altitude_min and current_Altitude &lt;= Altitude_max: in_Altitude_range = True
            #
            if in_Altitude_range:
                current_MagLat = ORBIT_MagLats[ idx ]
                if current_MagLat &gt;= MagLat_min and current_MagLat &lt;= MagLat_max: in_MagLat_range = True
            #
            if in_MagLat_range:
                current_MLT = ORBIT_MLTs[ idx ]
                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )
                
            # 
            if in_MLT_range: 
                current_Lat = ORBIT_Lats[ idx ]
                if current_Lat &gt;= Lat_min and current_Lat &lt;= Lat_max: in_Lat_range = True
                    
            if in_Lat_range==False:
                current_MagLat = ORBIT_MagLats[ idx ]
                current_MLT = ORBIT_MLTs[ idx ]
                current_Lat = ORBIT_Lats[ idx ]
                #if idx % 200000 == 0: print( &#34;ALT:&#34;,current_Altitude, &#34;MAGLAT:&#34;, current_MagLat, &#34;MLT:&#34;, current_MLT, &#34;LAT:&#34;,current_Lat )

            # The position is probably inside a bin (only kp remains to be checked). 
            # Open the corresponding TIEGCM file to read the kp and if position is in bin then calculate JH
            if in_Lat_range:
                current_timestamp = orbit_start_timestamp + current_timestamp_offset
                current_datetime  = datetime.utcfromtimestamp( current_timestamp )
                
                # Locate the corresponding TIEGCM file and timestep inside the file
                # one TIEGCM file contains 60 timesteps, 1 per 120min. The file&#39;s duration is 5 days. Each year consists of 74 files (the last file is smaller)
                start_of_current_year_datetime  = datetime.strptime(&#34;01 Jan &#34; + str(current_datetime.year) + &#34; 00:00:00&#34;, &#39;%d %b %Y %H:%M:%S&#39;)
                start_of_current_year_timestamp = calendar.timegm(start_of_current_year_datetime.utctimetuple())
                newfilenumber = int(  ( (current_timestamp - start_of_current_year_timestamp)/(60*120) ) / 60  ) 
                tmp = (current_timestamp - start_of_current_year_timestamp)/(60*120) - newfilenumber*60 
                timestep_number = int( tmp )
                if tmp - float(timestep_number) &gt; 0.5: timestep_number += 1 # select the nearest neighbor
                if  ( current_timestamp==start_of_current_year_timestamp  or  (current_timestamp - start_of_current_year_timestamp)/(60*120) ) % 60  !=  0: newfilenumber += 1 # file numbers start from 1
                if current_datetime.year == 2016: newfilenumber += 74
                if current_datetime.year == 2017: newfilenumber += 148
                
                # open the TIEGCM file if necessary
                if currentfilenumber &lt; 0   or   currentfilenumber != newfilenumber:
                    if currentfilenumber &gt;= 0: 
                        try:
                            tiegcm_CDF.close()
                        except:
                            print(&#34;Error closing tiegcm file no&#34;, currentfilenumber )
                    TIEGCMfilename = TIEGCM_filesPath + str(current_datetime.year) + &#34;/&#34; + TIEGCMfilenamePrefix + &#34;{:03.0f}&#34;.format(newfilenumber) + TIEGCMfilenamePostfix + &#34;.nc&#34;
                    currentfilenumber = newfilenumber
                    print(  &#34;Opening TIEGCMfile:&#34;, TIEGCMfilename)
                    try:
                        tiegcm_CDF = Dataset( TIEGCMfilename, &#39;r&#39; )
                    except Exception as ex:
                        print ( &#34;FILE NOT FOUND OR WRONG FORMAT:&#34;, TIEGCMfilename )
                        continue
                        
                # read Kp from the tiegcm file
                try:
                    current_Kp = tiegcm_CDF.variables[&#39;Kp&#39;][timestep_number]
                except:
                    #print(&#34;%%%%%%%%%%%%%%%%%%%%%&#34;)
                    #print(len(tiegcm_CDF.variables[&#39;Kp&#39;]), timestep_number)
                    #print( current_datetime, current_timestamp, start_of_current_year_timestamp )
                    #print(TIEGCMfilename)
                    #print(&#34;%%%%%%%%%%%%%%%%%%%%%&#34;)
                    try:
                        current_Kp = tiegcm_CDF.variables[&#39;Kp&#39;][timestep_number-1]
                    except:
                        #print( &#34;!! Timestep Error&#34;,  timestep_number) # &#34;of&#34;, len(tiegcm_CDF.variables[&#39;Kp&#39;]) )
                        continue
                    
                if current_Kp &gt;= Kp_min and current_Kp &lt;= Kp_max:
                    in_Kp_range = True 
                # if the satellite position matches a bin then mark it as a hit and remember the JH values 
                if in_MagLat_range and in_MLT_range and in_Altitude_range and in_Kp_range:
                    matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )
                    if matchedBin is not None:
                        # for this position locate the neighbor latitudes at the TIEGCM file. 
                        #lat1_idx, lat2_idx, lat1_val, lat2_val = findNeighborValues( TIEGCM_Lats, current_GeogLat )
                        # for this position locate the neighbor longitudes at the TIEGCM file.
                        #lon1_idx, lon2_idx, lon1_val, lon2_val = findNeighborValues( TIEGCM_Lons, current_Lon )
                        # for this position locate the neighbor Altitudes at the TIEGCM file. 
                        #lev1_idx, lev2_idx, lev1_val, lev2_val = findNeighborValues( CDFroot.variables[&#39;ZGMID&#39;][time_idx, :, lat_idx, lon_idx], current_Altitude )
                        current_JH = ORBIT_Ohmic[ idx ]
                        # save 
                        matchedBin.JH_values.append( current_JH )
                        matchedBin.MagLat_values.append( current_MagLat )
                        matchedBin.MLT_values.append( current_MLT )
                        matchedBin.Altitude_values.append( current_Altitude )
                        matchedBin.Lat_values.append( current_Lat )
                        matchedBin.Kp_values.append( current_Kp )
                        matchedBin.Time_values.append( current_timestamp )
                        matchedBin.EEX_values.append( ORBIT_EEX[ idx ] ) 
                        matchedBin.EEY_values.append( ORBIT_EEY[ idx ] ) 
                        matchedBin.Pedersen_values.append( ORBIT_Pedersen[ idx ] ) 
                        matchedBin.Density_values.append( ORBIT_Density[ idx ] ) 
                        if len(ORBIT_Lev) &gt; 0: matchedBin.Lev_values.append( ORBIT_Lev[ idx ] )
                        matchedBin.ConvectionHeating_values.append( ORBIT_ConvH[ idx ] )
                        matchedBin.WindHeating_values.append( ORBIT_WindH[ idx ] )
                        if len(ORBIT_Hall) &gt; 0: 
                            matchedBin.Hall_values.append( ORBIT_Hall[ idx ] ) 
                        all_JH_values.append( current_JH )
                        all_MagLat_values.append( current_MagLat )
                        all_MLT_values.append( current_MLT )
                        all_Altitude_values.append( current_Altitude )
                        all_Lat_values.append( current_Lat )
                        all_Kp_values.append( current_Kp )
                        all_Time_values.append( current_timestamp )
                        all_HittedBin_IDs.append( matchedBin.ID )
                        all_EEX_values.append( ORBIT_EEX[ idx ] )
                        all_EEY_values.append( ORBIT_EEY[ idx ] )
                        all_Pedersen_values.append( ORBIT_Pedersen[ idx ] )
                        all_Density_values.append( ORBIT_Density[ idx ] )
                        if len(ORBIT_Lev) &gt; 0: all_Lev_values.append( ORBIT_Lev[ idx ] )
                        all_ConvectionHeating_values.append( ORBIT_ConvH[ idx ] )
                        all_WindHeating_values.append( ORBIT_WindH[ idx ] )
                        if len(ORBIT_Hall) &gt; 0: all_Hall_values.append( ORBIT_Hall[ idx ] )
                        Matches += 1
                    else:
                        pass
                        #print( &#34;PARADOX at:&#34;, current_MLT, current_MagLat, current_Altitude, current_Kp, &#34; :: &#34;, time_idx, lev_idx, lat_idx, lon_idx )
            current_timestamp_offset += orbit_timestamp_step
    # save and clean up
    CalculateStatsOnData()
    SaveResults_CDF( ResultsFilename, &#34;&#34; ) 
    print( Matches, &#34;satellite positions where matched inside bins.&#34; )
    try:
        CDFroot.close()
    except:
        print (&#34;.&#34;)</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.AssignValuesPerBin_MultipleResultFiles"><code class="name flex">
<span>def <span class="ident">AssignValuesPerBin_MultipleResultFiles</span></span>(<span>TIEGCMfilesPath, ResultFilesPath)</span>
</code></dt>
<dd>
<div class="desc"><p>This function initiates the calculation.
It creates a Thread_ValueAssigner for each source file which resides in TIEGCMfilesPath
It also tells the thread to store the result file into ResultFilesPath</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AssignValuesPerBin_MultipleResultFiles( TIEGCMfilesPath, ResultFilesPath ):
    &#34;&#34;&#34;
    This function initiates the calculation. 
    It creates a Thread_ValueAssigner for each source file which resides in TIEGCMfilesPath
    It also tells the thread to store the result file into ResultFilesPath
    &#34;&#34;&#34;
    startSecs = time.time()

    if path.exists( ResultFilesPath ) == False:
        os.mkdir( ResultFilesPath )
    
    AllThreads = list()
    AllDataFiles = sorted( glob.glob( TIEGCMfilesPath + &#34;/*/*.nc&#34;, recursive=True ) )
    for currentDataFile in AllDataFiles:
        if &#39;\\&#39; in currentDataFile: #windows
            prefix = currentDataFile[ currentDataFile.rfind(&#39;\\&#39;)+1 : -3 ]
        else: # linux
            prefix = currentDataFile[ currentDataFile.rfind(&#39;/&#39;)+1 : -3 ]
        ResultsFilename = ResultFilesPath + currentDataFile[ currentDataFile.rfind(&#39;\\&#39;)+1 : -3 ] + &#34;.stats.nc&#34;
        if path.exists( ResultsFilename ): 
            print(&#34;Skipping because exists:&#34;, ResultsFilename)
            continue
        else:
            # wait if there are plenty alive threads
            alive_counter = 0
            for aThread in AllThreads:
                if aThread.is_alive():
                    alive_counter += 1
            while alive_counter &gt;= 5:
                time.sleep(random.randint(10, 15))
                alive_counter = 0
                for aThread in AllThreads:
                    if aThread.is_alive():
                        alive_counter += 1
            # spawn new thread
            CreateResults_CDF( ResultsFilename )
            T = Thread_ValueAssigner(currentDataFile, ResultsFilename)
            AllThreads.append(T)
            T.start()
            time.sleep(2)

    # wait for all threads to terminate
    for T in AllThreads: T.join()
    # finish it
    finishSecs = time.time()
    print( finishSecs-startSecs, &#34; sec&#34;)    </code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.CalculateStatsOnData"><code class="name flex">
<span>def <span class="ident">CalculateStatsOnData</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>This function uses the values assigned into the Bins to calculate mean, variance, deviation and stores them into the Bin class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CalculateStatsOnData():
    &#34;&#34;&#34;
    This function uses the values assigned into the Bins to calculate mean, variance, deviation and stores them into the Bin class.
    &#34;&#34;&#34;
    global Bins
    for B in Bins:
        if len(B.JH_values) &gt; 0:
            # calculate the mean value
            for aJHvalue in B.JH_values:
                if B.JH_min &gt; aJHvalue: B.JH_min = aJHvalue
                if B.JH_max &lt; aJHvalue: B.JH_max = aJHvalue
                B.JH_mean += aJHvalue
            B.JH_mean = B.JH_mean / len(B.JH_values)
            
            # calculate the median value
            B.JH_median = np.percentile(B.JH_values, 50)
            
            # for Variance (around mean):
            for aJHvalue in B.JH_values:
                B.JH_variance += abs(aJHvalue - B.JH_mean)**2
            B.JH_variance = B.JH_variance / len(B.JH_values)
            
            # for Median Variance (around median):
            for aJHvalue in B.JH_values:
                B.JH_medianVariance += abs(aJHvalue - B.JH_median)**2
            B.JH_medianVariance = B.JH_medianVariance / len(B.JH_values)
            
            # for Median absolute deviation
            AbsoluteDeviations = B.JH_values.copy()
            for i in range(0, len(AbsoluteDeviations)):
                AbsoluteDeviations[i] = abs(B.JH_median - AbsoluteDeviations[i])
            B.JH_medianAbsDev = np.percentile(AbsoluteDeviations, 50)</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.ClearBins"><code class="name flex">
<span>def <span class="ident">ClearBins</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Removes all Bins.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ClearBins():
    &#34;&#34;&#34;
        Removes all Bins.
    &#34;&#34;&#34;
    Bins.clear()     </code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.CreateNewBin"><code class="name flex">
<span>def <span class="ident">CreateNewBin</span></span>(<span>ID, Description, MagneticLocalTime_from, MagneticLocalTime_to, MagneticLatitude_from, MagneticLatitude_to, Altitude_from, Altitude_to, Kp_from, Kp_to, DesirableTime)</span>
</code></dt>
<dd>
<div class="desc"><p>Defines a new Bin according to the specified ranges.
All satellite positions which fall in these ranges will be assigned to this Bin.
The plots will be created according to all the defined Bins.
The library initializes certain predefined Bins. Call ClearBins() in order to remove them.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ID</code></strong> :&ensp;<code>string</code></dt>
<dd>a code name for this Bin. It will be displayed on the plots.</dd>
<dt><strong><code>Description</code></strong> :&ensp;<code>string</code></dt>
<dd>a description for this Bin. It will be displayed on the plots.</dd>
<dt><strong><code>MagneticLocalTime_from</code></strong></dt>
<dd>range for Magnetic-Local-Time of the Bin.</dd>
<dt><strong><code>MagneticLocalTime_to</code></strong></dt>
<dd>range for Magnetic-Local-Time of the Bin.</dd>
<dt><strong><code>MagneticLatitude_from</code></strong></dt>
<dd>range for Magnetic-Latitude of the Bin.</dd>
<dt><strong><code>MagneticLatitude_to</code></strong></dt>
<dd>range for Magnetic-Latitude of the Bin.</dd>
<dt><strong><code>Altitude_from</code></strong></dt>
<dd>range for Altitude of the Bin.</dd>
<dt><strong><code>Altitude_to</code></strong></dt>
<dd>range for Altitude of the Bin.</dd>
<dt><strong><code>Kp_from</code></strong></dt>
<dd>range for Kp-index of the Bin.</dd>
<dt><strong><code>Kp_to</code></strong></dt>
<dd>range for Kp-index of the Bin.</dd>
<dt><strong><code>DesirableTime</code></strong></dt>
<dd>(seconds) The minimun time for the satellite to stay inside the Bin in order to accomplish its mission.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CreateNewBin( ID, Description, MagneticLocalTime_from, MagneticLocalTime_to, MagneticLatitude_from, MagneticLatitude_to, Altitude_from, Altitude_to, Kp_from, Kp_to, DesirableTime ):
    &#34;&#34;&#34;
        Defines a new Bin according to the specified ranges.
        All satellite positions which fall in these ranges will be assigned to this Bin. 
        The plots will be created according to all the defined Bins.
        The library initializes certain predefined Bins. Call ClearBins() in order to remove them.
        Args:
            ID (string): a code name for this Bin. It will be displayed on the plots.
            Description (string): a description for this Bin. It will be displayed on the plots.
            MagneticLocalTime_from: range for Magnetic-Local-Time of the Bin.
            MagneticLocalTime_to: range for Magnetic-Local-Time of the Bin.
            MagneticLatitude_from: range for Magnetic-Latitude of the Bin.
            MagneticLatitude_to: range for Magnetic-Latitude of the Bin.
            Altitude_from: range for Altitude of the Bin.
            Altitude_to: range for Altitude of the Bin.
            Kp_from: range for Kp-index of the Bin.
            Kp_to: range for Kp-index of the Bin.
            DesirableTime: (seconds) The minimun time for the satellite to stay inside the Bin in order to accomplish its mission.
    &#34;&#34;&#34;
    Bins.append( Bin(ID, Description, MagneticLocalTime_from, MagneticLocalTime_to, MagneticLatitude_from, MagneticLatitude_to, Altitude_from, Altitude_to, Kp_from, Kp_to, DesirableTime) )</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.CreateResults_CDF"><code class="name flex">
<span>def <span class="ident">CreateResults_CDF</span></span>(<span>ResultsFilename, CALCULATIONS_Title='', CALCULATIONS_Description='', CALCULATIONS_RegionName='', CALCULATIONS_OrbitFilesPath='', CALCULATIONS_TIEGCMfolder='')</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a results NetCDF file and its structure. The file will contain no date.
The optional parameters are extra information to be added to the result-file.
Args:
ResultsFilename: the full or relative path and filename to be created.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CreateResults_CDF( ResultsFilename,  CALCULATIONS_Title=&#34;&#34;, CALCULATIONS_Description=&#34;&#34;, CALCULATIONS_RegionName=&#34;&#34;, CALCULATIONS_OrbitFilesPath=&#34;&#34;, CALCULATIONS_TIEGCMfolder=&#34;&#34;):
    &#34;&#34;&#34;
        Creates a results NetCDF file and its structure. The file will contain no date.
        The optional parameters are extra information to be added to the result-file.
        Args: 
            ResultsFilename: the full or relative path and filename to be created.
    &#34;&#34;&#34;
    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values, all_Kp_values, all_Time_values, all_EEX_values, all_EEY_values, all_Pedersen_values, all_Density_values, all_Lev_values, all_Hall_values
    # save general info
    resultsCDF = Dataset( ResultsFilename, &#39;w&#39; )
    resultsCDF.Content         = &#34;JOULE HEATING per BIN RESULTS. This file contains information about the bins in which the thermosphere is divided according to Magnetic Latitude, Magnetic Local Time, Altitude and Kp-index. We say there is a hit inside a bin when a satellite position or TIEGCM-grid position lies inside the above boundaries. The file contains data for each hit inside a bin. That is the position&#39;s MagLat, MLT, Alt, Kp and Joule-Heating value&#34;
    resultsCDF.DateOfCreation  = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
    resultsCDF.DateOfUpdate    = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
    resultsCDF.Title           = CALCULATIONS_Title
    resultsCDF.Region          = CALCULATIONS_RegionName
    resultsCDF.OrbitFile       = CALCULATIONS_OrbitFilesPath
    resultsCDF.Description     = CALCULATIONS_Description
    resultsCDF.DataPath        = CALCULATIONS_TIEGCMfolder
    resultsCDF.LastExecDurationSec = 0
    resultsCDF.Progress        = &#34;&#34;
    # save data for each bin spearately 
    resultsCDF.createDimension( &#34;SingleSpaceFooDimension&#34;, 1 )
    resultsCDF.createDimension(&#39;char8&#39;, 8)
    for B in Bins:
        # save general info about the bin
        VAR_BinInfo = resultsCDF.createVariable( B.ID, &#34;S1&#34;, (&#34;SingleSpaceFooDimension&#34;,) )
        VAR_BinInfo.long_name    = &#34;Information about the bin &#34; + B.ID + &#34; (&#34; + B.Description + &#34;)&#34;
        VAR_BinInfo.MagLat_min   = &#34;{:02.0f}&#34;.format(B.MagLat_min)
        VAR_BinInfo.MagLat_max   = &#34;{:02.0f}&#34;.format(B.MagLat_max)
        VAR_BinInfo.MLT_min      = &#34;{:02.0f}&#34;.format(B.MLT_min)
        VAR_BinInfo.MLT_max      = &#34;{:02.0f}&#34;.format(B.MLT_max)
        VAR_BinInfo.Altitude_min = &#34;{:02.0f}&#34;.format(B.Altitude_min)
        VAR_BinInfo.Altitude_max = &#34;{:02.0f}&#34;.format(B.Altitude_max)
        VAR_BinInfo.Lat_min       = &#34;{:02.0f}&#34;.format(B.Lat_min)
        VAR_BinInfo.Lat_max       = &#34;{:02.0f}&#34;.format(B.Lat_max)
        VAR_BinInfo.Kp_min       = &#34;{:02.0f}&#34;.format(B.Kp_min)
        VAR_BinInfo.Kp_max       = &#34;{:02.0f}&#34;.format(B.Kp_max)
        VAR_BinInfo.JH_mean      = &#34;{:.3e}&#34;.format(B.JH_mean)
        VAR_BinInfo.JH_variance  = &#34;{:.3e}&#34;.format(B.JH_variance)
        VAR_BinInfo.DesirableCumulativeTime = str(B.DesirableCumulativeTime) + &#34;sec&#34;
        if B.JH_min == 99999: 
            VAR_BinInfo.JH_min = &#34;&#34;
        else:
            VAR_BinInfo.JH_min = &#34;{:.3e}&#34;.format(B.JH_min)
        # create structure for each bin
        resultsCDF.createDimension( B.ID+&#34;_time_dim&#34;, None )
        VAR_BinTimeValues             = resultsCDF.createVariable( B.ID+&#34;_TimeValues&#34;, &#34;f4&#34;, (B.ID+&#34;_time_dim&#34;,) )
        VAR_BinTimeValues.description = &#34;UTC timestamp&#34;
        VAR_BinTimeValues.units       = &#34;seconds&#34;
        resultsCDF.createDimension( B.ID+&#34;_jh_dim&#34;, None )
        VAR_BinJHvalues = resultsCDF.createVariable( B.ID+&#34;_JHValues&#34;, &#34;f4&#34;, (B.ID+&#34;_jh_dim&#34;,) )
        VAR_BinJHvalues.description = &#34;Ohmic&#34;
        VAR_BinJHvalues.units       = &#34;W/m3&#34;
        resultsCDF.createDimension( B.ID+&#34;_maglat_dim&#34;, None )
        VAR_BinMagLatValues = resultsCDF.createVariable( B.ID+&#34;_MagLatValues&#34;, &#34;f4&#34;, (B.ID+&#34;_maglat_dim&#34;,) )
        VAR_BinMagLatValues.description = &#34;Magnetic Latitude&#34;
        VAR_BinMagLatValues.units       = &#34;degrees&#34;
        resultsCDF.createDimension( B.ID+&#34;_mlt_dim&#34;, None )
        VAR_BinMLTValues = resultsCDF.createVariable( B.ID+&#34;_MLTValues&#34;, &#34;f4&#34;, (B.ID+&#34;_mlt_dim&#34;,) )
        VAR_BinMLTValues.description = &#34;Magnetic Local Time&#34;
        VAR_BinMLTValues.units       = &#34;hours&#34;
        resultsCDF.createDimension( B.ID+&#34;_alt_dim&#34;, None )
        VAR_BinAltitudeValues = resultsCDF.createVariable( B.ID+&#34;_AltitudeValues&#34;, &#34;f4&#34;, (B.ID+&#34;_alt_dim&#34;,) )
        VAR_BinAltitudeValues.description = &#34;Altitude from the surface of the Earth&#34;
        VAR_BinAltitudeValues.units       = &#34;km&#34;
        resultsCDF.createDimension( B.ID+&#34;_lat_dim&#34;, None )
        VAR_BinLatValues = resultsCDF.createVariable( B.ID+&#34;_LatValues&#34;, &#34;f4&#34;, (B.ID+&#34;_lat_dim&#34;,) )
        VAR_BinLatValues.description = &#34;Latitude&#34;
        VAR_BinLatValues.units       = &#34;degrees&#34;
        resultsCDF.createDimension( B.ID+&#34;_kp_dim&#34;, None )
        VAR_BinKpValues = resultsCDF.createVariable( B.ID+&#34;_KpValues&#34;, &#34;f4&#34;, (B.ID+&#34;_kp_dim&#34;,) )
        VAR_BinKpValues.description = &#34;Kp index of Sun activity&#34;
        VAR_BinKpValues.units       = &#34;-&#34;
        resultsCDF.createDimension( B.ID+&#34;_eex_dim&#34;, None )
        VAR_BinEEXValues = resultsCDF.createVariable( B.ID+&#34;_EEXValues&#34;, &#34;f4&#34;, (B.ID+&#34;_eex_dim&#34;,) )
        VAR_BinEEXValues.description = &#34;Electric field strength East. (SI)&#34;
        VAR_BinEEXValues.units       = &#34;V/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_eey_dim&#34;, None )
        VAR_BinEEYValues = resultsCDF.createVariable( B.ID+&#34;_EEYValues&#34;, &#34;f4&#34;, (B.ID+&#34;_eey_dim&#34;,) )
        VAR_BinEEYValues.description = &#34;Electric field strength North. (SI)&#34;
        VAR_BinEEYValues.units       = &#34;V/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_ped_dim&#34;, None )
        VAR_BinPedersenValues = resultsCDF.createVariable( B.ID+&#34;_PedersenValues&#34;, &#34;f4&#34;, (B.ID+&#34;_ped_dim&#34;,) )
        VAR_BinPedersenValues.description = &#34;SIGMA_PED&#34;
        VAR_BinPedersenValues.units       = &#34;S/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_den_dim&#34;, None )
        VAR_BinDensityValues = resultsCDF.createVariable( B.ID+&#34;_DensityValues&#34;, &#34;f4&#34;, (B.ID+&#34;_den_dim&#34;,) )
        VAR_BinDensityValues.description = &#34;Total Density&#34;
        VAR_BinDensityValues.units       = &#34;g/cm3&#34;
        resultsCDF.createDimension( B.ID+&#34;_lev_dim&#34;, None )
        VAR_BinLevValues = resultsCDF.createVariable( B.ID+&#34;_LevValues&#34;, &#34;f4&#34;, (B.ID+&#34;_lev_dim&#34;,) )
        VAR_BinLevValues.description = &#34;midpoint levels&#34;
        VAR_BinLevValues.units       = &#34;&#34;
        resultsCDF.createDimension( B.ID+&#34;_hal_dim&#34;, None )
        VAR_BinHallValues = resultsCDF.createVariable( B.ID+&#34;_HallValues&#34;, &#34;f4&#34;, (B.ID+&#34;_hal_dim&#34;,) )
        VAR_BinHallValues.description = &#34;SIGMA_HAL&#34;
        VAR_BinHallValues.units       = &#34;S/m&#34;
        resultsCDF.createDimension( B.ID+&#34;_convh_dim&#34;, None )
        VAR_BinConvhValues = resultsCDF.createVariable( B.ID+&#34;_ConvectionHeatingValues&#34;, &#34;f4&#34;, (B.ID+&#34;_convh_dim&#34;,) )
        VAR_BinConvhValues.description = &#34;Convection Heating&#34;
        VAR_BinConvhValues.units       = &#34;W/m3&#34;
        resultsCDF.createDimension( B.ID+&#34;_windh_dim&#34;, None )
        VAR_BinWindhValues = resultsCDF.createVariable( B.ID+&#34;_WindHeatingValues&#34;, &#34;f4&#34;, (B.ID+&#34;_windh_dim&#34;,) )
        VAR_BinWindhValues.description = &#34;Wind Correction&#34;
        VAR_BinWindhValues.units       = &#34;W/m3&#34;
    ## save data for all hits
    resultsCDF.createDimension( &#34;time_dim&#34;, None )
    VAR_TimeValues         = resultsCDF.createVariable(&#34;allTimeValues&#34;, &#34;f4&#34;, (&#34;time_dim&#34;,) )
    VAR_TimeValues.description = &#34;UTC timestamp&#34;
    VAR_TimeValues.units       = &#34;seconds&#34;
    resultsCDF.createDimension( &#34;jh_dim&#34;, None )
    VAR_JHvalues = resultsCDF.createVariable(&#34;allJHValues&#34;, &#34;f4&#34;, (&#34;jh_dim&#34;,) )
    VAR_JHvalues.description = &#34;Ohmic&#34;
    VAR_JHvalues.units       = &#34;W/m3&#34;
    resultsCDF.createDimension( &#34;maglat_dim&#34;, None )
    VAR_MagLatValues = resultsCDF.createVariable(&#34;allMagLatValues&#34;, &#34;f4&#34;, (&#34;maglat_dim&#34;,) )
    VAR_MagLatValues.description = &#34;Magnetic Latitude&#34;
    VAR_MagLatValues.units       = &#34;degrees&#34;
    resultsCDF.createDimension( &#34;mlt_dim&#34;, None )
    VAR_MLTValues = resultsCDF.createVariable(&#34;allMLTValues&#34;, &#34;f4&#34;, (&#34;mlt_dim&#34;,) )
    VAR_MLTValues.description = &#34;Magnetic Local Time&#34;
    VAR_MLTValues.units       = &#34;hours&#34;
    resultsCDF.createDimension( &#34;alt_dim&#34;, None )
    VAR_AltitudeValues = resultsCDF.createVariable(&#34;allAltitudeValues&#34;, &#34;f4&#34;, (&#34;alt_dim&#34;,) )
    VAR_AltitudeValues.description = &#34;Altitude from the surface of the Earth&#34;
    VAR_AltitudeValues.units       = &#34;km&#34;
    resultsCDF.createDimension( &#34;lat_dim&#34;, None )
    VAR_LatValues = resultsCDF.createVariable(&#34;allLatValues&#34;, &#34;f4&#34;, (&#34;lat_dim&#34;,) )
    VAR_LatValues.description = &#34;Latitude&#34;
    VAR_LatValues.units       = &#34;degrees&#34;
    resultsCDF.createDimension( &#34;kp_dim&#34;, None )
    VAR_KpValues = resultsCDF.createVariable(&#34;allKpValues&#34;, &#34;f4&#34;, (&#34;kp_dim&#34;,) )
    VAR_KpValues.description = &#34;Kp index of Sun activity&#34;
    VAR_KpValues.units       = &#34;-&#34;
    resultsCDF.createDimension( &#34;bins_dim&#34;, None )
    VAR_HittedBinIDs = resultsCDF.createVariable(&#34;allHittedBinIDs&#34;, &#34;S1&#34;, (&#34;bins_dim&#34;,&#34;char8&#34;,) )
    VAR_HittedBinIDs.description = &#34;The ID of the bin, where the hit occured&#34;
    resultsCDF.createDimension( &#34;eex_dim&#34;, None )
    VAR_EEXvalues = resultsCDF.createVariable(&#34;allEEXValues&#34;, &#34;f4&#34;, (&#34;eex_dim&#34;,) )
    VAR_EEXvalues.description = &#34;Electric field strength East. (SI)&#34;
    VAR_EEXvalues.units       = &#34;V/m&#34;
    resultsCDF.createDimension( &#34;eey_dim&#34;, None )
    VAR_EEYvalues = resultsCDF.createVariable(&#34;allEEYValues&#34;, &#34;f4&#34;, (&#34;eey_dim&#34;,) )
    VAR_EEYvalues.description = &#34;Electric field strength North. (SI)&#34;
    VAR_EEYvalues.units       = &#34;V/m&#34;
    resultsCDF.createDimension( &#34;ped_dim&#34;, None )
    VAR_Pedersenvalues = resultsCDF.createVariable(&#34;allPedersenValues&#34;, &#34;f4&#34;, (&#34;ped_dim&#34;,) )
    VAR_Pedersenvalues.description = &#34;Pedersen Conductivity&#34;
    VAR_Pedersenvalues.units       = &#34;S/m&#34;
    resultsCDF.createDimension( &#34;den_dim&#34;, None )
    VAR_Densityvalues = resultsCDF.createVariable(&#34;allDensityValues&#34;, &#34;f4&#34;, (&#34;den_dim&#34;,) )
    VAR_Densityvalues.description = &#34;Total Density&#34;
    VAR_Densityvalues.units       = &#34;g/cm3&#34;
    resultsCDF.createDimension( &#34;lev_dim&#34;, None )
    VAR_LevValues = resultsCDF.createVariable(&#34;allLevValues&#34;, &#34;f4&#34;, (&#34;lev_dim&#34;,) )
    VAR_LevValues.description = &#34;midpoint levels&#34;
    VAR_LevValues.units       = &#34;&#34;
    resultsCDF.createDimension( &#34;hal_dim&#34;, None )
    VAR_Hallvalues = resultsCDF.createVariable(&#34;allHallValues&#34;, &#34;f4&#34;, (&#34;hal_dim&#34;,) )
    VAR_Hallvalues.description = &#34;Hall Conductivity&#34;
    VAR_Hallvalues.units       = &#34;S/m&#34;
    resultsCDF.createDimension( &#34;convh_dim&#34;, None )
    VAR_ConvhValues = resultsCDF.createVariable(&#34;allConvectionHeatingValues&#34;, &#34;f4&#34;, (&#34;convh_dim&#34;,) )
    VAR_ConvhValues.description = &#34;Convection Heating&#34;
    VAR_ConvhValues.units       = &#34;W/m3&#34;
    resultsCDF.createDimension( &#34;windh_dim&#34;, None )
    VAR_WindhValues = resultsCDF.createVariable(&#34;allWindHeatingValues&#34;, &#34;f4&#34;, (&#34;windh_dim&#34;,) )
    VAR_WindhValues.description = &#34;Wind Correction&#34;
    VAR_WindhValues.units       = &#34;W/m3&#34;
    resultsCDF.close()</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.GetMatchedBin"><code class="name flex">
<span>def <span class="ident">GetMatchedBin</span></span>(<span>MLT, MagLat, Altitude, Kp, Latitude)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds and returns the Bin object which matches the position of the satellite described by the arguments.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>MLT</code></strong></dt>
<dd>the Magnetic Local Time</dd>
<dt><strong><code>MagLat</code></strong></dt>
<dd>The Magnetic Latitude</dd>
<dt><strong><code>Altitude</code></strong></dt>
<dd>The Altitude</dd>
<dt><strong><code>Kp</code></strong></dt>
<dd>the Kp-index</dd>
<dt><strong><code>Latitude</code></strong></dt>
<dd>the Latitude</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="DaedalusMASE_Global_Statistics.data.Bin" href="#DaedalusMASE_Global_Statistics.data.Bin">Bin</a></code></dt>
<dd>the Bin in which the position represented by the arguments is matched.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetMatchedBin( MLT, MagLat, Altitude, Kp, Latitude ):
    &#34;&#34;&#34;
        Finds and returns the Bin object which matches the position of the satellite described by the arguments.
        
        Args:
                MLT: the Magnetic Local Time
                MagLat: The Magnetic Latitude
                Altitude: The Altitude
                Kp: the Kp-index
                Latitude: the Latitude
        Returns:
                Bin: the Bin in which the position represented by the arguments is matched.
    &#34;&#34;&#34;    
    MatchedBin = None
    for B in Bins:
        if Latitude &gt;= B.Lat_min  and  Latitude &lt;= B.Lat_max:
            if is_MLT_inside_range(MLT, B.MLT_min, B.MLT_max):
                if MagLat   &gt; B.MagLat_min    and  MagLat   &lt;= B.MagLat_max:
                    if Altitude &gt; B.Altitude_min  and  Altitude &lt;= B.Altitude_max:
                        Kp_min_to_check = B.Kp_min
                        if Kp_min_to_check == 0: Kp_min_to_check = -1
                        if Kp       &gt; Kp_min_to_check and  Kp       &lt;= B.Kp_max:
                            MatchedBin = B
                            break
    return MatchedBin</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.LoadResults_CDF"><code class="name flex">
<span>def <span class="ident">LoadResults_CDF</span></span>(<span>filepath, VariableToLoad, loadBinValues=True, loadGlobalValues=True, loadTimeValues=True, loadMagLatValues=True, loadMLTvalues=True, loadAltValues=True, loadLatValues=True, loadKpValues=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads the calculation results from a netcdf result-file and fills with data the corresponding Bins.
User must choose a Variable to work with (see start of this module for available variables).
User can choose which other parallel data to load in order to produce the plots he is interested in, in order to speed up loading</p>
<pre><code>Args: 
     filepath: the netcdf result-file to be loaded
     VariableToLoad: the variable which the user is interested in. Only data about this variable will be loaded
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def LoadResults_CDF( filepath, VariableToLoad, loadBinValues=True, loadGlobalValues=True, loadTimeValues=True, loadMagLatValues=True, loadMLTvalues=True, loadAltValues=True, loadLatValues=True, loadKpValues=True ):
    &#34;&#34;&#34;
    Reads the calculation results from a netcdf result-file and fills with data the corresponding Bins.
    User must choose a Variable to work with (see start of this module for available variables).
    User can choose which other parallel data to load in order to produce the plots he is interested in, in order to speed up loading
        
        Args: 
             filepath: the netcdf result-file to be loaded
             VariableToLoad: the variable which the user is interested in. Only data about this variable will be loaded
    &#34;&#34;&#34;
    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration
    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values, all_Kp_values, all_Time_values, all_EEX_values, all_EEY_values, all_Pedersen_values, all_Density_values, all_Lev_values, all_Hall_values

    # reset values
    for B in Bins:
        B.reset()
    all_JH_values.clear()
    all_MagLat_values.clear()
    all_MLT_values.clear()
    all_Altitude_values.clear()
    all_Lat_values.clear()
    all_Kp_values.clear() 
    all_Time_values.clear()
    all_HittedBin_IDs.clear()
    all_EEX_values.clear()
    all_EEY_values.clear()
    all_Pedersen_values.clear()
    all_Density_values.clear()
    all_Lev_values.clear()
    all_Hall_values.clear()
    all_ConvectionHeating_values.clear()
    all_WindHeating_values.clear()
    
    print( &#34;Started Loading&#34;, filepath, datetime.now() )

    # make a list of all the files we are going to load
    All_ResultFilenames = list()
    if filepath[-1] == &#39;/&#39;:
        All_ResultFilenames = sorted( glob.glob(filepath+&#34;*.nc&#34;) )
    else:
        All_ResultFilenames.append( filepath )
    
    # load each file into memory
    for file_idx in range(0, len(All_ResultFilenames)):
        if file_idx % 10 == 0: print( &#34;Now Loading&#34;, All_ResultFilenames[file_idx] )
        #if file_idx == 30: break
        resultsCDF = Dataset( All_ResultFilenames[file_idx], &#39;r&#39; )
        #### load general information
        if file_idx == 0:
            try:
                print( &#34;DateOfCreation:&#34;, resultsCDF.DateOfCreation, &#34; LastExecDurationSec :&#34;, resultsCDF.LastExecDurationSec , &#34;sec&#34; )
                #print( &#34;Title:&#34;, resultsCDF.Title, &#34; Description:&#34;, resultsCDF.Description )
                print( &#34;Region:&#34;, resultsCDF.Region )
                print( &#34;OrbitFile:&#34;, resultsCDF.OrbitFile )
                print( &#34;TIEGCM data path:&#34;, resultsCDF.DataPath, &#34;\n&#34; )
                #print( &#34;Progress:&#34;, resultsCDF.Progress, &#34;\n&#34; )
            except:
                pass
            CALCULATIONS_Title = resultsCDF.Title
            CALCULATIONS_Description = resultsCDF.Description
            #CALCULATIONS_ExecutionDuration = resultsCDF.LastExecDurationSec
            CALCULATIONS_RegionName = resultsCDF.Region
            CALCULATIONS_OrbitFilesPath = resultsCDF.OrbitFile.split()
            CALCULATIONS_TIEGCMfolder = resultsCDF.DataPath
        #### load data for each bin
        if loadBinValues:
            for B in Bins:
                try:
                    if loadTimeValues and len(CALCULATIONS_OrbitFilesPath) &gt; 0: concatLists( B.Time_values, list(resultsCDF.variables[ B.ID+&#34;_TimeValues&#34; ][:]) )
                    if loadMagLatValues: concatLists( B.MagLat_values, list(resultsCDF.variables[ B.ID+&#34;_MagLatValues&#34; ][:]) )
                    if loadMLTvalues: concatLists( B.MLT_values, list(resultsCDF.variables[ B.ID+&#34;_MLTValues&#34; ][:]) )
                    if loadAltValues: concatLists( B.Altitude_values, list(resultsCDF.variables[ B.ID+&#34;_AltitudeValues&#34; ][:]) )
                    try:
                        if loadLatValues: concatLists(B.Lat_values, list(resultsCDF.variables[ B.ID+&#34;_LatValues&#34; ][:]) )
                    except:
                        pass
                    if loadKpValues: concatLists(B.Kp_values, list(resultsCDF.variables[ B.ID+&#34;_KpValues&#34; ][:]) )
                    if VariableToLoad == &#34;Ohmic&#34;:    
                        Ohmics = resultsCDF.variables[ B.ID+&#34;_ConvectionHeatingValues&#34; ][:] + resultsCDF.variables[ B.ID+&#34;_WindHeatingValues&#34; ][:]
                        concatLists( B.JH_values, list(Ohmics) ) #    if VariableToLoad == &#34;Ohmic&#34;:     concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_ConvenctionHeatingValues&#34; ][:]+resultsCDF.variables[ B.ID+&#34;_WindHeatingValues&#34; ][:]) )
                    if VariableToLoad == &#34;EEX&#34;:    concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_EEXValues&#34; ][:])*1000 ) #if VariableToLoad == &#34;EEX_si&#34;:    B.EEX_values = list(resultsCDF.variables[ B.ID+&#34;_EEXValues&#34; ][:])
                    if VariableToLoad == &#34;EEY&#34;:    concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_EEYValues&#34; ][:])*1000 ) #if VariableToLoad == &#34;EEY_si&#34;:    B.EEY_values = list(resultsCDF.variables[ B.ID+&#34;_EEYValues&#34; ][:])
                    if VariableToLoad == &#34;SIGMA_PED&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_PedersenValues&#34; ][:]) ) #if VariableToLoad == &#34;SIGMA_PED&#34;: B.Pedersen_values = list(resultsCDF.variables[ B.ID+&#34;_PedersenValues&#34; ][:])
                    if VariableToLoad == &#34;SIGMA_HAL&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_HallValues&#34; ][:]) ) #if VariableToLoad == &#34;SIGMA_HAL&#34;: B.Hall_values = list(resultsCDF.variables[ B.ID+&#34;_HallValues&#34; ][:])
                    try:
                        if VariableToLoad == &#34;Convection_heating&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_ConvectionHeatingValues&#34; ][:]) )
                    except:
                        if VariableToLoad == &#34;Convection_heating&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_ConvenctionHeatingValues&#34; ][:]) )
                    if VariableToLoad == &#34;Wind_heating&#34;: concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+&#34;_WindHeatingValues&#34; ][:]) )
                except: # data about this region do not exist inside this netcdf file
                    continue
        #### load collective data about all bins
        if loadGlobalValues:
            if loadTimeValues and len(CALCULATIONS_OrbitFilesPath) &gt; 0: concatLists( all_Time_values, list(resultsCDF.variables[ &#34;allTimeValues&#34; ][:]) )
            if loadMagLatValues:  concatLists( all_MagLat_values, list(resultsCDF.variables[ &#34;allMagLatValues&#34; ][:]) )
            if loadMLTvalues: concatLists( all_MLT_values, list(resultsCDF.variables[ &#34;allMLTValues&#34; ][:]) )
            if loadAltValues: concatLists( all_Altitude_values, list(resultsCDF.variables[ &#34;allAltitudeValues&#34; ][:]) )
            try:
                if loadLatValues: concatLists( all_Lat_values, list(resultsCDF.variables[ &#34;allLatValues&#34; ][:]) )
            except:
                pass
            if loadKpValues: concatLists( all_Kp_values, list(resultsCDF.variables[ &#34;allKpValues&#34; ][:]) )
            if VariableToLoad == &#34;Ohmic&#34;: 
                Ohmics = resultsCDF.variables[ &#34;allConvectionHeatingValues&#34; ][:] + resultsCDF.variables[ &#34;allWindHeatingValues&#34; ][:]
                concatLists( all_JH_values, list(Ohmics) ) #if VariableToLoad == &#34;Ohmic&#34;:     concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allConvenctionHeatingValues&#34; ][:] + resultsCDF.variables[ &#34;allWindHeatingValues&#34; ][:]) )
            if VariableToLoad == &#34;EEX&#34;:    concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allEEXValues&#34; ][:]*1000) )#if VariableToLoad == &#34;EEX_si&#34;:    all_EEX_values = list(resultsCDF.variables[ &#34;allEEXValues&#34; ][:])
            if VariableToLoad == &#34;EEY&#34;:    concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allEEYValues&#34; ][:]*1000) )#if VariableToLoad == &#34;EEY_si&#34;:    all_EEY_values = list(resultsCDF.variables[ &#34;allEEYValues&#34; ][:])
            if VariableToLoad == &#34;SIGMA_PED&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allPedersenValues&#34; ][:]) )#if VariableToLoad == &#34;SIGMA_PED&#34;: all_Pedersen_values = list(resultsCDF.variables[ &#34;allPedersenValues&#34; ][:])
            if VariableToLoad == &#34;SIGMA_HAL&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allHallValues&#34; ][:]) )#if VariableToLoad == &#34;SIGMA_HAL&#34;: all_Hall_values = list(resultsCDF.variables[ &#34;allHallValues&#34; ][:])
            if VariableToLoad == &#34;JH/mass&#34;:   concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allJHValues&#34; ][:]/(1000*resultsCDF.variables[ &#34;allDensityValues&#34; ][:]) ) )
            if VariableToLoad == &#34;JH/pressure&#34;: 
                #newVals = np.zeros( len(resultsCDF.variables[ &#34;allJHValues&#34; ]) )
                #for i in range( 0, len(resultsCDF.variables[ &#34;allJHValues&#34; ]) ):
                #    newVals[i] = resultsCDF.variables[ &#34;allJHValues&#34; ][i]/(0.00005*math.exp(-resultsCDF.variables[ &#34;allLevValues&#34; ][i]) )  
                #concatLists( all_JH_values, list(newVals) )
                #print( &#34;QQQQ &#34;, resultsCDF.variables[ &#34;allJHValues&#34; ][1], resultsCDF.variables[ &#34;allJHValues&#34; ][1000] )
                #print( &#34;QQQQ &#34;, resultsCDF.variables[ &#34;allAltitudeValues&#34; ][1],  resultsCDF.variables[ &#34;allAltitudeValues&#34; ][1000] )
                concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allJHValues&#34; ][:]/(0.00005*np.exp(-resultsCDF.variables[ &#34;allLevValues&#34; ][:]) ) ) )
            try:
                if VariableToLoad == &#34;Convection_heating&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allConvectionHeatingValues&#34; ][:]) )
            except:
                if VariableToLoad == &#34;Convection_heating&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allConvenctionHeatingValues&#34; ][:]) )
            if VariableToLoad == &#34;Wind_heating&#34;: concatLists( all_JH_values, list(resultsCDF.variables[ &#34;allWindHeatingValues&#34; ][:]) )
        #### close and go on
        resultsCDF.close()
    ########
    
    # !!!! remove incorrect huge or negative Ohmic values
    if (VariableToLoad == &#34;Ohmic&#34;)  and  (&#34;Hz&#34; in filepath or &#34;Tri&#34; in filepath):
        # for each bin
        for B in Bins:
            if len(B.JH_values): print(B.ID, &#34;LENGTH BEFORE:&#34;, len(B.JH_values))
            huge_values = 0
            negative_values = 0
            nan_values = 0
            found_at_current_round = True
            while found_at_current_round:
                found_at_current_round = False
                for t in range(0, len(B.JH_values)):
                    if B.JH_values[t] &gt; 100 or B.JH_values[t] == float(&#34;inf&#34;):  huge_values += 1
                    if B.JH_values[t] &lt; 0   or B.JH_values[t] == float(&#34;-inf&#34;): negative_values += 1
                    if np.isnan(B.JH_values[t]): nan_values += 1
                    if B.JH_values[t]&gt;100 or B.JH_values[t]&lt;0 or np.isnan(B.JH_values[t]) or B.JH_values[t]==float(&#34;inf&#34;) or B.JH_values[t]==float(&#34;-inf&#34;):
                        found_at_current_round = True
                        del B.JH_values[t]
                        if len(B.Time_values) &gt; 0: del B.Time_values[t]
                        if len(B.MagLat_values) &gt; 0: del B.MagLat_values[t]
                        if len(B.MLT_values) &gt; 0: del B.MLT_values[t]
                        if len(B.Altitude_values) &gt; 0: del B.Altitude_values[t]
                        if len(B.Lat_values) &gt; 0: del B.Lat_values[t]
                        if len(B.Kp_values) &gt; 0: del B.Kp_values[t]
                        break
            if len(B.JH_values): print( B.ID, &#34;:&#34;,  &#34;huge values =&#34;, huge_values, &#34;negative values =&#34;, negative_values, &#34;nan values =&#34;, nan_values )
            if len(B.JH_values): print(B.ID, &#34;LENGTH AFTER:&#34;, len(B.JH_values))
        # for arrays with all the data
        print(&#34;ALL&#34;, &#34;LENGTH BEFORE:&#34;, len(all_JH_values))
        huge_values = 0
        negative_values = 0
        nan_values = 0
        found_at_current_round = True
        while found_at_current_round:
            found_at_current_round = False
            for t in range(0, len(all_JH_values)):
                if all_JH_values[t] &gt; 100 or all_JH_values[t] == float(&#34;inf&#34;):  huge_values += 1
                if all_JH_values[t] &lt; 0   or all_JH_values[t] == float(&#34;-inf&#34;): negative_values += 1
                if np.isnan(all_JH_values[t]): nan_values += 1
                if all_JH_values[t]&gt;100 or all_JH_values[t]&lt;0 or np.isnan(all_JH_values[t]) or all_JH_values[t]==float(&#34;inf&#34;) or all_JH_values[t]==float(&#34;-inf&#34;):
                    found_at_current_round = True
                    del all_JH_values[t]
                    if len(all_Time_values) &gt; 0: del all_Time_values[t]
                    if len(all_MagLat_values) &gt; 0: del all_MagLat_values[t]
                    if len(all_MLT_values) &gt; 0: del all_MLT_values[t]
                    if len(all_Altitude_values) &gt; 0: del all_Altitude_values[t]
                    if len(all_Lat_values) &gt; 0: del all_Lat_values[t]
                    if len(all_Kp_values) &gt; 0: del all_Kp_values[t]
                    break
        #print( &#34;Globaly&#34;, &#34;:&#34;,  &#34;huge values =&#34;, huge_values, &#34;negative values =&#34;, negative_values, &#34;nan values =&#34;, nan_values )
        #print(&#34;ALL&#34;, &#34;LENGTH AFTER:&#34;, len(all_JH_values))
    else:
        pass
        #print( &#34;NO correct value check:&#34;, VariableToLoad , filepath )
    ########
    CalculateStatsOnData()
    print( &#34;Results loaded for&#34;, VariableToLoad, &#34;    &#34;, datetime.now(), &#34;\n&#34; )</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.SaveResults_CDF"><code class="name flex">
<span>def <span class="ident">SaveResults_CDF</span></span>(<span>ResultsFilename, DataFilename)</span>
</code></dt>
<dd>
<div class="desc"><p>Append the results in a NetCDF file which can contain results of several calculations.
The data will be saved in ResultsFilename and they come from calculations on the netcdf DataFilename.
DataFilename is needed to check if the file contains already the results of calculations on that file.</p>
<pre><code>Args: 
    ResultsFilename: the netcdf file where the results will be stored.
    DataFilename: the netcdf file (with orbit or tiegcm data ) on which the calculation have taken place.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SaveResults_CDF( ResultsFilename, DataFilename ):
    &#34;&#34;&#34;
    Append the results in a NetCDF file which can contain results of several calculations.
    The data will be saved in ResultsFilename and they come from calculations on the netcdf DataFilename.
    DataFilename is needed to check if the file contains already the results of calculations on that file.
    
        Args: 
            ResultsFilename: the netcdf file where the results will be stored.
            DataFilename: the netcdf file (with orbit or tiegcm data ) on which the calculation have taken place. 
    &#34;&#34;&#34;
    if path.exists( ResultsFilename ) == False:
        CreateResults_CDF( ResultsFilename )
    # save general info
    ErrorMsg = &#34;&#34;
    resultsCDF = Dataset( ResultsFilename, &#39;a&#39; )
    resultsCDF.DateOfUpdate = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
    if resultsCDF.Region    != CALCULATIONS_RegionName: ErrorMsg = &#34;Save aborted: NetCDF file has already data about region &#34; + resultsCDF.Region + &#34; and you tried to save data about region &#34; + CALCULATIONS_RegionName        
    if resultsCDF.OrbitFile != CALCULATIONS_OrbitFilesPath: ErrorMsg = &#34;Save aborted: NetCDF file has already data about orbit &#34; + resultsCDF.OrbitFile + &#34; and you tried to save data about orbit &#34; + DataFilename
    if resultsCDF.DataPath  != CALCULATIONS_TIEGCMfolder: ErrorMsg = &#34;Save aborted: NetCDF file has already data about TIEGCM file &#34; + resultsCDF.DataPath  + &#34;and you tried to save data about TIEGCM file &#34; + CALCULATIONS_TIEGCMfolder        
    if len(DataFilename)&gt;0 and resultsCDF.Progress &gt; DataFilename: ErrorMsg = &#34;Save aborted: NetCDF file contains data about file: &#34; + resultsCDF.Progress + &#34; which is later than &#34; + DataFilename
    if len(ErrorMsg) &gt; 0:
        print( ErrorMsg )
        resultsCDF.close()
        return
    resultsCDF.LastExecDurationSec = ConvertLeadingZerosToSpaces(&#34;{0:.0f}&#34;.format(CALCULATIONS_ExecutionDuration)).strip()
    # save data for each bin spearately 
    for B in Bins:
        # save data about the hits inside the bin
        if len(B.Time_values) &gt; 0:
            resultsCDF.variables[B.ID+&#34;_TimeValues&#34;][:]      = resultsCDF.variables[B.ID+&#34;_TimeValues&#34;][:].tolist() + B.Time_values
            resultsCDF.variables[B.ID+&#34;_JHValues&#34;][:]        = resultsCDF.variables[B.ID+&#34;_JHValues&#34;][:].tolist() + B.JH_values        
            resultsCDF.variables[B.ID+&#34;_MagLatValues&#34;][:]    = resultsCDF.variables[B.ID+&#34;_MagLatValues&#34;][:].tolist() + B.MagLat_values
            resultsCDF.variables[B.ID+&#34;_MLTValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_MLTValues&#34;][:].tolist() + B.MLT_values
            resultsCDF.variables[B.ID+&#34;_AltitudeValues&#34;][:]  = resultsCDF.variables[B.ID+&#34;_AltitudeValues&#34;][:].tolist() + B.Altitude_values
            resultsCDF.variables[B.ID+&#34;_LatValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_LatValues&#34;][:].tolist() + B.Lat_values
            resultsCDF.variables[B.ID+&#34;_KpValues&#34;][:]        = resultsCDF.variables[B.ID+&#34;_KpValues&#34;][:].tolist() + B.Kp_values
            resultsCDF.variables[B.ID+&#34;_EEXValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_EEXValues&#34;][:].tolist() + B.EEX_values        
            resultsCDF.variables[B.ID+&#34;_EEYValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_EEYValues&#34;][:].tolist() + B.EEY_values
            resultsCDF.variables[B.ID+&#34;_PedersenValues&#34;][:]  = resultsCDF.variables[B.ID+&#34;_PedersenValues&#34;][:].tolist() + B.Pedersen_values
            resultsCDF.variables[B.ID+&#34;_DensityValues&#34;][:]   = resultsCDF.variables[B.ID+&#34;_DensityValues&#34;][:].tolist() + B.Density_values
            resultsCDF.variables[B.ID+&#34;_LevValues&#34;][:]       = resultsCDF.variables[B.ID+&#34;_LevValues&#34;][:].tolist() + B.Lev_values
            resultsCDF.variables[B.ID+&#34;_HallValues&#34;][:]      = resultsCDF.variables[B.ID+&#34;_HallValues&#34;][:].tolist() + B.Hall_values
            resultsCDF.variables[B.ID+&#34;_ConvectionHeatingValues&#34;][:] = resultsCDF.variables[B.ID+&#34;_ConvectionHeatingValues&#34;][:].tolist() + B.ConvectionHeating_values
            resultsCDF.variables[B.ID+&#34;_WindHeatingValues&#34;][:] = resultsCDF.variables[B.ID+&#34;_WindHeatingValues&#34;][:].tolist() + B.WindHeating_values
    ## save data for all hits
    if len(all_Time_values) &gt; 0:
        resultsCDF.variables[&#34;allTimeValues&#34;][:]     = resultsCDF.variables[&#34;allTimeValues&#34;][:].tolist() + all_Time_values
        resultsCDF.variables[&#34;allJHValues&#34;][:]       = resultsCDF.variables[&#34;allJHValues&#34;][:].tolist() + all_JH_values    
        resultsCDF.variables[&#34;allMagLatValues&#34;][:]   = resultsCDF.variables[&#34;allMagLatValues&#34;][:].tolist() + all_MagLat_values
        resultsCDF.variables[&#34;allMLTValues&#34;][:]      = resultsCDF.variables[&#34;allMLTValues&#34;][:].tolist() + all_MLT_values
        resultsCDF.variables[&#34;allAltitudeValues&#34;][:] = resultsCDF.variables[&#34;allAltitudeValues&#34;][:].tolist() + all_Altitude_values
        resultsCDF.variables[&#34;allLatValues&#34;][:]      = resultsCDF.variables[&#34;allLatValues&#34;][:].tolist() + all_Lat_values
        resultsCDF.variables[&#34;allKpValues&#34;][:]       = resultsCDF.variables[&#34;allKpValues&#34;][:].tolist() + all_Kp_values
        #resultsCDF.variables[&#34;allHittedBinIDs&#34;][:]   = resultsCDF.variables[&#34;allHittedBinIDs&#34;][:].tolist() + netCDF4.stringtochar(np.array(all_HittedBin_IDs[:], &#39;S8&#39;))
        resultsCDF.variables[&#34;allEEXValues&#34;][:]      = resultsCDF.variables[&#34;allEEXValues&#34;][:].tolist() + all_EEX_values
        resultsCDF.variables[&#34;allEEYValues&#34;][:]      = resultsCDF.variables[&#34;allEEYValues&#34;][:].tolist() + all_EEY_values
        resultsCDF.variables[&#34;allPedersenValues&#34;][:] = resultsCDF.variables[&#34;allPedersenValues&#34;][:].tolist() + all_Pedersen_values
        resultsCDF.variables[&#34;allDensityValues&#34;][:]  = resultsCDF.variables[&#34;allDensityValues&#34;][:].tolist() + all_Density_values
        resultsCDF.variables[&#34;allLevValues&#34;][:]      = resultsCDF.variables[&#34;allLevValues&#34;][:].tolist() + all_Lev_values
        resultsCDF.variables[&#34;allHallValues&#34;][:]     = resultsCDF.variables[&#34;allHallValues&#34;][:].tolist() + all_Hall_values
        resultsCDF.variables[&#34;allConvectionHeatingValues&#34;][:] = resultsCDF.variables[&#34;allConvectionHeatingValues&#34;][:].tolist() + all_ConvectionHeating_values
        resultsCDF.variables[&#34;allWindHeatingValues&#34;][:] = resultsCDF.variables[&#34;allWindHeatingValues&#34;][:].tolist() + all_WindHeating_values
    #
    resultsCDF.close()    </code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.doit"><code class="name flex">
<span>def <span class="ident">doit</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def doit():
    global all_JH_values
    all_JH_values.append(4.44);
    all_JH_values.clear()
    all_JH_values.append(4.44);</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.getBinByItsID"><code class="name flex">
<span>def <span class="ident">getBinByItsID</span></span>(<span>aBinID)</span>
</code></dt>
<dd>
<div class="desc"><p>ReturnsL the Bin object wich has the same ID as the argument</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getBinByItsID( aBinID ):
    &#34;&#34;&#34;
        ReturnsL the Bin object wich has the same ID as the argument
    &#34;&#34;&#34;
    CorrectBin = None
    for B in Bins:
        if  B.ID == aBinID:
            CorrectBin = B
            break
    return CorrectBin</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.getBinByItsProperties"><code class="name flex">
<span>def <span class="ident">getBinByItsProperties</span></span>(<span>MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Kp_min, Kp_max)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns: the bin object which has been defined by the same ranges as the arguments</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getBinByItsProperties( MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Kp_min, Kp_max ):
    &#34;&#34;&#34;
        Returns: the bin object which has been defined by the same ranges as the arguments
    &#34;&#34;&#34;
    CorrectBin = None
    for B in Bins:
        if             MLT_min      == B.MLT_min       and  MLT_max      == B.MLT_max:
            if         MagLat_min   == B.MagLat_min    and  MagLat_max   == B.MagLat_max:
                if     Altitude_min == B.Altitude_min  and  Altitude_max == B.Altitude_max:
                    if Kp_min       == B.Kp_min        and  Kp_max       == B.Kp_max:
                        CorrectBin = B
                        break
    return CorrectBin</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.getBinDescription"><code class="name flex">
<span>def <span class="ident">getBinDescription</span></span>(<span>str)</span>
</code></dt>
<dd>
<div class="desc"><p>Tries to identify the bin according to the given argument and returns its description. If it fails it returns the argument.
examples: "PCF_H2"-&gt;"Polar cap F-region"
"PCF"-&gt;"Polar cap F-region"</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getBinDescription( str ):
    &#34;&#34;&#34;
    Tries to identify the bin according to the given argument and returns its description. If it fails it returns the argument.
    examples: &#34;PCF_H2&#34;-&gt;&#34;Polar cap F-region&#34;   &#34;PCF&#34;-&gt;&#34;Polar cap F-region&#34;
    &#34;&#34;&#34;
    result = &#34;&#34;
    for B in Bins:
        if B.ID == str: result = B.Description
    if len(result)==0:
        for B in Bins:
            if B.ID.startswith( str ): result = B.Description
    if len(result)==0: result = str
    #
    return result</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.is_MLT_inside_range"><code class="name flex">
<span>def <span class="ident">is_MLT_inside_range</span></span>(<span>MLT, MLT_min, MLT_max)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if certain Magnetic-Local-Time lies in a certain range. It can handle ranges like 22-2</p>
<h2 id="returns">Returns</h2>
<p>true if MLT falls inside [MLT_min, MLT_max]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_MLT_inside_range( MLT, MLT_min, MLT_max ):
    &#34;&#34;&#34;
        Checks if certain Magnetic-Local-Time lies in a certain range. It can handle ranges like 22-2
        Returns:
            true if MLT falls inside [MLT_min, MLT_max]
    &#34;&#34;&#34;
    if MLT_min &lt; MLT_max: # example: from 13 to 18 hour
        return (MLT &gt; MLT_min  and  MLT &lt;= MLT_max)
    elif MLT_min == MLT_max: # example: from 12 until 12 the other day
        return True
    else: # example: from 22 to 3 hour
        return (MLT &gt; MLT_min  or   MLT &lt;= MLT_max)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="DaedalusMASE_Global_Statistics.data.Bin"><code class="flex name class">
<span>class <span class="ident">Bin</span></span>
<span>(</span><span>ID, Description, MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Lat_min, Lat_max, Kp_min, Kp_max, DesirableCumulativeTime)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Bin:
    ID             = &#34;&#34;
    Description    = &#34;&#34;
    MLT_min        = 0 # Magnetic Local Time (hour &amp; min of the 24-hour day) (string)
    MLT_max        = 0 # Magnetic Local Time (hour &amp; min of the 24-hour day) (string)
    MagLat_min     = 0 # Magnetic Latitude (degrees)
    MagLat_max     = 0 # Magnetic Latitude (degrees)
    Altitude_min   = 0 # Satellite&#39;s Altitude measured from Earth&#39;s surface (km)
    Altitude_max   = 0 # Satellite&#39;s Altitude measured from Earth&#39;s surface (km)
    Kp_min         = 0 #
    Kp_max         = 0 #
    Lat_min        = 0
    Lat_max        = 0
    NumOfBins      = 0 # How many parts will the Altitude range be splitted in
    CumulativeTime = 0 # (sec)
    DesirableCumulativeTime = 0 # (sec)
    JH_min      = 99999 # the minimum JH value inside the bin
    JH_max      = 0     # the maximum JH value inside the bin
    JH_mean     = 0     # the mean JH value inside the bin
    JH_median   = 0     # the median JH value inside the bin (=50th percentile)
    JH_variance = 0     # the variance of JH value inside the bin (variance = (1/(N-1)) * Sum{1-&gt;N}(X-MeanVariance)^2  )
    JH_medianVariance = 0
    JH_medianAbsDev = 0
    # Data:
    JH_values         = list() # here will be stored all Joule Heating values in order to calculate the variance at the end
    JH_distribution   = list() # the item 0 holds the number of points which have 0&lt;JH&lt;JH_max/100 etc
    MagLat_values     = list() #  these values correspond to the JH_values
    MLT_values        = list() #  these values correspond to the JH_values
    Altitude_values   = list() #  these values correspond to the JH_values
    Kp_values         = list() #  these values correspond to the JH_values
    Time_values       = list() #  these values correspond to the JH_values
    EEX_values        = list()
    EEY_values        = list()
    Pedersen_values   = list()
    Density_values    = list()
    Lev_values        = list()
    Hall_values       = list()
    ConvectionHeating_values = list()
    WindHeating_values = list()
    
    def __init__(self, ID, Description, MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Lat_min, Lat_max, Kp_min, Kp_max, DesirableCumulativeTime):
        self.ID             = ID
        self.Description    = Description
        self.MLT_min        = MLT_min 
        self.MLT_max        = MLT_max
        self.MagLat_min     = MagLat_min
        self.MagLat_max     = MagLat_max
        self.Altitude_min   = Altitude_min
        self.Altitude_max   = Altitude_max
        self.Lat_min        = Lat_min
        self.Lat_max        = Lat_max                
        self.Kp_min         = Kp_min
        self.Kp_max         = Kp_max
        self.DesirableCumulativeTime = DesirableCumulativeTime
        self.JH_values       = list()
        self.JH_distribution = [0] * 100
        self.MagLat_values   = list()
        self.MLT_values      = list()
        self.Altitude_values = list()
        self.Lat_values       = list()
        self.Kp_values       = list()
        self.Time_values     = list()
        self.EEX_values        = list()
        self.EEY_values        = list()
        self.Pedersen_values   = list()
        self.Density_values    = list()
        self.Lev_values        = list()
        self.Hall_values       = list()
        self.ConvectionHeating_values = list()
        self.WindHeating_values = list()

    def reset(self):
        self.JH_min      = 99999
        self.JH_mean     = 0
        self.JH_median   = 0
        self.JH_variance = 0
        self.JH_medianVariance = 0
        self.JH_medianAbsDev = 0
        self.JH_values.clear()
        self.MagLat_values.clear()
        self.MLT_values.clear()
        self.Altitude_values.clear()
        self.Lat_values.clear()
        self.Kp_values.clear()
        self.Time_values.clear()
        self.EEX_values.clear()
        self.EEY_values.clear()
        self.Pedersen_values.clear()
        self.Density_values.clear()
        self.Lev_values.clear()
        self.Hall_values.clear()        
        self.ConvectionHeating_values.clear()
        self.WindHeating_values.clear()
        
    def getInfo(self):
        s  = self.ID.ljust(8, &#39; &#39;) + &#34;: &#34;
        s += &#34;{:02.0f}&#34;.format(self.MLT_min)      + &#34;&lt;MLT&lt;=&#34;    + &#34;{:02.0f}&#34;.format(self.MLT_max)      + &#34; &#34;
        s += &#34;{:03.0f}&#34;.format(self.MagLat_min)   + &#34;&lt;MagLat&lt;=&#34; + &#34;{:03.0f}&#34;.format(self.MagLat_max)   + &#34; &#34;
        s += &#34;{:03.0f}&#34;.format(self.Altitude_min) + &#34;&lt;Alt&lt;=&#34;    + &#34;{:03.0f}&#34;.format(self.Altitude_max) + &#34; &#34;
        s += str(self.Kp_min)             + &#34;&lt;Kp&lt;=&#34;     + str(self.Kp_max)       + &#34; &#34;
        if self.JH_min == 99999:
            s += &#34; JHmin=&#34; + &#34;         &#34;
        else:
            s += &#34; JHmin=&#34; + &#34;{:.3e}&#34;.format(self.JH_min) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_min) )
        s += &#34; JHmean=&#34; + &#34;{:.3e}&#34;.format(self.JH_mean) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_mean) )
        s += &#34; JHvariance=&#34; + &#34;{:.3e}&#34;.format(self.JH_variance) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_variance) )
        ##
        str_JH = &#34;&#34;
        for i in range(0, len(self.JH_values) ):            
            str_JH += str( self.JH_values[i] )
            if i &lt; len(self.JH_values)-1: str_JH += &#39;,&#39;
        s += &#34; JH_values=&#34; + str_JH # &#39;&#39;.join(str(e) for e in self.JH_values)
        ##
        return s
    
    def printMe(self):
        print( self.getInfo()[:220] )</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Altitude_max"><code class="name">var <span class="ident">Altitude_max</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Altitude_min"><code class="name">var <span class="ident">Altitude_min</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Altitude_values"><code class="name">var <span class="ident">Altitude_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.ConvectionHeating_values"><code class="name">var <span class="ident">ConvectionHeating_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.CumulativeTime"><code class="name">var <span class="ident">CumulativeTime</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Density_values"><code class="name">var <span class="ident">Density_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Description"><code class="name">var <span class="ident">Description</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.DesirableCumulativeTime"><code class="name">var <span class="ident">DesirableCumulativeTime</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.EEX_values"><code class="name">var <span class="ident">EEX_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.EEY_values"><code class="name">var <span class="ident">EEY_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Hall_values"><code class="name">var <span class="ident">Hall_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.ID"><code class="name">var <span class="ident">ID</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_distribution"><code class="name">var <span class="ident">JH_distribution</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_max"><code class="name">var <span class="ident">JH_max</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_mean"><code class="name">var <span class="ident">JH_mean</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_median"><code class="name">var <span class="ident">JH_median</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_medianAbsDev"><code class="name">var <span class="ident">JH_medianAbsDev</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_medianVariance"><code class="name">var <span class="ident">JH_medianVariance</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_min"><code class="name">var <span class="ident">JH_min</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_values"><code class="name">var <span class="ident">JH_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.JH_variance"><code class="name">var <span class="ident">JH_variance</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Kp_max"><code class="name">var <span class="ident">Kp_max</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Kp_min"><code class="name">var <span class="ident">Kp_min</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Kp_values"><code class="name">var <span class="ident">Kp_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Lat_max"><code class="name">var <span class="ident">Lat_max</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Lat_min"><code class="name">var <span class="ident">Lat_min</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Lev_values"><code class="name">var <span class="ident">Lev_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.MLT_max"><code class="name">var <span class="ident">MLT_max</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.MLT_min"><code class="name">var <span class="ident">MLT_min</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.MLT_values"><code class="name">var <span class="ident">MLT_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.MagLat_max"><code class="name">var <span class="ident">MagLat_max</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.MagLat_min"><code class="name">var <span class="ident">MagLat_min</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.MagLat_values"><code class="name">var <span class="ident">MagLat_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.NumOfBins"><code class="name">var <span class="ident">NumOfBins</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Pedersen_values"><code class="name">var <span class="ident">Pedersen_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.Time_values"><code class="name">var <span class="ident">Time_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.WindHeating_values"><code class="name">var <span class="ident">WindHeating_values</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.getInfo"><code class="name flex">
<span>def <span class="ident">getInfo</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getInfo(self):
    s  = self.ID.ljust(8, &#39; &#39;) + &#34;: &#34;
    s += &#34;{:02.0f}&#34;.format(self.MLT_min)      + &#34;&lt;MLT&lt;=&#34;    + &#34;{:02.0f}&#34;.format(self.MLT_max)      + &#34; &#34;
    s += &#34;{:03.0f}&#34;.format(self.MagLat_min)   + &#34;&lt;MagLat&lt;=&#34; + &#34;{:03.0f}&#34;.format(self.MagLat_max)   + &#34; &#34;
    s += &#34;{:03.0f}&#34;.format(self.Altitude_min) + &#34;&lt;Alt&lt;=&#34;    + &#34;{:03.0f}&#34;.format(self.Altitude_max) + &#34; &#34;
    s += str(self.Kp_min)             + &#34;&lt;Kp&lt;=&#34;     + str(self.Kp_max)       + &#34; &#34;
    if self.JH_min == 99999:
        s += &#34; JHmin=&#34; + &#34;         &#34;
    else:
        s += &#34; JHmin=&#34; + &#34;{:.3e}&#34;.format(self.JH_min) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_min) )
    s += &#34; JHmean=&#34; + &#34;{:.3e}&#34;.format(self.JH_mean) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_mean) )
    s += &#34; JHvariance=&#34; + &#34;{:.3e}&#34;.format(self.JH_variance) #ConvertLeadingZerosToSpaces( &#34;{:09.3f}&#34;.format(self.JH_variance) )
    ##
    str_JH = &#34;&#34;
    for i in range(0, len(self.JH_values) ):            
        str_JH += str( self.JH_values[i] )
        if i &lt; len(self.JH_values)-1: str_JH += &#39;,&#39;
    s += &#34; JH_values=&#34; + str_JH # &#39;&#39;.join(str(e) for e in self.JH_values)
    ##
    return s</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.printMe"><code class="name flex">
<span>def <span class="ident">printMe</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def printMe(self):
    print( self.getInfo()[:220] )</code></pre>
</details>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Bin.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    self.JH_min      = 99999
    self.JH_mean     = 0
    self.JH_median   = 0
    self.JH_variance = 0
    self.JH_medianVariance = 0
    self.JH_medianAbsDev = 0
    self.JH_values.clear()
    self.MagLat_values.clear()
    self.MLT_values.clear()
    self.Altitude_values.clear()
    self.Lat_values.clear()
    self.Kp_values.clear()
    self.Time_values.clear()
    self.EEX_values.clear()
    self.EEY_values.clear()
    self.Pedersen_values.clear()
    self.Density_values.clear()
    self.Lev_values.clear()
    self.Hall_values.clear()        
    self.ConvectionHeating_values.clear()
    self.WindHeating_values.clear()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="DaedalusMASE_Global_Statistics.data.Thread_ValueAssigner"><code class="flex name class">
<span>class <span class="ident">Thread_ValueAssigner</span></span>
<span>(</span><span>DataFilename, ResultsFilename)</span>
</code></dt>
<dd>
<div class="desc"><p>The thread executes the actual calculation using a single source file (DataFilename) and producing one result file (ResultsFilename):<br>
- reads the netcdf orbit or tiegcm file<br>
- checks every space-time position<br>
- assign the position's data to the corresponding Bin <br>
- saves the above data into a netcdf results-file<br>
Threads are employed in order to speed up the calculation when there are many source files.
There will be one thread for each source file</p>
<p>This constructor should always be called with keyword arguments. Arguments are:</p>
<p><em>group</em> should be None; reserved for future extension when a ThreadGroup
class is implemented.</p>
<p><em>target</em> is the callable object to be invoked by the run()
method. Defaults to None, meaning nothing is called.</p>
<p><em>name</em> is the thread name. By default, a unique name is constructed of
the form "Thread-N" where N is a small decimal number.</p>
<p><em>args</em> is the argument tuple for the target invocation. Defaults to ().</p>
<p><em>kwargs</em> is a dictionary of keyword arguments for the target
invocation. Defaults to {}.</p>
<p>If a subclass overrides the constructor, it must make sure to invoke
the base class constructor (Thread.<strong>init</strong>()) before doing anything
else to the thread.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Thread_ValueAssigner (threading.Thread):
    &#34;&#34;&#34;
    The thread executes the actual calculation using a single source file (DataFilename) and producing one result file (ResultsFilename):  
        - reads the netcdf orbit or tiegcm file  
        - checks every space-time position  
        - assign the position&#39;s data to the corresponding Bin   
        - saves the above data into a netcdf results-file  
    Threads are employed in order to speed up the calculation when there are many source files. 
    There will be one thread for each source file
    &#34;&#34;&#34;
    def __init__(self, DataFilename, ResultsFilename):
        threading.Thread.__init__(self)
        self.DataFilename = DataFilename
        self.ResultsFilename = ResultsFilename
    def run(self):
        global Bins
        global all_JH_values
        DataFilename = self.DataFilename
        ResultsFilename = self.ResultsFilename
        print( &#34;Thread start&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename, &#34;\n&#34; )
        MagLat_min =  1000
        MagLat_max = -1000
        MLT_min    =  1000
        MLT_max    = -1000
        Altitude_min    =  1000
        Altitude_max    = -1000
        Lat_min     =  1000
        Lat_max     = -1000    
        Kp_min     =  1000
        Kp_max     = -1000
        localBins = copy.deepcopy(Bins)
        for B in localBins:
            B.reset()
            if B.MagLat_min &lt; MagLat_min: MagLat_min = B.MagLat_min 
            if B.MagLat_max &gt; MagLat_max: MagLat_max = B.MagLat_max
            if B.MLT_min &lt; MLT_min: MLT_min = B.MLT_min 
            if B.MLT_max &gt; MLT_max: MLT_max = B.MLT_max
            if B.Altitude_min &lt; Altitude_min: Altitude_min = B.Altitude_min 
            if B.Altitude_max &gt; Altitude_max: Altitude_max = B.Altitude_max
            if B.Lat_min &lt; Lat_min: Lat_min = B.Lat_min 
            if B.Lat_max &gt; Lat_max: Lat_max = B.Lat_max                        
            if B.Kp_min &lt; Kp_min: Kp_min = B.Kp_min 
            if B.Kp_max &gt; Kp_max: Kp_max = B.Kp_max            
        all_JH_values.clear()
        all_MagLat_values.clear()
        all_MLT_values.clear()
        all_Altitude_values.clear()
        all_Lat_values.clear()
        all_Kp_values.clear()
        all_Time_values.clear()
        all_HittedBin_IDs.clear()
        all_EEX_values.clear()
        all_EEY_values.clear()
        all_Pedersen_values.clear()
        all_Density_values.clear()
        all_Lev_values.clear()
        all_Hall_values.clear()
        all_ConvectionHeating_values.clear()
        all_WindHeating_values.clear()
        Matches = 0
        
        # parse TIEGCM file
        try:
            CDFroot = Dataset( DataFilename, &#39;r&#39; )
            print( &#34;Reading&#34;, DataFilename )
        except:
            print ( &#34;WRONG FORMAT:&#34;, DataFilename )
            return
        try:
            FileStartTimeStamp = calendar.timegm( datetime.strptime( CDFroot.variables[&#39;time&#39;].units[14:],  &#34;%Y-%m-%d %H:%M:%S&#34; ).utctimetuple() ) # ex: &#34;minutes since 2015-1-1 0:0:0&#34;
        except:
            print ( &#34;WRONG CONTENTS:&#34;, DataFilename )
            return
        length_time = CDFroot.variables[&#39;Ohmic&#39;].shape[0]
        length_lev  = CDFroot.variables[&#39;Ohmic&#39;].shape[1]
        length_lat  = CDFroot.variables[&#39;Ohmic&#39;].shape[2]
        length_lon  = CDFroot.variables[&#39;Ohmic&#39;].shape[3]
        # wait until disk is released
        DiskAccessLock.acquire()
        # Load or calculate all basic values from the netcdf file
        try:
            TIMEs   = CDFroot.variables[&#39;time&#39;][:] # minutes since the start time
            LATs    = CDFroot.variables[&#39;lat&#39;][:] 
            ALTs    = CDFroot.variables[&#39;ZGMID&#39;][:, :, :, :] / 100000 # it is stored in cm inside the file
            JHs     = CDFroot.variables[&#39;Ohmic&#39;][:, :, :, :]
            KPs     = CDFroot.variables[&#39;Kp&#39;][:]
            MAGLATs = CDFroot.variables[&#39;mlat_qdf&#39;][:, :, :, :] 
            MLTs    = CDFroot.variables[&#39;mlt_qdf&#39;][:, :, :, :] 
            EEXs    = CDFroot.variables[&#39;EEX&#39;][:, :, :, :] 
            EEYs    = CDFroot.variables[&#39;EEY&#39;][:, :, :, :] 
            PEDs    = CDFroot.variables[&#39;SIGMA_PED&#39;][:, :, :, :] 
            HALs    = CDFroot.variables[&#39;SIGMA_HAL&#39;][:, :, :, :]
            DENs    = CDFroot.variables[&#39;DEN&#39;][:, :, :, :] 
            LEVs    = CDFroot.variables[&#39;lev&#39;][:] 
            try:
                CONV_H  = CDFroot.variables[&#39;Convection_heating&#39;][:, :, :, :]
            except:
                CONV_H  = CDFroot.variables[&#39;Convenction_heating&#39;][:, :, :, :]
            WIND_H  = CDFroot.variables[&#39;Wind_heating&#39;][:, :, :, :]
        except Exception as e:
            print( &#34;Thread aborted while reading&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;:&#34;, e, repr(e), &#34;\n&#34; )
            DiskAccessLock.release()
            return 
        DiskAccessLock.release()
        print( &#34;Thread file read done&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34; )
    
        step = 1
        for idx_lat in range(0, length_lat, step):
            if idx_lat%2==0: print(&#34;Thread Calculating Lat&#34;,  idx_lat, ResultsFilename[-26:])
            current_Lat = LATs[idx_lat] 
            if current_Lat &lt; Lat_min  or  current_Lat &gt; Lat_max: continue
            for idx_lon in range(0, length_lon, step):
                for idx_lev in range(0, length_lev, step):
                    for idx_time in range(0, length_time, step):                    
                        in_Altitude_range = in_MagLat_range = in_MLT_range = in_Kp_range = False
                            
                        current_Altitude = ALTs[idx_time, idx_lev, idx_lat, idx_lon]
                        if current_Altitude &gt;= Altitude_min and current_Altitude &lt;= Altitude_max:
                            in_Altitude_range = True
                        
                        if in_Altitude_range:
                            current_MagLat = MAGLATs[ idx_time, idx_lev, idx_lat, idx_lon ]
                            if current_MagLat &gt;= MagLat_min and current_MagLat &lt;= MagLat_max:
                                in_MagLat_range = True
                                
                        if in_MagLat_range:
                            current_MLT = MLTs[ idx_time, idx_lev, idx_lat, idx_lon ]
                            if in_MagLat_range:
                                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )
                        
                        if in_MLT_range:
                            current_Kp = KPs[idx_time]
                            if current_Kp &gt;= Kp_min and current_Kp &lt;= Kp_max:
                                in_Kp_range = True   
                                
                        if in_Kp_range:                    
                            matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )
                            if matchedBin is not None:
                                for B in localBins:
                                    if B.ID == matchedBin.ID:
                                        matchedBin = B
                                current_time = int( FileStartTimeStamp + TIMEs[idx_time]*120*60 )
                                current_JH = JHs[idx_time, idx_lev, idx_lat ,idx_lon] #CDFroot.variables[&#39;Joule Heating&#39;][idx_time, idx_lev, idx_lat, idx_lon]
                                matchedBin.JH_values.append( current_JH )
                                matchedBin.MagLat_values.append( current_MagLat )
                                matchedBin.MLT_values.append( current_MLT )
                                matchedBin.Altitude_values.append( current_Altitude )
                                matchedBin.Kp_values.append( current_Kp )
                                matchedBin.Time_values.append( current_time )
                                matchedBin.EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.Lev_values.append( LEVs[ idx_lev ] ) 
                                matchedBin.ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                matchedBin.WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                all_JH_values.append( current_JH )
                                all_MagLat_values.append( current_MagLat )
                                all_MLT_values.append( current_MLT )
                                all_Altitude_values.append( current_Altitude )
                                all_Kp_values.append( current_Kp )
                                all_Time_values.append( current_time )
                                all_HittedBin_IDs.append( matchedBin.ID )
                                all_EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                all_Lev_values.append( LEVs[ idx_lev ] )
                                all_ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                                all_WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] )
                                Matches += 1
                    #break
                #break
        CDFroot.close()
        # wait until disk is released
        #DiskAccessLock.acquire()
        #### SAVE Results ####
        try:
            # save general info
            resultsCDF = Dataset( ResultsFilename, &#39;a&#39; )
            resultsCDF.DateOfUpdate = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
            resultsCDF.Region = CALCULATIONS_RegionName
            resultsCDF.DataPath = CALCULATIONS_TIEGCMfolder
            # save data for each bin seperately 
            for B in localBins:
                # save data about the hits inside the bin
                if len(B.Time_values) &gt; 0:
                    resultsCDF.variables[B.ID+&#34;_TimeValues&#34;][:]      = B.Time_values
                    resultsCDF.variables[B.ID+&#34;_JHValues&#34;][:]        = B.JH_values        
                    resultsCDF.variables[B.ID+&#34;_MagLatValues&#34;][:]    = B.MagLat_values
                    resultsCDF.variables[B.ID+&#34;_MLTValues&#34;][:]       = B.MLT_values
                    resultsCDF.variables[B.ID+&#34;_AltitudeValues&#34;][:]  = B.Altitude_values
                    resultsCDF.variables[B.ID+&#34;_LatValues&#34;][:]       = B.Lat_values
                    resultsCDF.variables[B.ID+&#34;_KpValues&#34;][:]        = B.Kp_values
                    resultsCDF.variables[B.ID+&#34;_EEXValues&#34;][:]       = B.EEX_values        
                    resultsCDF.variables[B.ID+&#34;_EEYValues&#34;][:]       = B.EEY_values
                    resultsCDF.variables[B.ID+&#34;_PedersenValues&#34;][:]  = B.Pedersen_values
                    resultsCDF.variables[B.ID+&#34;_HallValues&#34;][:]      = B.Hall_values
                    resultsCDF.variables[B.ID+&#34;_DensityValues&#34;][:]   = B.Density_values
                    resultsCDF.variables[B.ID+&#34;_LevValues&#34;][:]       = B.Lev_values
                    resultsCDF.variables[B.ID+&#34;_ConvectionHeatingValues&#34;][:] = B.ConvectionHeating_values
                    resultsCDF.variables[B.ID+&#34;_WindHeatingValues&#34;][:] = B.WindHeating_values
            ## save data for all hits
            resultsCDF.variables[&#34;allTimeValues&#34;][:]     = all_Time_values
            resultsCDF.variables[&#34;allJHValues&#34;][:]       = all_JH_values    
            resultsCDF.variables[&#34;allMagLatValues&#34;][:]   = all_MagLat_values
            resultsCDF.variables[&#34;allMLTValues&#34;][:]      = all_MLT_values
            resultsCDF.variables[&#34;allAltitudeValues&#34;][:] = all_Altitude_values
            resultsCDF.variables[&#34;allLatValues&#34;][:]      = all_Lat_values
            resultsCDF.variables[&#34;allKpValues&#34;][:]       = all_Kp_values
            #resultsCDF.variables[&#34;allHittedBinIDs&#34;][:]   = netCDF4.stringtochar(np.array(all_HittedBin_IDs[:], &#39;S8&#39;))
            resultsCDF.variables[&#34;allEEXValues&#34;][:]      = all_EEX_values
            resultsCDF.variables[&#34;allEEYValues&#34;][:]      = all_EEY_values
            resultsCDF.variables[&#34;allPedersenValues&#34;][:] = all_Pedersen_values
            resultsCDF.variables[&#34;allHallValues&#34;][:]     = all_Hall_values
            resultsCDF.variables[&#34;allDensityValues&#34;][:]  = all_Density_values
            resultsCDF.variables[&#34;allLevValues&#34;][:]      = all_Lev_values
            resultsCDF.variables[&#34;allConvectionHeatingValues&#34;][:] = all_ConvectionHeating_values
            resultsCDF.variables[&#34;allWindHeatingValues&#34;][:] = all_WindHeating_values
            #
            resultsCDF.close()    
        except Exception as e:
            print( &#34;!!!! Thread error while writing&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34; )
            print( e )
            #DiskAccessLock.release()
        #DiskAccessLock.release()
    
        print( &#34;Thread finish&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34;, Matches, &#34;matches&#34;, len(localBins[0].JH_values), len(Bins[0].JH_values) )
        print( &#34;&#34; )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>threading.Thread</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="DaedalusMASE_Global_Statistics.data.Thread_ValueAssigner.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method representing the thread's activity.</p>
<p>You may override this method in a subclass. The standard run() method
invokes the callable object passed to the object's constructor as the
target argument, if any, with sequential and keyword arguments taken
from the args and kwargs arguments, respectively.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    global Bins
    global all_JH_values
    DataFilename = self.DataFilename
    ResultsFilename = self.ResultsFilename
    print( &#34;Thread start&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename, &#34;\n&#34; )
    MagLat_min =  1000
    MagLat_max = -1000
    MLT_min    =  1000
    MLT_max    = -1000
    Altitude_min    =  1000
    Altitude_max    = -1000
    Lat_min     =  1000
    Lat_max     = -1000    
    Kp_min     =  1000
    Kp_max     = -1000
    localBins = copy.deepcopy(Bins)
    for B in localBins:
        B.reset()
        if B.MagLat_min &lt; MagLat_min: MagLat_min = B.MagLat_min 
        if B.MagLat_max &gt; MagLat_max: MagLat_max = B.MagLat_max
        if B.MLT_min &lt; MLT_min: MLT_min = B.MLT_min 
        if B.MLT_max &gt; MLT_max: MLT_max = B.MLT_max
        if B.Altitude_min &lt; Altitude_min: Altitude_min = B.Altitude_min 
        if B.Altitude_max &gt; Altitude_max: Altitude_max = B.Altitude_max
        if B.Lat_min &lt; Lat_min: Lat_min = B.Lat_min 
        if B.Lat_max &gt; Lat_max: Lat_max = B.Lat_max                        
        if B.Kp_min &lt; Kp_min: Kp_min = B.Kp_min 
        if B.Kp_max &gt; Kp_max: Kp_max = B.Kp_max            
    all_JH_values.clear()
    all_MagLat_values.clear()
    all_MLT_values.clear()
    all_Altitude_values.clear()
    all_Lat_values.clear()
    all_Kp_values.clear()
    all_Time_values.clear()
    all_HittedBin_IDs.clear()
    all_EEX_values.clear()
    all_EEY_values.clear()
    all_Pedersen_values.clear()
    all_Density_values.clear()
    all_Lev_values.clear()
    all_Hall_values.clear()
    all_ConvectionHeating_values.clear()
    all_WindHeating_values.clear()
    Matches = 0
    
    # parse TIEGCM file
    try:
        CDFroot = Dataset( DataFilename, &#39;r&#39; )
        print( &#34;Reading&#34;, DataFilename )
    except:
        print ( &#34;WRONG FORMAT:&#34;, DataFilename )
        return
    try:
        FileStartTimeStamp = calendar.timegm( datetime.strptime( CDFroot.variables[&#39;time&#39;].units[14:],  &#34;%Y-%m-%d %H:%M:%S&#34; ).utctimetuple() ) # ex: &#34;minutes since 2015-1-1 0:0:0&#34;
    except:
        print ( &#34;WRONG CONTENTS:&#34;, DataFilename )
        return
    length_time = CDFroot.variables[&#39;Ohmic&#39;].shape[0]
    length_lev  = CDFroot.variables[&#39;Ohmic&#39;].shape[1]
    length_lat  = CDFroot.variables[&#39;Ohmic&#39;].shape[2]
    length_lon  = CDFroot.variables[&#39;Ohmic&#39;].shape[3]
    # wait until disk is released
    DiskAccessLock.acquire()
    # Load or calculate all basic values from the netcdf file
    try:
        TIMEs   = CDFroot.variables[&#39;time&#39;][:] # minutes since the start time
        LATs    = CDFroot.variables[&#39;lat&#39;][:] 
        ALTs    = CDFroot.variables[&#39;ZGMID&#39;][:, :, :, :] / 100000 # it is stored in cm inside the file
        JHs     = CDFroot.variables[&#39;Ohmic&#39;][:, :, :, :]
        KPs     = CDFroot.variables[&#39;Kp&#39;][:]
        MAGLATs = CDFroot.variables[&#39;mlat_qdf&#39;][:, :, :, :] 
        MLTs    = CDFroot.variables[&#39;mlt_qdf&#39;][:, :, :, :] 
        EEXs    = CDFroot.variables[&#39;EEX&#39;][:, :, :, :] 
        EEYs    = CDFroot.variables[&#39;EEY&#39;][:, :, :, :] 
        PEDs    = CDFroot.variables[&#39;SIGMA_PED&#39;][:, :, :, :] 
        HALs    = CDFroot.variables[&#39;SIGMA_HAL&#39;][:, :, :, :]
        DENs    = CDFroot.variables[&#39;DEN&#39;][:, :, :, :] 
        LEVs    = CDFroot.variables[&#39;lev&#39;][:] 
        try:
            CONV_H  = CDFroot.variables[&#39;Convection_heating&#39;][:, :, :, :]
        except:
            CONV_H  = CDFroot.variables[&#39;Convenction_heating&#39;][:, :, :, :]
        WIND_H  = CDFroot.variables[&#39;Wind_heating&#39;][:, :, :, :]
    except Exception as e:
        print( &#34;Thread aborted while reading&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;:&#34;, e, repr(e), &#34;\n&#34; )
        DiskAccessLock.release()
        return 
    DiskAccessLock.release()
    print( &#34;Thread file read done&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34; )

    step = 1
    for idx_lat in range(0, length_lat, step):
        if idx_lat%2==0: print(&#34;Thread Calculating Lat&#34;,  idx_lat, ResultsFilename[-26:])
        current_Lat = LATs[idx_lat] 
        if current_Lat &lt; Lat_min  or  current_Lat &gt; Lat_max: continue
        for idx_lon in range(0, length_lon, step):
            for idx_lev in range(0, length_lev, step):
                for idx_time in range(0, length_time, step):                    
                    in_Altitude_range = in_MagLat_range = in_MLT_range = in_Kp_range = False
                        
                    current_Altitude = ALTs[idx_time, idx_lev, idx_lat, idx_lon]
                    if current_Altitude &gt;= Altitude_min and current_Altitude &lt;= Altitude_max:
                        in_Altitude_range = True
                    
                    if in_Altitude_range:
                        current_MagLat = MAGLATs[ idx_time, idx_lev, idx_lat, idx_lon ]
                        if current_MagLat &gt;= MagLat_min and current_MagLat &lt;= MagLat_max:
                            in_MagLat_range = True
                            
                    if in_MagLat_range:
                        current_MLT = MLTs[ idx_time, idx_lev, idx_lat, idx_lon ]
                        if in_MagLat_range:
                            in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )
                    
                    if in_MLT_range:
                        current_Kp = KPs[idx_time]
                        if current_Kp &gt;= Kp_min and current_Kp &lt;= Kp_max:
                            in_Kp_range = True   
                            
                    if in_Kp_range:                    
                        matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )
                        if matchedBin is not None:
                            for B in localBins:
                                if B.ID == matchedBin.ID:
                                    matchedBin = B
                            current_time = int( FileStartTimeStamp + TIMEs[idx_time]*120*60 )
                            current_JH = JHs[idx_time, idx_lev, idx_lat ,idx_lon] #CDFroot.variables[&#39;Joule Heating&#39;][idx_time, idx_lev, idx_lat, idx_lon]
                            matchedBin.JH_values.append( current_JH )
                            matchedBin.MagLat_values.append( current_MagLat )
                            matchedBin.MLT_values.append( current_MLT )
                            matchedBin.Altitude_values.append( current_Altitude )
                            matchedBin.Kp_values.append( current_Kp )
                            matchedBin.Time_values.append( current_time )
                            matchedBin.EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            matchedBin.EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            matchedBin.Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            matchedBin.Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            matchedBin.Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            matchedBin.Lev_values.append( LEVs[ idx_lev ] ) 
                            matchedBin.ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            matchedBin.WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            all_JH_values.append( current_JH )
                            all_MagLat_values.append( current_MagLat )
                            all_MLT_values.append( current_MLT )
                            all_Altitude_values.append( current_Altitude )
                            all_Kp_values.append( current_Kp )
                            all_Time_values.append( current_time )
                            all_HittedBin_IDs.append( matchedBin.ID )
                            all_EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                            all_EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                            all_Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                            all_Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                            all_Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] )
                            all_Lev_values.append( LEVs[ idx_lev ] )
                            all_ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) 
                            all_WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] )
                            Matches += 1
                #break
            #break
    CDFroot.close()
    # wait until disk is released
    #DiskAccessLock.acquire()
    #### SAVE Results ####
    try:
        # save general info
        resultsCDF = Dataset( ResultsFilename, &#39;a&#39; )
        resultsCDF.DateOfUpdate = datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;)
        resultsCDF.Region = CALCULATIONS_RegionName
        resultsCDF.DataPath = CALCULATIONS_TIEGCMfolder
        # save data for each bin seperately 
        for B in localBins:
            # save data about the hits inside the bin
            if len(B.Time_values) &gt; 0:
                resultsCDF.variables[B.ID+&#34;_TimeValues&#34;][:]      = B.Time_values
                resultsCDF.variables[B.ID+&#34;_JHValues&#34;][:]        = B.JH_values        
                resultsCDF.variables[B.ID+&#34;_MagLatValues&#34;][:]    = B.MagLat_values
                resultsCDF.variables[B.ID+&#34;_MLTValues&#34;][:]       = B.MLT_values
                resultsCDF.variables[B.ID+&#34;_AltitudeValues&#34;][:]  = B.Altitude_values
                resultsCDF.variables[B.ID+&#34;_LatValues&#34;][:]       = B.Lat_values
                resultsCDF.variables[B.ID+&#34;_KpValues&#34;][:]        = B.Kp_values
                resultsCDF.variables[B.ID+&#34;_EEXValues&#34;][:]       = B.EEX_values        
                resultsCDF.variables[B.ID+&#34;_EEYValues&#34;][:]       = B.EEY_values
                resultsCDF.variables[B.ID+&#34;_PedersenValues&#34;][:]  = B.Pedersen_values
                resultsCDF.variables[B.ID+&#34;_HallValues&#34;][:]      = B.Hall_values
                resultsCDF.variables[B.ID+&#34;_DensityValues&#34;][:]   = B.Density_values
                resultsCDF.variables[B.ID+&#34;_LevValues&#34;][:]       = B.Lev_values
                resultsCDF.variables[B.ID+&#34;_ConvectionHeatingValues&#34;][:] = B.ConvectionHeating_values
                resultsCDF.variables[B.ID+&#34;_WindHeatingValues&#34;][:] = B.WindHeating_values
        ## save data for all hits
        resultsCDF.variables[&#34;allTimeValues&#34;][:]     = all_Time_values
        resultsCDF.variables[&#34;allJHValues&#34;][:]       = all_JH_values    
        resultsCDF.variables[&#34;allMagLatValues&#34;][:]   = all_MagLat_values
        resultsCDF.variables[&#34;allMLTValues&#34;][:]      = all_MLT_values
        resultsCDF.variables[&#34;allAltitudeValues&#34;][:] = all_Altitude_values
        resultsCDF.variables[&#34;allLatValues&#34;][:]      = all_Lat_values
        resultsCDF.variables[&#34;allKpValues&#34;][:]       = all_Kp_values
        #resultsCDF.variables[&#34;allHittedBinIDs&#34;][:]   = netCDF4.stringtochar(np.array(all_HittedBin_IDs[:], &#39;S8&#39;))
        resultsCDF.variables[&#34;allEEXValues&#34;][:]      = all_EEX_values
        resultsCDF.variables[&#34;allEEYValues&#34;][:]      = all_EEY_values
        resultsCDF.variables[&#34;allPedersenValues&#34;][:] = all_Pedersen_values
        resultsCDF.variables[&#34;allHallValues&#34;][:]     = all_Hall_values
        resultsCDF.variables[&#34;allDensityValues&#34;][:]  = all_Density_values
        resultsCDF.variables[&#34;allLevValues&#34;][:]      = all_Lev_values
        resultsCDF.variables[&#34;allConvectionHeatingValues&#34;][:] = all_ConvectionHeating_values
        resultsCDF.variables[&#34;allWindHeatingValues&#34;][:] = all_WindHeating_values
        #
        resultsCDF.close()    
    except Exception as e:
        print( &#34;!!!! Thread error while writing&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34; )
        print( e )
        #DiskAccessLock.release()
    #DiskAccessLock.release()

    print( &#34;Thread finish&#34;,  datetime.now().strftime(&#34;%d-%m-%Y %H:%M:%S&#34;), ResultsFilename[-26:], &#34;\n&#34;, Matches, &#34;matches&#34;, len(localBins[0].JH_values), len(Bins[0].JH_values) )
    print( &#34;&#34; )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="DaedalusMASE_Global_Statistics" href="index.html">DaedalusMASE_Global_Statistics</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="DaedalusMASE_Global_Statistics.data.AssignJouleHeatingValuesToBins_AlongOrbit" href="#DaedalusMASE_Global_Statistics.data.AssignJouleHeatingValuesToBins_AlongOrbit">AssignJouleHeatingValuesToBins_AlongOrbit</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.AssignValuesPerBin_MultipleResultFiles" href="#DaedalusMASE_Global_Statistics.data.AssignValuesPerBin_MultipleResultFiles">AssignValuesPerBin_MultipleResultFiles</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.CalculateStatsOnData" href="#DaedalusMASE_Global_Statistics.data.CalculateStatsOnData">CalculateStatsOnData</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.ClearBins" href="#DaedalusMASE_Global_Statistics.data.ClearBins">ClearBins</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.CreateNewBin" href="#DaedalusMASE_Global_Statistics.data.CreateNewBin">CreateNewBin</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.CreateResults_CDF" href="#DaedalusMASE_Global_Statistics.data.CreateResults_CDF">CreateResults_CDF</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.GetMatchedBin" href="#DaedalusMASE_Global_Statistics.data.GetMatchedBin">GetMatchedBin</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.LoadResults_CDF" href="#DaedalusMASE_Global_Statistics.data.LoadResults_CDF">LoadResults_CDF</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.SaveResults_CDF" href="#DaedalusMASE_Global_Statistics.data.SaveResults_CDF">SaveResults_CDF</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.doit" href="#DaedalusMASE_Global_Statistics.data.doit">doit</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.getBinByItsID" href="#DaedalusMASE_Global_Statistics.data.getBinByItsID">getBinByItsID</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.getBinByItsProperties" href="#DaedalusMASE_Global_Statistics.data.getBinByItsProperties">getBinByItsProperties</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.getBinDescription" href="#DaedalusMASE_Global_Statistics.data.getBinDescription">getBinDescription</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.is_MLT_inside_range" href="#DaedalusMASE_Global_Statistics.data.is_MLT_inside_range">is_MLT_inside_range</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="DaedalusMASE_Global_Statistics.data.Bin" href="#DaedalusMASE_Global_Statistics.data.Bin">Bin</a></code></h4>
<ul class="">
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Altitude_max" href="#DaedalusMASE_Global_Statistics.data.Bin.Altitude_max">Altitude_max</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Altitude_min" href="#DaedalusMASE_Global_Statistics.data.Bin.Altitude_min">Altitude_min</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Altitude_values" href="#DaedalusMASE_Global_Statistics.data.Bin.Altitude_values">Altitude_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.ConvectionHeating_values" href="#DaedalusMASE_Global_Statistics.data.Bin.ConvectionHeating_values">ConvectionHeating_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.CumulativeTime" href="#DaedalusMASE_Global_Statistics.data.Bin.CumulativeTime">CumulativeTime</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Density_values" href="#DaedalusMASE_Global_Statistics.data.Bin.Density_values">Density_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Description" href="#DaedalusMASE_Global_Statistics.data.Bin.Description">Description</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.DesirableCumulativeTime" href="#DaedalusMASE_Global_Statistics.data.Bin.DesirableCumulativeTime">DesirableCumulativeTime</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.EEX_values" href="#DaedalusMASE_Global_Statistics.data.Bin.EEX_values">EEX_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.EEY_values" href="#DaedalusMASE_Global_Statistics.data.Bin.EEY_values">EEY_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Hall_values" href="#DaedalusMASE_Global_Statistics.data.Bin.Hall_values">Hall_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.ID" href="#DaedalusMASE_Global_Statistics.data.Bin.ID">ID</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_distribution" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_distribution">JH_distribution</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_max" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_max">JH_max</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_mean" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_mean">JH_mean</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_median" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_median">JH_median</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_medianAbsDev" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_medianAbsDev">JH_medianAbsDev</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_medianVariance" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_medianVariance">JH_medianVariance</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_min" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_min">JH_min</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_values" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_values">JH_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.JH_variance" href="#DaedalusMASE_Global_Statistics.data.Bin.JH_variance">JH_variance</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Kp_max" href="#DaedalusMASE_Global_Statistics.data.Bin.Kp_max">Kp_max</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Kp_min" href="#DaedalusMASE_Global_Statistics.data.Bin.Kp_min">Kp_min</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Kp_values" href="#DaedalusMASE_Global_Statistics.data.Bin.Kp_values">Kp_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Lat_max" href="#DaedalusMASE_Global_Statistics.data.Bin.Lat_max">Lat_max</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Lat_min" href="#DaedalusMASE_Global_Statistics.data.Bin.Lat_min">Lat_min</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Lev_values" href="#DaedalusMASE_Global_Statistics.data.Bin.Lev_values">Lev_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.MLT_max" href="#DaedalusMASE_Global_Statistics.data.Bin.MLT_max">MLT_max</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.MLT_min" href="#DaedalusMASE_Global_Statistics.data.Bin.MLT_min">MLT_min</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.MLT_values" href="#DaedalusMASE_Global_Statistics.data.Bin.MLT_values">MLT_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.MagLat_max" href="#DaedalusMASE_Global_Statistics.data.Bin.MagLat_max">MagLat_max</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.MagLat_min" href="#DaedalusMASE_Global_Statistics.data.Bin.MagLat_min">MagLat_min</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.MagLat_values" href="#DaedalusMASE_Global_Statistics.data.Bin.MagLat_values">MagLat_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.NumOfBins" href="#DaedalusMASE_Global_Statistics.data.Bin.NumOfBins">NumOfBins</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Pedersen_values" href="#DaedalusMASE_Global_Statistics.data.Bin.Pedersen_values">Pedersen_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.Time_values" href="#DaedalusMASE_Global_Statistics.data.Bin.Time_values">Time_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.WindHeating_values" href="#DaedalusMASE_Global_Statistics.data.Bin.WindHeating_values">WindHeating_values</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.getInfo" href="#DaedalusMASE_Global_Statistics.data.Bin.getInfo">getInfo</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.printMe" href="#DaedalusMASE_Global_Statistics.data.Bin.printMe">printMe</a></code></li>
<li><code><a title="DaedalusMASE_Global_Statistics.data.Bin.reset" href="#DaedalusMASE_Global_Statistics.data.Bin.reset">reset</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="DaedalusMASE_Global_Statistics.data.Thread_ValueAssigner" href="#DaedalusMASE_Global_Statistics.data.Thread_ValueAssigner">Thread_ValueAssigner</a></code></h4>
<ul class="">
<li><code><a title="DaedalusMASE_Global_Statistics.data.Thread_ValueAssigner.run" href="#DaedalusMASE_Global_Statistics.data.Thread_ValueAssigner.run">run</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>